#!/usr/bin/env python3
"""
–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π - –¥–µ—Ç–∞–ª—å–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ —Ç–æ–≥–æ, –∫–∞–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∏ –ø–æ—á–µ–º—É –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç
"""

import json
from collections import defaultdict

def analyze_packet_details(packets):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞"""
    analysis = {
        'total_packets': len(packets),
        'tcp_packets': 0,
        'tls_packets': 0,
        'small_packets': 0,
        'fake_candidates': 0,
        'split_evidence': 0,
        'timing_anomalies': 0,
        'ttl_variations': set(),
        'packet_sizes': [],
        'sequence_analysis': {},
        'detailed_packets': []
    }
    
    timestamps = []
    sequences = []
    
    for i, packet in enumerate(packets):
        packet_detail = {
            'index': i,
            'num': packet.get('num'),
            'timestamp': packet.get('timestamp'),
            'src_ip': packet.get('src_ip'),
            'dst_ip': packet.get('dst_ip'),
            'src_port': packet.get('src_port'),
            'dst_port': packet.get('dst_port'),
            'ttl': packet.get('ttl'),
            'payload_len': packet.get('payload_len', 0),
            'flags': packet.get('flags', ''),
            'seq': packet.get('seq'),
            'ack': packet.get('ack'),
            'analysis': {}
        }
        
        # TCP –∞–Ω–∞–ª–∏–∑
        if packet.get('src_port') or packet.get('dst_port'):
            analysis['tcp_packets'] += 1
            
            # TTL –∞–Ω–∞–ª–∏–∑
            ttl = packet.get('ttl')
            if ttl:
                analysis['ttl_variations'].add(ttl)
                
                # –ù–∏–∑–∫–∏–π TTL = –≤–æ–∑–º–æ–∂–Ω—ã–π fake –ø–∞–∫–µ—Ç
                if ttl <= 5:
                    analysis['fake_candidates'] += 1
                    packet_detail['analysis']['likely_fake'] = True
                    packet_detail['analysis']['fake_reason'] = f"Low TTL: {ttl}"
            
            # –†–∞–∑–º–µ—Ä payload
            payload_len = packet.get('payload_len', 0)
            analysis['packet_sizes'].append(payload_len)
            
            # –ú–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞–∫–µ—Ç—ã = –≤–æ–∑–º–æ–∂–Ω—ã–π split
            if payload_len > 0 and payload_len <= 10:
                analysis['small_packets'] += 1
                analysis['split_evidence'] += 1
                packet_detail['analysis']['likely_split'] = True
                packet_detail['analysis']['split_reason'] = f"Small payload: {payload_len} bytes"
            
            # TLS –∞–Ω–∞–ª–∏–∑
            payload_hex = packet.get('payload_hex', '')
            if payload_hex and payload_hex.startswith('16'):
                analysis['tls_packets'] += 1
                packet_detail['analysis']['tls_packet'] = True
                
                # –ê–Ω–∞–ª–∏–∑ TLS record
                if len(payload_hex) >= 10:
                    try:
                        tls_version = payload_hex[2:6]
                        tls_length = int(payload_hex[6:10], 16)
                        packet_detail['analysis']['tls_version'] = tls_version
                        packet_detail['analysis']['tls_length'] = tls_length
                        
                        # –§—Ä–∞–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π TLS handshake
                        if payload_len < 100 and tls_length > payload_len:
                            packet_detail['analysis']['fragmented_tls'] = True
                    except:
                        pass
            
            # Sequence –∞–Ω–∞–ª–∏–∑
            seq = packet.get('seq')
            if seq is not None:
                sequences.append((i, seq))
        
        # Timing –∞–Ω–∞–ª–∏–∑
        timestamp = packet.get('timestamp')
        if timestamp:
            timestamps.append((i, timestamp))
        
        analysis['detailed_packets'].append(packet_detail)
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    if len(sequences) > 1:
        disorder_count = 0
        for i in range(1, len(sequences)):
            if sequences[i][1] < sequences[i-1][1]:
                disorder_count += 1
                # –û—Ç–º–µ—á–∞–µ–º –ø–∞–∫–µ—Ç—ã —Å –Ω–∞—Ä—É—à–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞
                analysis['detailed_packets'][sequences[i][0]]['analysis']['out_of_order'] = True
        
        analysis['sequence_analysis']['disorder_count'] = disorder_count
        analysis['sequence_analysis']['total_sequences'] = len(sequences)
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–∞–π–º–∏–Ω–≥–∞
    if len(timestamps) > 1:
        intervals = []
        for i in range(1, len(timestamps)):
            interval = timestamps[i][1] - timestamps[i-1][1]
            intervals.append(interval)
            
            # –û—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã (–≤–æ–∑–º–æ–∂–Ω–æ fake –ø–∞–∫–µ—Ç—ã)
            if interval < 0.001:
                analysis['timing_anomalies'] += 1
                analysis['detailed_packets'][timestamps[i][0]]['analysis']['fast_timing'] = True
        
        if intervals:
            analysis['sequence_analysis']['avg_interval'] = sum(intervals) / len(intervals)
            analysis['sequence_analysis']['min_interval'] = min(intervals)
            analysis['sequence_analysis']['max_interval'] = max(intervals)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º set –≤ list –¥–ª—è JSON
    analysis['ttl_variations'] = list(analysis['ttl_variations'])
    
    return analysis

def identify_strategy_type(analysis):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
    strategies = []
    
    # Split —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
    if analysis['split_evidence'] > 0:
        strategies.append({
            'type': 'split',
            'confidence': min(analysis['split_evidence'] / analysis['total_packets'], 1.0),
            'evidence': f"{analysis['split_evidence']} small packets detected"
        })
    
    # Fake —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
    if analysis['fake_candidates'] > 0:
        strategies.append({
            'type': 'fake',
            'confidence': min(analysis['fake_candidates'] / analysis['total_packets'], 1.0),
            'evidence': f"{analysis['fake_candidates']} low-TTL packets detected"
        })
    
    # Disorder —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
    disorder_count = analysis['sequence_analysis'].get('disorder_count', 0)
    if disorder_count > 0:
        strategies.append({
            'type': 'disorder',
            'confidence': min(disorder_count / analysis['tcp_packets'], 1.0) if analysis['tcp_packets'] > 0 else 0,
            'evidence': f"{disorder_count} out-of-order packets detected"
        })
    
    # Multisplit —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
    if analysis['split_evidence'] > 2:
        strategies.append({
            'type': 'multisplit',
            'confidence': min(analysis['split_evidence'] / 5, 1.0),
            'evidence': f"Multiple small packets: {analysis['split_evidence']}"
        })
    
    # Timing-based —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
    if analysis['timing_anomalies'] > 0:
        strategies.append({
            'type': 'timing',
            'confidence': min(analysis['timing_anomalies'] / analysis['total_packets'], 1.0),
            'evidence': f"{analysis['timing_anomalies']} timing anomalies detected"
        })
    
    return strategies

def analyze_failure_reasons(analysis):
    """–ê–Ω–∞–ª–∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω –Ω–µ—É–¥–∞—á–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
    reasons = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ DPI –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ
    if analysis['tls_packets'] > 0 and analysis['split_evidence'] > 0:
        reasons.append({
            'category': 'DPI_DETECTION',
            'reason': 'DPI –º–æ–∂–µ—Ç –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π TLS handshake',
            'severity': 'HIGH',
            'recommendation': '–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∏–ª–∏ –æ–±—Ñ—É—Å–∫–∞—Ü–∏—é'
        })
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ TTL —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    ttl_variations = len(analysis['ttl_variations'])
    if ttl_variations > 1 and analysis['fake_candidates'] == 0:
        reasons.append({
            'category': 'TTL_INEFFECTIVE',
            'reason': 'TTL –≤–∞—Ä–∏–∞—Ü–∏–∏ –µ—Å—Ç—å, –Ω–æ –Ω–µ—Ç –Ω–∏–∑–∫–∏—Ö TTL –¥–ª—è fake –ø–∞–∫–µ—Ç–æ–≤',
            'severity': 'MEDIUM',
            'recommendation': '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ TTL –∑–Ω–∞—á–µ–Ω–∏—è (1-3)'
        })
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–∞–∫–µ—Ç–æ–≤
    if analysis['packet_sizes']:
        avg_size = sum(analysis['packet_sizes']) / len(analysis['packet_sizes'])
        if avg_size > 100 and analysis['split_evidence'] == 0:
            reasons.append({
                'category': 'INSUFFICIENT_FRAGMENTATION',
                'reason': f'–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ {avg_size:.1f} –±–∞–π—Ç - –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è',
                'severity': 'HIGH',
                'recommendation': '–£–≤–µ–ª–∏—á–∏—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ—Å—Ç—å split —Å—Ç—Ä–∞—Ç–µ–≥–∏–π'
            })
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ timing –∞—Ç–∞–∫
    timing_info = analysis['sequence_analysis']
    if timing_info.get('min_interval', 1) > 0.01:
        reasons.append({
            'category': 'TIMING_INEFFECTIVE',
            'reason': f'–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª {timing_info.get("min_interval", 0):.3f}s - –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±—ã—Å—Ç—Ä–æ',
            'severity': 'LOW',
            'recommendation': '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ timing –∞—Ç–∞–∫–∏'
        })
    
    return reasons

def main():
    print("üî¨ –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º adapt.json
    try:
        with open("adapt.json", "r", encoding="utf-8") as f:
            data = json.load(f)
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª adapt.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    flows = data.get("flows", {})
    
    print(f"üìä –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ {len(flows)} –ø–æ—Ç–æ–∫–æ–≤")
    
    all_results = {}
    
    for flow_name, packets in flows.items():
        print(f"\nüîó –ü–æ—Ç–æ–∫: {flow_name}")
        print(f"   –ü–∞–∫–µ—Ç–æ–≤: {len(packets)}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis = analyze_packet_details(packets)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        strategies = identify_strategy_type(analysis)
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω –Ω–µ—É–¥–∞—á
        failure_reasons = analyze_failure_reasons(analysis)
        
        print(f"   üìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"     TCP –ø–∞–∫–µ—Ç—ã: {analysis['tcp_packets']}")
        print(f"     TLS –ø–∞–∫–µ—Ç—ã: {analysis['tls_packets']}")
        print(f"     –ú–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞–∫–µ—Ç—ã: {analysis['small_packets']}")
        print(f"     –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –≤ fake: {analysis['fake_candidates']}")
        print(f"     TTL –≤–∞—Ä–∏–∞—Ü–∏–∏: {analysis['ttl_variations']}")
        
        if analysis['packet_sizes']:
            avg_size = sum(analysis['packet_sizes']) / len(analysis['packet_sizes'])
            print(f"     –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {avg_size:.1f} –±–∞–π—Ç")
        
        print(f"   üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:")
        if strategies:
            for strategy in strategies:
                confidence_pct = strategy['confidence'] * 100
                print(f"     ‚úÖ {strategy['type']}: {confidence_pct:.1f}% ({strategy['evidence']})")
        else:
            print(f"     ‚ùå –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
        
        print(f"   ‚ö†Ô∏è  –ü—Ä–∏—á–∏–Ω—ã –Ω–µ—É–¥–∞—á:")
        if failure_reasons:
            for reason in failure_reasons:
                severity_icon = {"HIGH": "üî¥", "MEDIUM": "üü°", "LOW": "üü¢"}[reason['severity']]
                print(f"     {severity_icon} {reason['category']}: {reason['reason']}")
                print(f"        üí° {reason['recommendation']}")
        else:
            print(f"     ‚úÖ –û—á–µ–≤–∏–¥–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞–∫–µ—Ç–æ–≤
        print(f"   üì¶ –î–µ—Ç–∞–ª–∏ –ø–∞–∫–µ—Ç–æ–≤:")
        for packet in analysis['detailed_packets'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            packet_analysis = packet.get('analysis', {})
            flags_str = f" flags={packet['flags']}" if packet['flags'] else ""
            ttl_str = f" TTL={packet['ttl']}" if packet['ttl'] else ""
            payload_str = f" payload={packet['payload_len']}" if packet['payload_len'] else ""
            
            analysis_tags = []
            if packet_analysis.get('likely_fake'):
                analysis_tags.append("FAKE")
            if packet_analysis.get('likely_split'):
                analysis_tags.append("SPLIT")
            if packet_analysis.get('tls_packet'):
                analysis_tags.append("TLS")
            if packet_analysis.get('out_of_order'):
                analysis_tags.append("DISORDER")
            if packet_analysis.get('fast_timing'):
                analysis_tags.append("FAST")
            
            tags_str = f" [{','.join(analysis_tags)}]" if analysis_tags else ""
            
            print(f"     #{packet['num']}: {packet['src_ip']}:{packet['src_port']} -> {packet['dst_ip']}:{packet['dst_port']}{ttl_str}{payload_str}{flags_str}{tags_str}")
        
        if len(analysis['detailed_packets']) > 5:
            print(f"     ... –∏ –µ—â–µ {len(analysis['detailed_packets']) - 5} –ø–∞–∫–µ—Ç–æ–≤")
        
        all_results[flow_name] = {
            'analysis': analysis,
            'strategies': strategies,
            'failure_reasons': failure_reasons
        }
    
    # –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã
    print(f"\nüìä –û–ë–©–ò–ï –í–´–í–û–î–´:")
    
    total_strategies = sum(len(result['strategies']) for result in all_results.values())
    total_flows_with_strategies = sum(1 for result in all_results.values() if result['strategies'])
    
    print(f"   –ü–æ—Ç–æ–∫–æ–≤ —Å–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏: {total_flows_with_strategies}/{len(flows)}")
    print(f"   –í—Å–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {total_strategies}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    strategy_stats = defaultdict(int)
    for result in all_results.values():
        for strategy in result['strategies']:
            strategy_stats[strategy['type']] += 1
    
    print(f"   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π:")
    for strategy_type, count in strategy_stats.items():
        print(f"     {strategy_type}: {count} –ø–æ—Ç–æ–∫–æ–≤")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
    problem_stats = defaultdict(int)
    for result in all_results.values():
        for reason in result['failure_reasons']:
            problem_stats[reason['category']] += 1
    
    print(f"   –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:")
    for problem_type, count in problem_stats.items():
        print(f"     {problem_type}: {count} –ø–æ—Ç–æ–∫–æ–≤")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –ò–¢–û–ì–û–í–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    
    if total_flows_with_strategies == 0:
        print("   ‚ùå –ö–†–ò–¢–ò–ß–ù–û: –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è!")
        print("     1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç–∏–≤–∞—Ü–∏—é bypass engine")
        print("     2. –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        print("     3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å WinDivert —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    elif total_flows_with_strategies < len(flows):
        print("   ‚ö†Ô∏è  –ß–ê–°–¢–ò–ß–ù–û: –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –Ω–µ –∫–æ –≤—Å–µ–º –ø–æ—Ç–æ–∫–∞–º")
        print("     1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Ç—Ä–∞—Ñ–∏–∫–∞")
        print("     2. –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –¥–æ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª")
    else:
        print("   ‚úÖ –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è, –Ω–æ DPI –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–ª—Å—è")
        
        if 'DPI_DETECTION' in problem_stats:
            print("     1. DPI –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ - –Ω—É–∂–Ω—ã –±–æ–ª–µ–µ —Å–∫—Ä—ã—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏")
        if 'INSUFFICIENT_FRAGMENTATION' in problem_stats:
            print("     2. –£–≤–µ–ª–∏—á–∏—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
        if 'TTL_INEFFECTIVE' in problem_stats:
            print("     3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ TTL –∑–Ω–∞—á–µ–Ω–∏—è")
        
        print("     4. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã:")
        print("        - –û–±—Ñ—É—Å–∫–∞—Ü–∏—è SNI")
        print("        - –¢—É–Ω–Ω–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –¥—Ä—É–≥–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª—ã")
        print("        - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CDN/–ø—Ä–æ–∫—Å–∏")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    with open("deep_strategy_analysis.json", "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ deep_strategy_analysis.json")

if __name__ == "__main__":
    main()