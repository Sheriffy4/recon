#!/usr/bin/env python3
"""
PCAP Comparison Analyzer for Recon vs Zapret

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É PCAP —Ñ–∞–π–ª–∞–º–∏ recon –∏ zapret –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è
–ø—Ä–∏—á–∏–Ω —Ä–∞–∑–ª–∏—á–∏–π –≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –æ–±—Ö–æ–¥–∞ DPI.

–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
1. Fake SNI - zapret –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ SNI
2. Checksum corruption - —Ä–∞–∑–ª–∏—á–∏—è –≤ TCP checksum
3. TCP flags - —Ä–∞–∑–ª–∏—á–∏—è –≤ —Ñ–ª–∞–≥–∞—Ö –ø–∞–∫–µ—Ç–æ–≤
4. Sequence numbers - —Ä–∞–∑–ª–∏—á–∏—è –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
5. Timing - —Ä–∞–∑–ª–∏—á–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç–æ–≤
"""

import json
import logging
import sys
import os
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path

# Add recon directory to path
recon_dir = os.path.dirname(os.path.abspath(__file__))
if recon_dir not in sys.path:
    sys.path.insert(0, recon_dir)

try:
    from scapy.all import rdpcap, TCP, IP, TLS
    SCAPY_AVAILABLE = True
except ImportError:
    SCAPY_AVAILABLE = False
    print("‚ö†Ô∏è  Scapy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scapy")


@dataclass
class PacketAnalysis:
    """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞."""
    timestamp: float
    src_ip: str
    dst_ip: str
    src_port: int
    dst_port: int
    tcp_flags: int
    seq_num: int
    ack_num: int
    ttl: int
    checksum: int
    checksum_valid: bool
    payload_len: int
    is_tls: bool
    sni: Optional[str] = None
    payload_preview: str = ""


@dataclass
class FlowAnalysis:
    """–ê–Ω–∞–ª–∏–∑ TCP –ø–æ—Ç–æ–∫–∞."""
    flow_id: str
    packets: List[PacketAnalysis]
    fake_packets: List[PacketAnalysis]
    real_packets: List[PacketAnalysis]
    sni_values: List[str]
    timing_analysis: Dict[str, Any]
    effectiveness_score: float


class PCAPComparator:
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç PCAP —Ñ–∞–π–ª—ã recon –∏ zapret."""
    
    def __init__(self, debug: bool = True):
        self.logger = logging.getLogger("PCAPComparator")
        if debug:
            logging.basicConfig(level=logging.DEBUG)
        
    def analyze_pcap_files(self, recon_pcap: str, zapret_pcap: str) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ PCAP —Ñ–∞–π–ª–æ–≤.
        
        Args:
            recon_pcap: –ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É recon
            zapret_pcap: –ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É zapret
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        if not SCAPY_AVAILABLE:
            return {"error": "Scapy –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ PCAP"}
        
        self.logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ PCAP —Ñ–∞–π–ª–æ–≤:")
        self.logger.info(f"  Recon: {recon_pcap}")
        self.logger.info(f"  Zapret: {zapret_pcap}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
        if not os.path.exists(recon_pcap):
            return {"error": f"Recon PCAP —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {recon_pcap}"}
        
        if not os.path.exists(zapret_pcap):
            return {"error": f"Zapret PCAP —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {zapret_pcap}"}
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π PCAP
            recon_analysis = self._analyze_single_pcap(recon_pcap, "recon")
            zapret_analysis = self._analyze_single_pcap(zapret_pcap, "zapret")
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            comparison = self._compare_analyses(recon_analysis, zapret_analysis)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = self._generate_recommendations(comparison)
            
            return {
                "recon_analysis": recon_analysis,
                "zapret_analysis": zapret_analysis,
                "comparison": comparison,
                "recommendations": recommendations,
                "summary": self._generate_summary(comparison)
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ PCAP: {e}")
            return {"error": str(e)}
    
    def _analyze_single_pcap(self, pcap_file: str, source: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω PCAP —Ñ–∞–π–ª."""
        self.logger.info(f"üì¶ –ê–Ω–∞–ª–∏–∑ {source} PCAP: {pcap_file}")
        
        try:
            packets = rdpcap(pcap_file)
            self.logger.info(f"  –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(packets)} –ø–∞–∫–µ—Ç–æ–≤")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–∞–∫–µ—Ç—ã –ø–æ –ø–æ—Ç–æ–∫–∞–º
            flows = self._group_packets_by_flow(packets)
            self.logger.info(f"  –ù–∞–π–¥–µ–Ω–æ {len(flows)} TCP –ø–æ—Ç–æ–∫–æ–≤")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –ø–æ—Ç–æ–∫
            flow_analyses = {}
            for flow_id, flow_packets in flows.items():
                flow_analysis = self._analyze_flow(flow_id, flow_packets)
                flow_analyses[flow_id] = flow_analysis
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_packets = len(packets)
            tcp_packets = len([p for p in packets if TCP in p])
            tls_packets = len([p for p in packets if TCP in p and len(p[TCP].payload) > 0])
            
            return {
                "source": source,
                "file": pcap_file,
                "total_packets": total_packets,
                "tcp_packets": tcp_packets,
                "tls_packets": tls_packets,
                "flows": flow_analyses,
                "statistics": self._calculate_statistics(flow_analyses)
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {source} PCAP: {e}")
            return {"error": str(e), "source": source}
    
    def _group_packets_by_flow(self, packets) -> Dict[str, List]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–∞–∫–µ—Ç—ã –ø–æ TCP –ø–æ—Ç–æ–∫–∞–º."""
        flows = {}
        
        for packet in packets:
            if TCP not in packet or IP not in packet:
                continue
            
            ip = packet[IP]
            tcp = packet[TCP]
            
            # –°–æ–∑–¥–∞–µ–º ID –ø–æ—Ç–æ–∫–∞ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π)
            src_ip, dst_ip = ip.src, ip.dst
            src_port, dst_port = tcp.sport, tcp.dport
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ—Ç–æ–∫ (–º–µ–Ω—å—à–∏–π IP:port –ø–µ—Ä–≤—ã–º)
            if (src_ip, src_port) > (dst_ip, dst_port):
                src_ip, dst_ip = dst_ip, src_ip
                src_port, dst_port = dst_port, src_port
            
            flow_id = f"{src_ip}:{src_port}->{dst_ip}:{dst_port}"
            
            if flow_id not in flows:
                flows[flow_id] = []
            
            flows[flow_id].append(packet)
        
        return flows
    
    def _analyze_flow(self, flow_id: str, packets: List) -> FlowAnalysis:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π TCP –ø–æ—Ç–æ–∫."""
        packet_analyses = []
        fake_packets = []
        real_packets = []
        sni_values = []
        
        for packet in packets:
            analysis = self._analyze_packet(packet)
            packet_analyses.append(analysis)
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –ø–∞–∫–µ—Ç—ã –ø–æ TTL
            if analysis.ttl <= 4:  # –ù–∏–∑–∫–∏–π TTL = fake –ø–∞–∫–µ—Ç
                fake_packets.append(analysis)
            else:
                real_packets.append(analysis)
            
            # –°–æ–±–∏—Ä–∞–µ–º SNI
            if analysis.sni:
                sni_values.append(analysis.sni)
        
        # –ê–Ω–∞–ª–∏–∑ timing
        timing_analysis = self._analyze_timing(packet_analyses)
        
        # –û—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        effectiveness_score = self._calculate_effectiveness_score(
            fake_packets, real_packets, sni_values
        )
        
        return FlowAnalysis(
            flow_id=flow_id,
            packets=packet_analyses,
            fake_packets=fake_packets,
            real_packets=real_packets,
            sni_values=list(set(sni_values)),
            timing_analysis=timing_analysis,
            effectiveness_score=effectiveness_score
        )
    
    def _analyze_packet(self, packet) -> PacketAnalysis:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞–∫–µ—Ç."""
        ip = packet[IP]
        tcp = packet[TCP]
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        analysis = PacketAnalysis(
            timestamp=float(packet.time),
            src_ip=ip.src,
            dst_ip=ip.dst,
            src_port=tcp.sport,
            dst_port=tcp.dport,
            tcp_flags=tcp.flags,
            seq_num=tcp.seq,
            ack_num=tcp.ack,
            ttl=ip.ttl,
            checksum=tcp.chksum,
            checksum_valid=self._validate_checksum(packet),
            payload_len=len(tcp.payload),
            is_tls=False
        )
        
        # –ê–Ω–∞–ª–∏–∑ TLS –∏ SNI
        if len(tcp.payload) > 0:
            payload = bytes(tcp.payload)
            analysis.payload_preview = payload[:50].hex()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TLS
            if self._is_tls_packet(payload):
                analysis.is_tls = True
                analysis.sni = self._extract_sni(payload)
        
        return analysis
    
    def _validate_checksum(self, packet) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å TCP checksum."""
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –ø–∞–∫–µ—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            test_packet = packet.copy()
            del test_packet[TCP].chksum
            
            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º checksum
            test_packet = IP(bytes(test_packet))
            
            return test_packet[TCP].chksum == packet[TCP].chksum
        except:
            return False
    
    def _is_tls_packet(self, payload: bytes) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–∞–∫–µ—Ç TLS."""
        if len(payload) < 6:
            return False
        
        # TLS Record header: type(1) + version(2) + length(2)
        record_type = payload[0]
        version = (payload[1] << 8) | payload[2]
        
        # TLS record types: 20-24, –≤–µ—Ä—Å–∏–∏: 0x0301-0x0304
        return (record_type in [20, 21, 22, 23, 24] and 
                version in [0x0301, 0x0302, 0x0303, 0x0304])
    
    def _extract_sni(self, payload: bytes) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç SNI –∏–∑ TLS ClientHello."""
        try:
            if len(payload) < 43:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä ClientHello
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TLS Handshake
            if payload[0] != 0x16:  # Handshake record
                return None
            
            # –ò—â–µ–º ClientHello
            if len(payload) < 6 or payload[5] != 0x01:  # ClientHello
                return None
            
            # –ü–∞—Ä—Å–∏–º ClientHello –¥–ª—è –ø–æ–∏—Å–∫–∞ SNI extension
            offset = 43  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —á–∞—Å—Ç—å ClientHello
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Session ID
            if offset >= len(payload):
                return None
            session_id_len = payload[offset]
            offset += 1 + session_id_len
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Cipher Suites
            if offset + 2 >= len(payload):
                return None
            cipher_suites_len = (payload[offset] << 8) | payload[offset + 1]
            offset += 2 + cipher_suites_len
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Compression Methods
            if offset >= len(payload):
                return None
            compression_len = payload[offset]
            offset += 1 + compression_len
            
            # –ß–∏—Ç–∞–µ–º Extensions
            if offset + 2 >= len(payload):
                return None
            extensions_len = (payload[offset] << 8) | payload[offset + 1]
            offset += 2
            
            # –ò—â–µ–º SNI extension (type = 0x0000)
            extensions_end = offset + extensions_len
            while offset + 4 < extensions_end:
                ext_type = (payload[offset] << 8) | payload[offset + 1]
                ext_len = (payload[offset + 2] << 8) | payload[offset + 3]
                offset += 4
                
                if ext_type == 0x0000:  # SNI extension
                    return self._parse_sni_extension(payload[offset:offset + ext_len])
                
                offset += ext_len
            
            return None
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è SNI: {e}")
            return None
    
    def _parse_sni_extension(self, sni_data: bytes) -> Optional[str]:
        """–ü–∞—Ä—Å–∏—Ç SNI extension."""
        try:
            if len(sni_data) < 5:
                return None
            
            # Server Name List Length
            list_len = (sni_data[0] << 8) | sni_data[1]
            offset = 2
            
            # Server Name Type (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 0 –¥–ª—è hostname)
            if offset >= len(sni_data) or sni_data[offset] != 0:
                return None
            offset += 1
            
            # Server Name Length
            if offset + 2 >= len(sni_data):
                return None
            name_len = (sni_data[offset] << 8) | sni_data[offset + 1]
            offset += 2
            
            # Server Name
            if offset + name_len > len(sni_data):
                return None
            
            return sni_data[offset:offset + name_len].decode('utf-8', errors='ignore')
            
        except Exception:
            return None
    
    def _analyze_timing(self, packets: List[PacketAnalysis]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç timing –ø–∞–∫–µ—Ç–æ–≤."""
        if len(packets) < 2:
            return {"intervals": [], "avg_interval": 0.0, "total_duration": 0.0}
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        sorted_packets = sorted(packets, key=lambda p: p.timestamp)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        intervals = []
        for i in range(1, len(sorted_packets)):
            interval = sorted_packets[i].timestamp - sorted_packets[i-1].timestamp
            intervals.append(interval * 1000)  # –í –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        
        total_duration = sorted_packets[-1].timestamp - sorted_packets[0].timestamp
        avg_interval = sum(intervals) / len(intervals) if intervals else 0.0
        
        return {
            "intervals": intervals,
            "avg_interval": avg_interval,
            "total_duration": total_duration * 1000,  # –í –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            "packet_count": len(packets)
        }
    
    def _calculate_effectiveness_score(
        self, fake_packets: List[PacketAnalysis], 
        real_packets: List[PacketAnalysis], 
        sni_values: List[str]
    ) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ—Ç–æ–∫–∞."""
        score = 0.0
        
        # –ù–∞–ª–∏—á–∏–µ fake –ø–∞–∫–µ—Ç–æ–≤ (+30%)
        if fake_packets:
            score += 0.3
        
        # –ù–∞–ª–∏—á–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ (+20%)
        if real_packets:
            score += 0.2
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ fake SNI (+25%)
        if sni_values:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ SNI
            fake_sni_detected = any(
                sni for sni in sni_values 
                if not any(domain in sni.lower() for domain in ['x.com', 'twitter.com', 'twimg.com'])
            )
            if fake_sni_detected:
                score += 0.25
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ TCP —Ñ–ª–∞–≥–∏ (+15%)
        psh_flags = sum(1 for p in fake_packets if p.tcp_flags & 0x08)  # PSH flag
        if psh_flags > 0:
            score += 0.15
        
        # –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ checksums (+10%)
        bad_checksums = sum(1 for p in fake_packets if not p.checksum_valid)
        if bad_checksums > 0:
            score += 0.10
        
        return min(1.0, score)
    
    def _calculate_statistics(self, flows: Dict[str, FlowAnalysis]) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
        if not flows:
            return {}
        
        total_packets = sum(len(flow.packets) for flow in flows.values())
        total_fake = sum(len(flow.fake_packets) for flow in flows.values())
        total_real = sum(len(flow.real_packets) for flow in flows.values())
        
        avg_effectiveness = sum(flow.effectiveness_score for flow in flows.values()) / len(flows)
        
        # SNI —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        all_sni = []
        for flow in flows.values():
            all_sni.extend(flow.sni_values)
        unique_sni = list(set(all_sni))
        
        return {
            "total_flows": len(flows),
            "total_packets": total_packets,
            "fake_packets": total_fake,
            "real_packets": total_real,
            "fake_ratio": total_fake / total_packets if total_packets > 0 else 0.0,
            "avg_effectiveness": avg_effectiveness,
            "unique_sni_count": len(unique_sni),
            "sni_values": unique_sni[:10]  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        }
    
    def _compare_analyses(self, recon_analysis: Dict, zapret_analysis: Dict) -> Dict[str, Any]:
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑—ã recon –∏ zapret."""
        comparison = {
            "packet_count_diff": {},
            "effectiveness_diff": {},
            "sni_comparison": {},
            "timing_comparison": {},
            "technical_differences": {}
        }
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞–∫–µ—Ç–æ–≤
        recon_stats = recon_analysis.get("statistics", {})
        zapret_stats = zapret_analysis.get("statistics", {})
        
        comparison["packet_count_diff"] = {
            "recon_total": recon_stats.get("total_packets", 0),
            "zapret_total": zapret_stats.get("total_packets", 0),
            "recon_fake": recon_stats.get("fake_packets", 0),
            "zapret_fake": zapret_stats.get("fake_packets", 0),
            "fake_ratio_recon": recon_stats.get("fake_ratio", 0.0),
            "fake_ratio_zapret": zapret_stats.get("fake_ratio", 0.0)
        }
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        comparison["effectiveness_diff"] = {
            "recon_avg": recon_stats.get("avg_effectiveness", 0.0),
            "zapret_avg": zapret_stats.get("avg_effectiveness", 0.0),
            "difference": zapret_stats.get("avg_effectiveness", 0.0) - recon_stats.get("avg_effectiveness", 0.0)
        }
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ SNI
        recon_sni = set(recon_stats.get("sni_values", []))
        zapret_sni = set(zapret_stats.get("sni_values", []))
        
        comparison["sni_comparison"] = {
            "recon_sni": list(recon_sni),
            "zapret_sni": list(zapret_sni),
            "common_sni": list(recon_sni & zapret_sni),
            "recon_only": list(recon_sni - zapret_sni),
            "zapret_only": list(zapret_sni - recon_sni),
            "zapret_uses_fake_sni": len(zapret_sni) > 0 and not any(
                domain in str(zapret_sni).lower() 
                for domain in ['x.com', 'twitter.com', 'twimg.com']
            )
        }
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–ª–∏—á–∏—è
        comparison["technical_differences"] = self._analyze_technical_differences(
            recon_analysis, zapret_analysis
        )
        
        return comparison
    
    def _analyze_technical_differences(self, recon_analysis: Dict, zapret_analysis: Dict) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è–º–∏."""
        differences = {
            "checksum_handling": {},
            "tcp_flags": {},
            "sequence_numbers": {},
            "ttl_usage": {}
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ç–æ–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–∞–∑–ª–∏—á–∏–π
        recon_flows = recon_analysis.get("flows", {})
        zapret_flows = zapret_analysis.get("flows", {})
        
        # Checksum –∞–Ω–∞–ª–∏–∑
        recon_bad_checksums = 0
        recon_total_fake = 0
        for flow in recon_flows.values():
            for packet in flow.fake_packets:
                recon_total_fake += 1
                if not packet.checksum_valid:
                    recon_bad_checksums += 1
        
        zapret_bad_checksums = 0
        zapret_total_fake = 0
        for flow in zapret_flows.values():
            for packet in flow.fake_packets:
                zapret_total_fake += 1
                if not packet.checksum_valid:
                    zapret_bad_checksums += 1
        
        differences["checksum_handling"] = {
            "recon_bad_checksum_ratio": recon_bad_checksums / recon_total_fake if recon_total_fake > 0 else 0.0,
            "zapret_bad_checksum_ratio": zapret_bad_checksums / zapret_total_fake if zapret_total_fake > 0 else 0.0,
            "zapret_better": zapret_bad_checksums > recon_bad_checksums
        }
        
        # TTL –∞–Ω–∞–ª–∏–∑
        recon_ttls = []
        zapret_ttls = []
        
        for flow in recon_flows.values():
            recon_ttls.extend([p.ttl for p in flow.fake_packets])
        
        for flow in zapret_flows.values():
            zapret_ttls.extend([p.ttl for p in flow.fake_packets])
        
        differences["ttl_usage"] = {
            "recon_ttls": list(set(recon_ttls)),
            "zapret_ttls": list(set(zapret_ttls)),
            "recon_avg_ttl": sum(recon_ttls) / len(recon_ttls) if recon_ttls else 0,
            "zapret_avg_ttl": sum(zapret_ttls) / len(zapret_ttls) if zapret_ttls else 0
        }
        
        return differences
    
    def _generate_recommendations(self, comparison: Dict[str, Any]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é recon."""
        recommendations = []
        
        # SNI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        sni_comp = comparison.get("sni_comparison", {})
        if sni_comp.get("zapret_uses_fake_sni", False) and not sni_comp.get("recon_only"):
            recommendations.append(
                "üé≠ –ö–†–ò–¢–ò–ß–ù–û: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ–¥–¥–µ–ª—å–Ω—ã—Ö SNI –∫–∞–∫ –≤ zapret. "
                "Zapret –∏—Å–ø–æ–ª—å–∑—É–µ—Ç fake SNI –¥–ª—è –æ–±—Ö–æ–¥–∞ DPI, –∞ recon –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ."
            )
        
        # Checksum —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        tech_diff = comparison.get("technical_differences", {})
        checksum_diff = tech_diff.get("checksum_handling", {})
        if checksum_diff.get("zapret_better", False):
            recommendations.append(
                "üîß –£–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É TCP checksum. Zapret —á–∞—â–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ "
                "checksums –≤ fake –ø–∞–∫–µ—Ç–∞—Ö –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—Ö–æ–¥–∞ DPI."
            )
        
        # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        eff_diff = comparison.get("effectiveness_diff", {})
        if eff_diff.get("difference", 0) > 0.2:
            recommendations.append(
                f"üìà –û–±—â–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å zapret –≤—ã—à–µ –Ω–∞ {eff_diff.get('difference', 0):.1%}. "
                "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –≤–Ω–µ–¥—Ä–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ä–∞–∑–ª–∏—á–∏—è."
            )
        
        # –ü–∞–∫–µ—Ç—ã
        packet_diff = comparison.get("packet_count_diff", {})
        if packet_diff.get("fake_ratio_zapret", 0) > packet_diff.get("fake_ratio_recon", 0):
            recommendations.append(
                "üì¶ –£–≤–µ–ª–∏—á–∏—Ç—å –¥–æ–ª—é fake –ø–∞–∫–µ—Ç–æ–≤. Zapret –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª—å—à–µ fake –ø–∞–∫–µ—Ç–æ–≤ "
                "–¥–ª—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—Ö–æ–¥–∞."
            )
        
        # TTL —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        ttl_usage = tech_diff.get("ttl_usage", {})
        if ttl_usage.get("zapret_avg_ttl", 0) < ttl_usage.get("recon_avg_ttl", 0):
            recommendations.append(
                "‚è±Ô∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–µ TTL –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∫ –≤ zapret. "
                f"Zapret: {ttl_usage.get('zapret_avg_ttl', 0):.1f}, "
                f"Recon: {ttl_usage.get('recon_avg_ttl', 0):.1f}"
            )
        
        if not recommendations:
            recommendations.append("‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –í–æ–∑–º–æ–∂–Ω—ã –±–æ–ª–µ–µ —Ç–æ–Ω–∫–∏–µ —Ä–∞–∑–ª–∏—á–∏—è –≤ timing –∏–ª–∏ –ª–æ–≥–∏–∫–µ.")
        
        return recommendations
    
    def _generate_summary(self, comparison: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
        eff_diff = comparison.get("effectiveness_diff", {})
        sni_comp = comparison.get("sni_comparison", {})
        
        return {
            "zapret_more_effective": eff_diff.get("difference", 0) > 0.1,
            "effectiveness_gap": eff_diff.get("difference", 0),
            "main_issue": "fake_sni" if sni_comp.get("zapret_uses_fake_sni", False) else "unknown",
            "critical_fixes_needed": len([r for r in self._generate_recommendations(comparison) if "–ö–†–ò–¢–ò–ß–ù–û" in r]),
            "status": "needs_improvement" if eff_diff.get("difference", 0) > 0.1 else "acceptable"
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞."""
    import argparse
    
    parser = argparse.ArgumentParser(description="–ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É PCAP —Ñ–∞–π–ª–∞–º–∏ recon –∏ zapret")
    parser.add_argument("--recon-pcap", required=True, help="–ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É recon")
    parser.add_argument("--zapret-pcap", required=True, help="–ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É zapret")
    parser.add_argument("--output", help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (JSON)")
    parser.add_argument("--debug", action="store_true", help="–í–∫–ª—é—á–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    comparator = PCAPComparator(debug=args.debug)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    print("üîç –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ PCAP —Ñ–∞–π–ª–æ–≤...")
    results = comparator.analyze_pcap_files(args.recon_pcap, args.zapret_pcap)
    
    if "error" in results:
        print(f"‚ùå –û—à–∏–±–∫–∞: {results['error']}")
        return 1
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "="*60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–†–ê–í–ù–ï–ù–ò–Ø PCAP")
    print("="*60)
    
    summary = results.get("summary", {})
    print(f"–°—Ç–∞—Ç—É—Å: {'‚ùå –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è' if summary.get('status') == 'needs_improvement' else '‚úÖ –ü—Ä–∏–µ–º–ª–µ–º–æ'}")
    print(f"–†–∞–∑—Ä—ã–≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {summary.get('effectiveness_gap', 0):.1%}")
    print(f"–ö—Ä–∏—Ç–∏—á–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {summary.get('critical_fixes_needed', 0)}")
    
    print(f"\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    for i, rec in enumerate(results.get("recommendations", []), 1):
        print(f"{i}. {rec}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output}")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())