#!/usr/bin/env python3
"""
File Analyzer - –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É.
"""

import ast
import json
from pathlib import Path
from typing import Dict, List, Optional, Any, Set, Tuple
from dataclasses import dataclass
from collections import defaultdict
from datetime import datetime


@dataclass
class MethodInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–µ—Ç–æ–¥–µ."""
    name: str
    line_start: int
    line_end: int
    complexity: int
    parameters_count: int
    calls_count: int
    is_public: bool
    responsibility_group: str


@dataclass
class ClassInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Å–µ."""
    name: str
    line_start: int
    line_end: int
    methods: List[MethodInfo]
    responsibilities_count: int
    is_god_object: bool
    
    @property
    def public_methods_count(self) -> int:
        return len([m for m in self.methods if m.is_public])
        
    @property
    def total_complexity(self) -> int:
        return sum(m.complexity for m in self.methods)


@dataclass
class FileAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞."""
    filepath: str
    lines_count: int
    classes: List[ClassInfo]
    imports_count: int
    complexity_score: int
    issues: List[str]
    recommendations: List[str]
    refactoring_priority: int  # 1-10, –≥–¥–µ 10 = –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
    automation_potential: float  # 0.0-1.0


class FileAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
    
    def __init__(self):
        self.responsibility_keywords = {
            "strategy": ["strategy", "generate", "create", "build", "construct", "produce"],
            "testing": ["test", "validate", "verify", "check", "probe", "assert"],
            "analysis": ["analyze", "parse", "process", "examine", "inspect", "scan"],
            "caching": ["cache", "store", "save", "load", "persist", "retrieve"],
            "logging": ["log", "debug", "info", "warn", "error", "trace"],
            "config": ["config", "setting", "option", "parameter", "preference"],
            "network": ["connect", "request", "response", "http", "tcp", "socket"],
            "fingerprint": ["fingerprint", "detect", "identify", "recognize", "signature"],
            "monitoring": ["monitor", "track", "measure", "metric", "stat", "observe"],
            "validation": ["validate", "sanitize", "normalize", "clean", "format"],
            "transformation": ["transform", "convert", "modify", "change", "update"],
            "coordination": ["coordinate", "orchestrate", "manage", "control", "handle"]
        }
        
    def analyze_file(self, filepath: Path) -> FileAnalysisResult:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞."""
        
        try:
            content = filepath.read_text(encoding='utf-8')
            tree = ast.parse(content)
            lines = content.splitlines()
            
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            lines_count = len(lines)
            imports_count = len([node for node in ast.walk(tree) 
                               if isinstance(node, (ast.Import, ast.ImportFrom))])
            
            # –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Å–æ–≤
            classes = []
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_info = self._analyze_class(node, lines)
                    classes.append(class_info)
                    
            # –û–±—â–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
            complexity_score = sum(cls.total_complexity for cls in classes)
            
            # –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
            issues = self._identify_issues(lines_count, classes, complexity_score)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            recommendations = self._generate_recommendations(classes, issues)
            
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞
            priority = self._calculate_priority(lines_count, classes, len(issues))
            
            # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
            automation_potential = self._calculate_automation_potential(classes, issues)
            
            return FileAnalysisResult(
                filepath=str(filepath),
                lines_count=lines_count,
                classes=classes,
                imports_count=imports_count,
                complexity_score=complexity_score,
                issues=issues,
                recommendations=recommendations,
                refactoring_priority=priority,
                automation_potential=automation_potential
            )
            
        except Exception as e:
            return FileAnalysisResult(
                filepath=str(filepath),
                lines_count=0,
                classes=[],
                imports_count=0,
                complexity_score=0,
                issues=[f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}"],
                recommendations=["–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏"],
                refactoring_priority=1,
                automation_potential=0.0
            )
            
    def _analyze_class(self, class_node: ast.ClassDef, lines: List[str]) -> ClassInfo:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞."""
        
        methods = []
        for node in class_node.body:
            if isinstance(node, ast.FunctionDef):
                method_info = self._analyze_method(node, lines)
                methods.append(method_info)
                
        # –ü–æ–¥—Å—á–µ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–µ–π
        responsibilities = set(m.responsibility_group for m in methods)
        responsibilities_count = len(responsibilities)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ God Object
        is_god_object = (len(methods) > 15 or 
                        responsibilities_count > 5 or
                        sum(m.complexity for m in methods) > 100)
        
        return ClassInfo(
            name=class_node.name,
            line_start=class_node.lineno,
            line_end=getattr(class_node, 'end_lineno', class_node.lineno + 10),
            methods=methods,
            responsibilities_count=responsibilities_count,
            is_god_object=is_god_object
        )
        
    def _analyze_method(self, method_node: ast.FunctionDef, lines: List[str]) -> MethodInfo:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞."""
        
        # –°–ª–æ–∂–Ω–æ—Å—Ç—å (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è)
        complexity = self._calculate_method_complexity(method_node)
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        parameters_count = len(method_node.args.args) - 1  # –ò—Å–∫–ª—é—á–∏—Ç—å self
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π
        calls_count = len([node for node in ast.walk(method_node) 
                          if isinstance(node, ast.Call)])
        
        # –ü—É–±–ª–∏—á–Ω—ã–π/–ø—Ä–∏–≤–∞—Ç–Ω—ã–π
        is_public = not method_node.name.startswith('_')
        
        # –ì—Ä—É–ø–ø–∞ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        responsibility_group = self._determine_responsibility(method_node.name)
        
        return MethodInfo(
            name=method_node.name,
            line_start=method_node.lineno,
            line_end=getattr(method_node, 'end_lineno', method_node.lineno + 5),
            complexity=complexity,
            parameters_count=parameters_count,
            calls_count=calls_count,
            is_public=is_public,
            responsibility_group=responsibility_group
        )
        
    def _calculate_method_complexity(self, method_node: ast.FunctionDef) -> int:
        """–†–∞—Å—á–µ—Ç —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–∞."""
        
        complexity = 1  # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        
        for node in ast.walk(method_node):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(node, ast.Try):
                complexity += len(node.handlers)
            elif isinstance(node, (ast.And, ast.Or)):
                complexity += 1
            elif isinstance(node, ast.ExceptHandler):
                complexity += 1
                
        return complexity
        
    def _determine_responsibility(self, method_name: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–∞."""
        
        method_lower = method_name.lower()
        
        for group, keywords in self.responsibility_keywords.items():
            if any(keyword in method_lower for keyword in keywords):
                return group
                
        return "other"
        
    def _identify_issues(self, lines_count: int, classes: List[ClassInfo], 
                        complexity_score: int) -> List[str]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º –≤ —Ñ–∞–π–ª–µ."""
        
        issues = []
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        if lines_count > 1000:
            issues.append(f"üî¥ –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª: {lines_count} —Å—Ç—Ä–æ–∫ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è <500)")
        elif lines_count > 500:
            issues.append(f"üü° –ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª: {lines_count} —Å—Ç—Ä–æ–∫ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è <500)")
            
        # –ü—Ä–æ–±–ª–µ–º—ã —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if complexity_score > 200:
            issues.append(f"üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {complexity_score} (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è <50)")
        elif complexity_score > 100:
            issues.append(f"üü° –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {complexity_score} (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è <50)")
            
        # –ü—Ä–æ–±–ª–µ–º—ã –∫–ª–∞—Å—Å–æ–≤
        god_objects = [cls for cls in classes if cls.is_god_object]
        if god_objects:
            for god_obj in god_objects:
                issues.append(f"üî¥ God Object: –∫–ª–∞—Å—Å '{god_obj.name}' –∏–º–µ–µ—Ç {god_obj.public_methods_count} –ø—É–±–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –∏ {god_obj.responsibilities_count} –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–µ–π")
                
        # –ü—Ä–æ–±–ª–µ–º—ã –º–µ—Ç–æ–¥–æ–≤
        complex_methods = []
        for cls in classes:
            for method in cls.methods:
                if method.complexity > 10:
                    complex_methods.append(f"{cls.name}.{method.name}")
                    
        if complex_methods:
            issues.append(f"üü° –°–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã ({len(complex_methods)}): {', '.join(complex_methods[:3])}{'...' if len(complex_methods) > 3 else ''}")
            
        return issues
        
    def _generate_recommendations(self, classes: List[ClassInfo], issues: List[str]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É."""
        
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è God Objects
        god_objects = [cls for cls in classes if cls.is_god_object]
        if god_objects:
            recommendations.append("üéØ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω 'Extract Method to Component Class' –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è God Objects")
            recommendations.append("üèóÔ∏è –°–æ–∑–¥–∞—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–µ–π")
            recommendations.append("üíâ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Constructor Injection –¥–ª—è —Å–≤—è–∑—ã–≤–∞–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
            
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞
        if any("–±–æ–ª—å—à–æ–π —Ñ–∞–π–ª" in issue.lower() for issue in issues):
            recommendations.append("üìÅ –†–∞–∑–¥–µ–ª–∏—Ç—å —Ñ–∞–π–ª –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥—É–ª–µ–π –ø–æ –¥–æ–º–µ–Ω–∞–º")
            recommendations.append("üîß –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω 'Split Monolithic Configuration'")
            
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if any("—Å–ª–æ–∂–Ω–æ—Å—Ç—å" in issue.lower() for issue in issues):
            recommendations.append("üé≠ –ò–∑–≤–ª–µ—á—å —Å–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
            recommendations.append("üîÑ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω Strategy –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è —É—Å–ª–æ–≤–Ω–æ–π –ª–æ–≥–∏–∫–∏")
            
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é
        if god_objects or any("—Å–ª–æ–∂–Ω–æ—Å—Ç—å" in issue.lower() for issue in issues):
            recommendations.append("üß™ –°–æ–∑–¥–∞—Ç—å unit —Ç–µ—Å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞")
            recommendations.append("üî¨ –ü—Ä–∏–º–µ–Ω–∏—Ç—å property-based —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
            
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
        automation_potential = self._calculate_automation_potential(classes, issues)
        if automation_potential > 0.7:
            recommendations.append(f"ü§ñ –í—ã—Å–æ–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ ({automation_potential:.1%}) - –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å auto_refactor.py")
        elif automation_potential > 0.4:
            recommendations.append(f"‚öôÔ∏è –°—Ä–µ–¥–Ω–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ ({automation_potential:.1%}) - —á–∞—Å—Ç–∏—á–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–∞")
            
        return recommendations
        
    def _calculate_priority(self, lines_count: int, classes: List[ClassInfo], issues_count: int) -> int:
        """–†–∞—Å—á–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ (1-10)."""
        
        priority = 1
        
        # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        if lines_count > 2000:
            priority += 3
        elif lines_count > 1000:
            priority += 2
        elif lines_count > 500:
            priority += 1
            
        # God Objects
        god_objects_count = len([cls for cls in classes if cls.is_god_object])
        priority += min(god_objects_count * 2, 4)
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º
        priority += min(issues_count, 3)
        
        return min(priority, 10)
        
    def _calculate_automation_potential(self, classes: List[ClassInfo], issues: List[str]) -> float:
        """–†–∞—Å—á–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ (0.0-1.0)."""
        
        potential = 0.0
        
        # God Objects –ª–µ–≥–∫–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å
        god_objects = [cls for cls in classes if cls.is_god_object]
        if god_objects:
            potential += 0.4
            
        # –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –º–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if any("–±–æ–ª—å—à–æ–π —Ñ–∞–π–ª" in issue.lower() for issue in issues):
            potential += 0.3
            
        # –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å —á–∞—Å—Ç–∏—á–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ–º–∞
        if any("—Å–ª–æ–∂–Ω–æ—Å—Ç—å" in issue.lower() for issue in issues):
            potential += 0.2
            
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ —Ö–æ—Ä–æ—à–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É—é—Ç—Å—è
        multi_responsibility_classes = [cls for cls in classes if cls.responsibilities_count > 3]
        if multi_responsibility_classes:
            potential += 0.3
            
        return min(potential, 1.0)
        
    def generate_detailed_report(self, result: FileAnalysisResult) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞."""
        
        report = f"""
# üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞

**–§–∞–π–ª**: `{result.filepath}`
**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üìä –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ | –°—Ç–∞—Ç—É—Å |
|---------|----------|--------|
| –°—Ç—Ä–æ–∫ –∫–æ–¥–∞ | {result.lines_count:,} | {'üî¥' if result.lines_count > 1000 else 'üü°' if result.lines_count > 500 else 'üü¢'} |
| –ö–ª–∞—Å—Å–æ–≤ | {len(result.classes)} | {'üî¥' if len(result.classes) > 5 else 'üü¢'} |
| –ò–º–ø–æ—Ä—Ç–æ–≤ | {result.imports_count} | {'üü°' if result.imports_count > 20 else 'üü¢'} |
| –°–ª–æ–∂–Ω–æ—Å—Ç—å | {result.complexity_score} | {'üî¥' if result.complexity_score > 200 else 'üü°' if result.complexity_score > 100 else 'üü¢'} |
| –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ | {result.refactoring_priority}/10 | {'üî¥' if result.refactoring_priority > 7 else 'üü°' if result.refactoring_priority > 4 else 'üü¢'} |
| –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ | {result.automation_potential:.1%} | {'üü¢' if result.automation_potential > 0.7 else 'üü°' if result.automation_potential > 0.4 else 'üî¥'} |

## üéØ –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Å–æ–≤

"""
        
        for cls in result.classes:
            status = "üî¥ God Object" if cls.is_god_object else "üü¢ –ù–æ—Ä–º–∞–ª—å–Ω—ã–π"
            
            report += f"""
### `{cls.name}` {status}

- **–°—Ç—Ä–æ–∫–∏**: {cls.line_start}-{cls.line_end}
- **–ú–µ—Ç–æ–¥–æ–≤**: {len(cls.methods)} (–ø—É–±–ª–∏—á–Ω—ã—Ö: {cls.public_methods_count})
- **–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–µ–π**: {cls.responsibilities_count}
- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: {cls.total_complexity}

**–ì—Ä—É–ø–ø—ã –º–µ—Ç–æ–¥–æ–≤ –ø–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—è–º**:
"""
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –º–µ—Ç–æ–¥–æ–≤ –ø–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—è–º
            responsibility_groups = defaultdict(list)
            for method in cls.methods:
                responsibility_groups[method.responsibility_group].append(method)
                
            for group, methods in responsibility_groups.items():
                report += f"- **{group.title()}**: {len(methods)} –º–µ—Ç–æ–¥–æ–≤\n"
                
        report += f"""

## ‚ö†Ô∏è –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

"""
        
        for issue in result.issues:
            report += f"- {issue}\n"
            
        report += f"""

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥—É

"""
        
        for rec in result.recommendations:
            report += f"- {rec}\n"
            
        # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π
        if result.refactoring_priority > 6:
            report += f"""

## üöÄ –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)

### –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
1. –°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞
2. –£–±–µ–¥–∏—Ç—å—Å—è –≤ –Ω–∞–ª–∏—á–∏–∏ —Ç–µ—Å—Ç–æ–≤ (–µ—Å–ª–∏ –Ω–µ—Ç - —Å–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–µ)
3. –ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ git

### –≠—Ç–∞–ø 2: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥
```bash
# –ê–Ω–∞–ª–∏–∑ –∏ –ø–ª–∞–Ω
python auto_refactor.py "{result.filepath}" --dry-run

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ (–µ—Å–ª–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ > 70%)
python auto_refactor.py "{result.filepath}"
```

### –≠—Ç–∞–ø 3: –†—É—á–Ω–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞
1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤
2. –î–æ–±–∞–≤–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å DI –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
4. –°–æ–∑–¥–∞—Ç—å comprehensive —Ç–µ—Å—Ç—ã

### –≠—Ç–∞–ø 4: –í–∞–ª–∏–¥–∞—Ü–∏—è
1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–µ—Å—Ç—ã
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
3. –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
"""
        
        report += f"""

---
*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ AST –∞–Ω–∞–ª–∏–∑–∞ –∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞*
"""
        
        return report


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è CLI."""
    import argparse
    from datetime import datetime
    
    parser = argparse.ArgumentParser(description="–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞")
    parser.add_argument("file", help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    parser.add_argument("--output", "-o", help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞")
    parser.add_argument("--json", action="store_true", help="–í—ã–≤–æ–¥ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ")
    
    args = parser.parse_args()
    
    filepath = Path(args.file)
    if not filepath.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
        return
        
    print(f"üîç –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {filepath}")
    
    analyzer = FileAnalyzer()
    result = analyzer.analyze_file(filepath)
    
    if args.json:
        # JSON –≤—ã–≤–æ–¥ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        import json
        from dataclasses import asdict
        output = asdict(result)
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(output, f, indent=2, ensure_ascii=False)
        else:
            print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        # –ß–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–π –æ—Ç—á–µ—Ç
        report = analyzer.generate_detailed_report(result)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {args.output}")
        else:
            print(report)
            
    # –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
    print(f"\nüìä –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞:")
    print(f"   üìè –†–∞–∑–º–µ—Ä: {result.lines_count:,} —Å—Ç—Ä–æ–∫")
    print(f"   üèóÔ∏è –ö–ª–∞—Å—Å–æ–≤: {len(result.classes)}")
    print(f"   üî• –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {result.refactoring_priority}/10")
    print(f"   ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è: {result.automation_potential:.1%}")
    
    if result.refactoring_priority > 6:
        print(f"\nüö® –í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢ –†–ï–§–ê–ö–¢–û–†–ò–ù–ì–ê!")
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ")


if __name__ == "__main__":
    main()