"""Rule effectiveness reporting for monitoring system."""

import logging
from datetime import datetime
from typing import Dict, Any

logger = logging.getLogger(__name__)


def generate_rule_effectiveness_report(
    effectiveness_reporter,
    knowledge_accumulator,
    export_json: bool = True,
    export_visualization: bool = True,
) -> Dict[str, Any]:
    """
    Task 8.3: Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð¾Ð² Ð¾Ð± ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð°Ð²Ð¸Ð».

    Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ñƒ, ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð² JSON Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ
    Ð¸ ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ñ‚Ð¾Ð¿ Ð¿Ñ€Ð°Ð²Ð¸Ð» Ð¿Ð¾ success_rate.

    Args:
        effectiveness_reporter: EffectivenessReporter instance
        knowledge_accumulator: KnowledgeAccumulator instance
        export_json: Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ JSON Ð¾Ñ‚Ñ‡ÐµÑ‚
        export_visualization: Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²ÑƒÑŽ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ

    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
    """
    if not effectiveness_reporter:
        logger.warning("Effectiveness reporter not available")
        return {"error": "Effectiveness reporter not available"}

    if not knowledge_accumulator:
        logger.warning("Knowledge accumulator not provided")
        return {"error": "Knowledge accumulator not provided"}

    try:
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚
        created_files = effectiveness_reporter.generate_comprehensive_report(
            knowledge_accumulator,
            export_json=export_json,
            export_visualization=export_visualization,
        )

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð´Ð»Ñ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚Ð°
        report = effectiveness_reporter.generate_effectiveness_report(knowledge_accumulator)

        result = {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "created_files": created_files,
            "summary": {
                "total_rules": report.total_rules,
                "active_rules": report.active_rules,
                "high_performance_rules": report.high_performance_rules,
                "top_success_rate": (
                    report.top_rules_by_success_rate[0].success_rate
                    if report.top_rules_by_success_rate
                    else 0.0
                ),
                "recommendations_count": len(report.recommendations),
            },
            "top_rules_preview": [
                {
                    "rule_id": rule.rule_id,
                    "success_rate": rule.success_rate,
                    "total_applications": rule.total_applications,
                    "unique_domains": rule.unique_domains_count,
                }
                for rule in report.top_rules_by_success_rate[:5]
            ],
        }

        logger.info(
            f"ðŸ“Š Rule effectiveness report generated: "
            f"{report.total_rules} rules analyzed, "
            f"{len(created_files)} files created"
        )

        return result

    except Exception as e:
        logger.error(f"Error generating rule effectiveness report: {e}")
        return {"error": str(e), "success": False}


def get_rule_effectiveness_summary(
    effectiveness_reporter,
    knowledge_accumulator,
) -> Dict[str, Any]:
    """
    Task 8.3: ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ð¹ ÑÐ²Ð¾Ð´ÐºÐ¸ Ð¾Ð± ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð°Ð²Ð¸Ð».

    Args:
        effectiveness_reporter: EffectivenessReporter instance
        knowledge_accumulator: KnowledgeAccumulator instance

    Returns:
        Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ Ñ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ð¹ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¾Ð¹ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸
    """
    if not effectiveness_reporter or not knowledge_accumulator:
        return {}

    try:
        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°
        rule_stats = effectiveness_reporter.analyze_rule_effectiveness(knowledge_accumulator)

        if not rule_stats:
            return {"total_rules": 0, "message": "No rules found"}

        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        active_rules = [r for r in rule_stats if r.total_applications > 0]
        high_performance_rules = [r for r in active_rules if r.success_rate > 0.8]

        # Ð¢Ð¾Ð¿ 3 Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ð¿Ð¾ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸
        top_rules = sorted(active_rules, key=lambda x: x.success_rate, reverse=True)[:3]

        # Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ
        avg_success_rate = 0.0
        if active_rules:
            avg_success_rate = sum(r.success_rate for r in active_rules) / len(active_rules)

        return {
            "total_rules": len(rule_stats),
            "active_rules": len(active_rules),
            "high_performance_rules": len(high_performance_rules),
            "average_success_rate": avg_success_rate,
            "top_rules": [
                {
                    "rule_id": rule.rule_id,
                    "success_rate": rule.success_rate,
                    "applications": rule.total_applications,
                }
                for rule in top_rules
            ],
            "performance_distribution": {
                "excellent": len([r for r in active_rules if r.success_rate > 0.9]),
                "good": len([r for r in active_rules if 0.7 < r.success_rate <= 0.9]),
                "fair": len([r for r in active_rules if 0.5 < r.success_rate <= 0.7]),
                "poor": len([r for r in active_rules if r.success_rate <= 0.5]),
            },
        }

    except Exception as e:
        logger.error(f"Error getting rule effectiveness summary: {e}")
        return {"error": str(e)}
