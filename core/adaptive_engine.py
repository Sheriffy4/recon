"""
AdaptiveEngine - –≥–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—Ö–æ–¥–∞ DPI.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Ä–µ–∞–ª–∏–∑—É–µ—Ç –µ–¥–∏–Ω—É—é —Ç–æ—á–∫—É –≤—Ö–æ–¥–∞ –¥–ª—è –≤—Å–µ–π –ª–æ–≥–∏–∫–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ–±—Ö–æ–¥–∞,
–∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É—è —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º FR-1, FR-2, FR-3.
"""

import asyncio
import json
import logging
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime
import concurrent.futures
from functools import lru_cache
import threading
import hashlib
import pickle
import subprocess
from enum import Enum

# –°–ø–∏—Å–æ–∫ —à–∏—Ñ—Ä–æ–≤ –¥–ª—è —ç–º—É–ª—è—Ü–∏–∏ Chrome –∏ —Ä–∞–∑–¥—É–≤–∞–Ω–∏—è ClientHello –¥–æ ~1400 –±–∞–π—Ç
BROWSER_CIPHER_LIST = (
    "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:"
    "ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:"
    "ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:"
    "ECDHE-RSA-AES128-SHA:ECDHE-RSA-AES256-SHA:AES128-GCM-SHA256:"
    "AES256-GCM-SHA384:AES128-SHA:AES256-SHA:DES-CBC3-SHA:"
    "TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:"
    "ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:"
    "ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:"
    "DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:"
    "DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:"
    "DHE-RSA-AES256-SHA256:EDH-RSA-DES-CBC3-SHA"
)

# Define enums first to avoid import issues
class LogLevel(Enum):
    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class LogCategory(Enum):
    SYSTEM = "system"
    STRATEGY_TEST = "strategy_test"
    DPI_ANALYSIS = "dpi_analysis"
    FINGERPRINTING = "fingerprinting"
    PERFORMANCE = "performance"
    VALIDATION = "validation"
    ENGINE_OPERATION = "engine_operation"
    NETWORK = "network"
    ERROR_ANALYSIS = "error_analysis"

class LogContext:
    def __init__(self, **kwargs):
        for key, value in kwargs.items():
            setattr(self, key, value)


try:
    from core.bypass.filtering.feature_flags import FeatureFlagManager as FeatureFlags
except ImportError:
    FeatureFlags = None

try:
    from pcap_to_json_analyzer import analyze_pcap as analyze_pcap_json
    PCAP_JSON_AVAILABLE = True
except ImportError:
    analyze_pcap_json = None
    PCAP_JSON_AVAILABLE = False

# Task 7.1: Import TestResultCoordinator for test result management
try:
    from core.test_result_coordinator import TestResultCoordinator
    from core.pcap.analyzer import PCAPAnalyzer
    from core.validation.strategy_validator import StrategyValidator as ValidationStrategyValidator
    from core.validation.strategy_saver import StrategySaver
    TEST_RESULT_COORDINATOR_AVAILABLE = True
except ImportError as e:
    logging.warning(f"TestResultCoordinator components not available: {e}")
    TestResultCoordinator = None
    PCAPAnalyzer = None
    ValidationStrategyValidator = None
    StrategySaver = None
    TEST_RESULT_COORDINATOR_AVAILABLE = False
# Task 7.4: Import diagnostics modules
try:
    from core.diagnostics.structured_logger import (
        get_structured_logger
    )
    from core.diagnostics.performance_monitor import get_performance_monitor
    DIAGNOSTICS_AVAILABLE = True
    # Use string-based approach to avoid enum conflicts
    pass
except ImportError:
    DIAGNOSTICS_AVAILABLE = False
    logging.warning("Diagnostics modules not available")
    get_structured_logger = None
    get_performance_monitor = None

# Task 8.1: Import closed-loop metrics
try:
    from core.metrics.closed_loop_metrics import (
        get_closed_loop_metrics_collector,
        ClosedLoopMetricsCollector
    )
    CLOSED_LOOP_METRICS_AVAILABLE = True
except ImportError:
    CLOSED_LOOP_METRICS_AVAILABLE = False
    logging.warning("Closed-loop metrics not available")
    get_closed_loop_metrics_collector = None

# Auto-strategy-discovery: Import ConnectionMetrics
try:
    from core.connection_metrics import ConnectionMetrics, BlockType
    CONNECTION_METRICS_AVAILABLE = True
except ImportError:
    CONNECTION_METRICS_AVAILABLE = False
    logging.warning("ConnectionMetrics not available")
    ConnectionMetrics = None
    BlockType = None

# Task 3.3: Import StrategyEvaluator for centralized success/failure evaluation
try:
    from core.strategy_evaluator import StrategyEvaluator, EvaluationResult
    STRATEGY_EVALUATOR_AVAILABLE = True
except ImportError:
    STRATEGY_EVALUATOR_AVAILABLE = False
    logging.warning("StrategyEvaluator not available")
    StrategyEvaluator = None
    EvaluationResult = None
    ClosedLoopMetricsCollector = None

# Task 18: Import adaptive strategy adjuster
try:
    from core.adaptive_strategy_adjuster import AdaptiveStrategyAdjuster
    ADAPTIVE_STRATEGY_ADJUSTER_AVAILABLE = True
except ImportError:
    ADAPTIVE_STRATEGY_ADJUSTER_AVAILABLE = False
    logging.warning("Adaptive strategy adjuster not available")
    AdaptiveStrategyAdjuster = None

# –ò–º–ø–æ—Ä—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
try:
    from core.strategy_failure_analyzer import (
        StrategyFailureAnalyzer, 
        FailureReport, 
        Strategy, 
        TestResult, 
        TrialArtifacts
    )
    from core.fingerprint.dpi_fingerprint_service import (
        DPIFingerprintService, 
        DPIFingerprint
    )
    from core.strategy.strategy_intent_engine import (
        StrategyIntentEngine, 
        StrategyIntent
    )
    from core.strategy.strategy_generator import (
        StrategyGenerator, 
        GeneratedStrategy
    )
    COMPONENTS_AVAILABLE = True
except ImportError as e:
    logging.warning(f"Some adaptive components not available: {e}")
    COMPONENTS_AVAILABLE = False
    StrategyFailureAnalyzer = None
    FailureReport = None
    Strategy = None
    TestResult = None
    TrialArtifacts = None
    DPIFingerprintService = None
    DPIFingerprint = None
    StrategyIntentEngine = None
    StrategyIntent = None
    StrategyGenerator = None
    GeneratedStrategy = None

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–æ–¥—É–ª—è–º–∏ –ø—Ä–æ–µ–∫—Ç–∞
try:
    from core.unified_bypass_engine import UnifiedBypassEngine
    from core.bypass.engine.attack_dispatcher import AttackDispatcher
    from core.bypass.attacks.attack_registry import get_attack_registry
    # Task 7.3: Import capture-enabled bypass engine wrapper
    from core.pcap.bypass_engine_integration import WindowsBypassEngineWithCapture
    ENGINE_AVAILABLE = True
except ImportError as e:
    logging.warning(f"Bypass engine components not available: {e}")
    ENGINE_AVAILABLE = False
    UnifiedBypassEngine = None
    AttackDispatcher = None
    get_attack_registry = None
    WindowsBypassEngineWithCapture = None

LOG = logging.getLogger("AdaptiveEngine")


@dataclass
class StrategyResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
    success: bool
    strategy: Optional[Any] = None
    message: str = ""
    execution_time: float = 0.0
    trials_count: int = 0
    fingerprint_updated: bool = False
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AdaptiveConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –¥–≤–∏–∂–∫–∞"""
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    max_trials: int = 15
    stop_on_success: bool = True
    enable_fingerprinting: bool = True
    enable_failure_analysis: bool = True
    
    # –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö
    fingerprints_file: str = "dpi_fingerprints.json"
    strategies_file: str = "best_strategies.json"
    negative_knowledge_file: str = "negative_knowledge.json"
    protocol_preferences_file: str = "protocol_preferences.json"
    
    # –¢–∞–π–º–∞—É—Ç—ã
    strategy_timeout: float = 30.0
    connection_timeout: float = 5.0
    
    # Dual-stack –∏ —Å–µ—Ç–µ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    enable_ipv6_fallback: bool = True
    prefer_ipv4: bool = True  # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞—Ç—å IPv4 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    timeout_factor_content_inspection: float = 2.0  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å —Ç–∞–π–º–∞—É—Ç–∞ –¥–ª—è DPI_CONTENT_INSPECTION
    timeout_factor_slow_cdn: float = 1.5  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö CDN
    
    # –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã
    mode: str = "comprehensive"  # quick, balanced, comprehensive
    
    # –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    enable_caching: bool = True
    cache_ttl_hours: int = 24
    enable_parallel_testing: bool = False  # –û–¢–ö–õ–Æ–ß–ï–ù–û: DPI —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—Ç –∑–∞ —Å–µ—Ç–µ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã
    max_parallel_workers: int = 5  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–º–µ–Ω–æ–≤
    enable_profiling: bool = False
    fingerprint_cache_size: int = 1000
    strategy_cache_size: int = 500
    
    # Task 11.1: Verification mode parameters
    verify_with_pcap: bool = False  # Enable verification mode with extended PCAP capture
    
    # Task 12.2: Batch mode parameters (Requirement 6.1, 6.2)
    batch_mode: bool = False  # Enable batch mode - saves only to adaptive_knowledge.json, not domain_rules.json
    
    # Task 7.1: Test result coordinator feature flag (Requirement 9.2)
    use_test_result_coordinator: bool = True  # Enable TestResultCoordinator for consistent test verdicts
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "AdaptiveConfig":
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        return cls(**{k: v for k, v in data.items() if hasattr(cls, k)})


class AdaptiveEngine:
    """
    –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—Ö–æ–¥–∞ DPI.
    
    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:
    - Strategy Failure Analyzer (SFA)
    - DPI Fingerprint Service (DFS) 
    - Strategy Intent Engine (SIE)
    - Strategy Generator (SG)
    - Enhanced Strategy Calibrator
    """
    
    def __init__(self, config: Optional[AdaptiveConfig] = None):
        self.config = config or AdaptiveConfig()
        
        # === –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: –ì–ª–æ–±–∞–ª—å–Ω—ã–π lock –¥–ª—è WinDivert ===
        self._divert_lock = threading.RLock()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–µ–π –∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ –ü–ï–†–ï–î –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._fingerprint_cache = {}
        self._strategy_cache = {}
        self._domain_accessibility_cache = {}
        self._protocol_preference_cache = {}  # –ö—ç—à –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ IPv4/IPv6
        self._cache_lock = threading.RLock()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._init_components()
        
        # Initialize feature flags
        self._feature_flags = None
        try:
            if FeatureFlags is None:
                LOG.warning("‚ö†Ô∏è FeatureFlags class not imported, trying direct import")
                from core.feature_flags import FeatureFlags as FF
                self._feature_flags = FF()
            else:
                self._feature_flags = FeatureFlags()
            LOG.info("‚úÖ Feature flags initialized successfully")
        except Exception as e:
            LOG.error(f"‚ùå Could not initialize feature flags: {e}")
            import traceback
            LOG.error(traceback.format_exc())
        
        # –ù–û–í–û–ï: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è
        try:
            from core.knowledge.knowledge_accumulator import KnowledgeAccumulator
            from core.knowledge.pattern_matcher import PatternMatcher
            
            self.knowledge_accumulator = KnowledgeAccumulator()
            self.pattern_matcher = PatternMatcher(self.knowledge_accumulator)
            
            LOG.info("‚úÖ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        except ImportError as e:
            LOG.warning(f"‚ö†Ô∏è –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {e}")
            self.knowledge_accumulator = None
            self.pattern_matcher = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
        self.stats = {
            "domains_processed": 0,
            "strategies_found": 0,
            "total_trials": 0,
            "fingerprints_created": 0,
            "failures_analyzed": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "parallel_tests_executed": 0,
            "average_test_time": 0.0,
            "fingerprint_creation_time": 0.0,
            "strategy_generation_time": 0.0
        }
        
        # –ù–û–í–û–ï: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è
        self.closed_loop_stats = {
            "iterations_total": 0,
            "intents_generated": 0,
            "strategies_augmented": 0,
            "pattern_matches": 0,
            "knowledge_updates": 0
        }
        
        # –ù–û–í–û–ï: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö —Ç–∞–π–º–∞—É—Ç–æ–≤
        self.timeout_stats = {
            "adaptive_timeouts_applied": 0,
            "content_inspection_adjustments": 0,
            "rst_injection_adjustments": 0,
            "network_timeout_adjustments": 0,
            "slow_cdn_adjustments": 0,
            "average_timeout_factor": 1.0
        }
        
        # Task 8.1: Initialize closed-loop metrics collector
        self.metrics_collector = None
        if CLOSED_LOOP_METRICS_AVAILABLE and get_closed_loop_metrics_collector:
            try:
                self.metrics_collector = get_closed_loop_metrics_collector()
                LOG.info("‚úÖ –ö–æ–ª–ª–µ–∫—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫: {e}")
                self.metrics_collector = None
        else:
            LOG.warning("‚ö†Ô∏è –ö–æ–ª–ª–µ–∫—Ç–æ—Ä –º–µ—Ç—Ä–∏–∫ –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # Task 18: Initialize adaptive strategy adjuster
        self.strategy_adjuster = None
        if ADAPTIVE_STRATEGY_ADJUSTER_AVAILABLE and AdaptiveStrategyAdjuster:
            try:
                self.strategy_adjuster = AdaptiveStrategyAdjuster()
                LOG.info("[OK] Adaptive strategy adjuster initialized")
            except Exception as e:
                LOG.warning(f"Failed to initialize adaptive strategy adjuster: {e}")
                self.strategy_adjuster = None
        else:
            LOG.warning("Adaptive strategy adjuster not available")
        
        # Task 3.3: Initialize StrategyEvaluator for centralized success/failure evaluation
        self.strategy_evaluator = None
        if STRATEGY_EVALUATOR_AVAILABLE and StrategyEvaluator:
            try:
                self.strategy_evaluator = StrategyEvaluator()
                LOG.info("‚úÖ StrategyEvaluator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
            except Exception as e:
                LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ StrategyEvaluator: {e}")
                self.strategy_evaluator = None
        else:
            LOG.warning("‚ö†Ô∏è StrategyEvaluator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # Task 5.4: Initialize AdaptiveKnowledgeBase for automatic strategy discovery
        self.adaptive_knowledge = None
        try:
            from core.adaptive_knowledge import AdaptiveKnowledgeBase
            self.adaptive_knowledge = AdaptiveKnowledgeBase()
            LOG.info("‚úÖ AdaptiveKnowledgeBase –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
        except Exception as e:
            LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AdaptiveKnowledgeBase: {e}")
            self.adaptive_knowledge = None
        
        # Task 11.5: Initialize StrategyValidator for verification mode
        self.strategy_validator = None
        try:
            from core.strategy_validator import StrategyValidator
            self.strategy_validator = StrategyValidator()
            LOG.info("‚úÖ StrategyValidator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞")
        except Exception as e:
            LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ StrategyValidator: {e}")
            self.strategy_validator = None
        
        # Task 7.1: Initialize TestResultCoordinator for consistent test verdicts (Requirement 9.2)
        self.test_result_coordinator = None
        if self.config.use_test_result_coordinator and TEST_RESULT_COORDINATOR_AVAILABLE:
            try:
                # Initialize dependencies
                pcap_analyzer = PCAPAnalyzer() if PCAPAnalyzer else None
                validation_strategy_validator = ValidationStrategyValidator() if ValidationStrategyValidator else None
                
                # Initialize coordinator
                self.test_result_coordinator = TestResultCoordinator(
                    pcap_analyzer=pcap_analyzer,
                    strategy_validator=validation_strategy_validator
                )
                LOG.info("‚úÖ TestResultCoordinator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç–µ—Å—Ç–æ–≤")
                LOG.info(f"   PCAP Analyzer: {'Available' if pcap_analyzer else 'Not Available'}")
                LOG.info(f"   Strategy Validator: {'Available' if validation_strategy_validator else 'Not Available'}")
            except Exception as e:
                LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TestResultCoordinator: {e}")
                self.test_result_coordinator = None
        else:
            if not self.config.use_test_result_coordinator:
                LOG.info("‚ÑπÔ∏è TestResultCoordinator –æ—Ç–∫–ª—é—á–µ–Ω —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é")
            else:
                LOG.warning("‚ö†Ô∏è TestResultCoordinator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # Task 7.1: Initialize StrategySaver for deduplication (Requirement 5.4, 5.5)
        self.strategy_saver = None
        if self.config.use_test_result_coordinator and TEST_RESULT_COORDINATOR_AVAILABLE and StrategySaver:
            try:
                self.strategy_saver = StrategySaver()
                LOG.info("‚úÖ StrategySaver –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π")
            except Exception as e:
                LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ StrategySaver: {e}")
                self.strategy_saver = None

        
        # –ü—É–ª –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if self.config.enable_parallel_testing:
            self._executor = concurrent.futures.ThreadPoolExecutor(
                max_workers=self.config.max_parallel_workers
            )
        else:
            self._executor = None
        
        # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
        self._profiling_data = {}
        self._profiling_lock = threading.RLock()
        self._avg_augmentation_time = 0.0
        self._augmentation_count = 0
        
        # Task 7.4: Initialize diagnostics
        self.structured_logger = None
        self.performance_monitor = None
        if DIAGNOSTICS_AVAILABLE and get_structured_logger and get_performance_monitor:
            try:
                self.structured_logger = get_structured_logger()
                self.performance_monitor = get_performance_monitor()
                LOG.info("Diagnostics modules initialized successfully")
            except Exception as e:
                LOG.warning(f"Failed to initialize diagnostics: {e}")
        
        LOG.info(f"AdaptiveEngine initialized with caching={'enabled' if self.config.enable_caching else 'disabled'}, "
                f"parallel_testing={'enabled' if self.config.enable_parallel_testing else 'disabled'}")
    
    def _get_strategy_name(self, strategy: Any) -> str:
        """
        Extract strategy name from strategy object.
        
        Args:
            strategy: Strategy object (can be dict, object, or string)
            
        Returns:
            Strategy name as string
        """
        if isinstance(strategy, str):
            return strategy
        elif isinstance(strategy, dict):
            return strategy.get('name', strategy.get('attack_name', 'unknown'))
        elif hasattr(strategy, 'name'):
            return strategy.name
        elif hasattr(strategy, 'attack_name'):
            return strategy.attack_name
        else:
            return 'unknown'
    
    def _record_profiling_data(self, operation: str, execution_time: float):
        """
        –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
        
        Args:
            operation: –ù–∞–∑–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            execution_time: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        if not self.config.enable_profiling:
            return
        
        with self._profiling_lock:
            if operation not in self._profiling_data:
                self._profiling_data[operation] = {
                    "total_time": 0.0,
                    "call_count": 0,
                    "min_time": float('inf'),
                    "max_time": 0.0,
                    "avg_time": 0.0
                }
            
            data = self._profiling_data[operation]
            data["total_time"] += execution_time
            data["call_count"] += 1
            data["min_time"] = min(data["min_time"], execution_time)
            data["max_time"] = max(data["max_time"], execution_time)
            data["avg_time"] = data["total_time"] / data["call_count"]
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            if execution_time > 1.0:  # –û–ø–µ—Ä–∞—Ü–∏–∏ –¥–æ–ª—å—à–µ 1 —Å–µ–∫—É–Ω–¥—ã
                LOG.warning(f"‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è {operation}: {execution_time:.3f}s "
                           f"(—Å—Ä–µ–¥–Ω–µ–µ: {data['avg_time']:.3f}s)")
    
    def _update_average_augmentation_time(self, execution_time: float):
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ augmentation –¥–ª—è –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
        
        Args:
            execution_time: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è augmentation –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        with self._profiling_lock:
            self._augmentation_count += 1
            self._avg_augmentation_time = (
                (self._avg_augmentation_time * (self._augmentation_count - 1) + execution_time) /
                self._augmentation_count
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if self._avg_augmentation_time > 0.2:  # 200ms –ª–∏–º–∏—Ç
                LOG.warning(f"‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è augmentation –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç: "
                           f"{self._avg_augmentation_time:.3f}s > 0.200s")
    
    def get_profiling_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        with self._profiling_lock:
            stats = {
                "profiling_enabled": self.config.enable_profiling,
                "avg_augmentation_time_ms": self._avg_augmentation_time * 1000,
                "augmentation_count": self._augmentation_count,
                "performance_requirements": {
                    "avg_augmentation_time_limit_ms": 200,
                    "meets_requirements": self._avg_augmentation_time <= 0.2
                },
                "operations": {}
            }
            
            for operation, data in self._profiling_data.items():
                stats["operations"][operation] = {
                    "avg_time_ms": data["avg_time"] * 1000,
                    "min_time_ms": data["min_time"] * 1000,
                    "max_time_ms": data["max_time"] * 1000,
                    "total_time_ms": data["total_time"] * 1000,
                    "call_count": data["call_count"],
                    "total_time_percentage": (data["total_time"] / 
                                            sum(op["total_time"] for op in self._profiling_data.values())) * 100
                }
            
            return stats
    
    def optimize_hot_paths(self):
        """
        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–æ—Ä—è—á–∏—Ö –ø—É—Ç–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è.
        
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        –¥–ª—è –Ω–∞–∏–±–æ–ª–µ–µ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.
        """
        if not self.config.enable_profiling or not self._profiling_data:
            LOG.info("–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ –∏–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
            return
        
        with self._profiling_lock:
            # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
            slow_operations = []
            for operation, data in self._profiling_data.items():
                if data["avg_time"] > 0.1:  # –û–ø–µ—Ä–∞—Ü–∏–∏ –º–µ–¥–ª–µ–Ω–Ω–µ–µ 100ms
                    slow_operations.append((operation, data["avg_time"]))
            
            slow_operations.sort(key=lambda x: x[1], reverse=True)
            
            if slow_operations:
                LOG.info(f"üîß –ù–∞–π–¥–µ–Ω–æ {len(slow_operations)} –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
                
                for operation, avg_time in slow_operations[:5]:  # –¢–æ–ø 5
                    LOG.info(f"   - {operation}: {avg_time:.3f}s")
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                    if operation == "pattern_matching":
                        self._optimize_pattern_matching()
                    elif operation == "pcap_analysis":
                        self._optimize_pcap_analysis()
                    elif operation == "strategy_generation":
                        self._optimize_strategy_generation()
            else:
                LOG.info("‚úÖ –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã")
    
    def _optimize_pattern_matching(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."""
        if self.pattern_matcher:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞ –¥–ª—è Pattern Matcher
            LOG.info("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Pattern Matcher: —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫—ç—à–∞")
            # –ö—ç—à —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ PatternMatcher
    
    def _optimize_pcap_analysis(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ PCAP."""
        LOG.info("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è PCAP –∞–Ω–∞–ª–∏–∑–∞: —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–µ –º–µ—Ç–æ–¥—ã")
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è SFA
    
    def _optimize_strategy_generation(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π."""
        LOG.info("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
        # –ú–æ–∂–Ω–æ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —É–º–µ–Ω—å—à–∏—Ç—å max_strategies –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    
    def _test_strategy(self, target_ip: str, strategy_input, domain: Optional[str], timeout: float,
                      verification_mode: bool = False, enable_capture: bool = True) -> Dict[str, Any]:  # Requirement 1.2: Add enable_capture
        """
        Test strategy using the appropriate method based on feature flags.
        
        This method automatically selects between:
        - Service-based testing (like zapret) - NEW, more reliable
        - Inline testing (current approach) - OLD, has issues
        
        Args:
            target_ip: Target IP address
            strategy_input: Strategy configuration
            domain: Domain name
            timeout: Timeout in seconds
            verification_mode: Enable extended PCAP capture for verification (Task 11.2)
            enable_capture: Enable individual PCAP capture (Requirement 1.2: False when using shared PCAP)
            
        Returns:
            Dict with test results
        """
        # Check if service-based testing is enabled
        use_service_based = False
        if self._feature_flags:
            try:
                use_service_based = self._feature_flags.is_enabled('service_based_testing')
                LOG.info(f"üîç Service-based testing flag: {use_service_based}")
            except Exception as e:
                LOG.warning(f"Could not check service_based_testing flag: {e}")
        else:
            LOG.warning("‚ö†Ô∏è Feature flags not available, defaulting to inline testing")
        
        # Check method availability
        has_service_method = hasattr(self.bypass_engine, 'test_strategy_as_service')
        has_inline_method = hasattr(self.bypass_engine, 'test_strategy_like_testing_mode')
        LOG.info(f"üîç Available methods: service={has_service_method}, inline={has_inline_method}")
        
        # Select testing method
        if use_service_based and has_service_method:
            LOG.info("‚úÖ Using service-based testing (zapret-style)")
            return self.bypass_engine.test_strategy_as_service(
                target_ip=target_ip,
                strategy_input=strategy_input,
                domain=domain,
                timeout=timeout,
                verification_mode=verification_mode,  # Task 11.2: Pass verification_mode
                enable_capture=enable_capture  # Requirement 1.2: Pass enable_capture
            )
        elif has_inline_method:
            LOG.info("‚ö†Ô∏è Using inline testing (legacy)")
            return self.bypass_engine.test_strategy_like_testing_mode(
                target_ip=target_ip,
                strategy_input=strategy_input,
                domain=domain,
                timeout=timeout,
                verification_mode=verification_mode  # Task 11.2: Pass verification_mode
            )
        else:
            LOG.error("‚ùå No testing method available!")
            return {
                "success": False,
                "error": "No testing method available",
                "target_ip": target_ip,
                "domain": domain
            }
    
    def _init_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        if not COMPONENTS_AVAILABLE:
            raise ImportError("Required adaptive components not available")
        
        # Task 6.2: Initialize DoHIntegration for unified DNS resolution
        try:
            from core.dns.doh_integration import DoHIntegration
            self.doh_integration = DoHIntegration.from_config_file("config/doh_config.json")
            LOG.info("‚úÖ DoHIntegration initialized for adaptive engine")
            LOG.info(f"   DoH enabled: {self.doh_integration.enable_doh}")
            LOG.info(f"   Auto-detect blocking: {self.doh_integration.auto_detect_blocking}")
        except Exception as e:
            LOG.warning(f"‚ö†Ô∏è DoHIntegration not available: {e}, using direct DoHResolver")
            self.doh_integration = None
        
        # === –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: UnifiedStrategyLoader ===
        # Task 6.1: Use StrategyManager instead of UnifiedStrategyLoader (which doesn't exist)
        try:
            from core.strategy_manager import StrategyManager
            self._strategy_manager = StrategyManager()
            LOG.info("‚úÖ StrategyManager initialized for strategy persistence")
        except Exception as e:
            LOG.warning(f"‚ö†Ô∏è StrategyManager not available: {e}")
            self._strategy_manager = None
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if StrategyFailureAnalyzer:
            self.failure_analyzer = StrategyFailureAnalyzer()
        if DPIFingerprintService:
            self.fingerprint_service = DPIFingerprintService(
                cache_file=self.config.fingerprints_file
            )
        if StrategyIntentEngine:
            self.intent_engine = StrategyIntentEngine()
        if StrategyGenerator:
            self.strategy_generator = StrategyGenerator()
        
        # === –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: UnifiedBypassEngine —Å –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π ===
        if ENGINE_AVAILABLE and UnifiedBypassEngine:
            try:
                from core.unified_bypass_engine import UnifiedEngineConfig
                
                engine_config = UnifiedEngineConfig(
                    debug=True,
                    force_override=True,
                    enable_diagnostics=True,
                    log_all_strategies=True,
                    track_forced_override=True
                )
                
                if WindowsBypassEngineWithCapture:
                    self.bypass_engine = WindowsBypassEngineWithCapture(
                        UnifiedBypassEngine(config=engine_config)
                    )
                    LOG.info("‚úÖ Capture-enabled bypass engine initialized")
                else:
                    self.bypass_engine = UnifiedBypassEngine(config=engine_config)
                    LOG.warning("‚ö†Ô∏è Regular bypass engine initialized")
            except Exception as e:
                LOG.error(f"Bypass engine init failed: {e}")
                self.bypass_engine = None
        else:
            LOG.warning("Bypass engine not available")
            self.bypass_engine = None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        self.best_strategies = self._load_best_strategies()
        self.negative_knowledge = self._load_negative_knowledge()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤
        self._load_protocol_preferences()
        
        # Task 6.5: Log component initialization summary
        LOG.info("=" * 60)
        LOG.info("AdaptiveEngine Component Initialization Summary:")
        LOG.info(f"  ‚úÖ StrategyManager: {'Available' if self._strategy_manager else 'Not Available'}")
        LOG.info(f"  ‚úÖ DoHIntegration: {'Available' if self.doh_integration else 'Not Available'}")
        LOG.info(f"  ‚úÖ BypassEngine: {'Available' if self.bypass_engine else 'Not Available'}")
        LOG.info(f"  ‚úÖ PCAP Capture: {'Enabled' if WindowsBypassEngineWithCapture and isinstance(self.bypass_engine, WindowsBypassEngineWithCapture) else 'Disabled'}")
        LOG.info(f"  ‚úÖ Forced Override: Enabled (all strategies use no_fallbacks=True, forced=True)")
        LOG.info(f"  ‚úÖ Strategy Validation: Enabled")
        LOG.info(f"  ‚úÖ PCAP Analysis: Enabled (PCAPAnalyzer)")
        LOG.info("=" * 60)
    
    def _load_best_strategies(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ª—É—á—à–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
        strategies_file = Path(self.config.strategies_file)
        if not strategies_file.exists():
            return {}
        
        try:
            with open(strategies_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                strategies = {}
                for domain, strategy_data in data.items():
                    if Strategy:
                        strategies[domain] = Strategy(
                            name=strategy_data.get("name", "unknown"),
                            attack_name=strategy_data.get("attack_name", "unknown"),
                            parameters=strategy_data.get("parameters", {}),
                            id=strategy_data.get("id")
                        )
                LOG.info(f"Loaded {len(strategies)} saved strategies")
                return strategies
        except Exception as e:
            LOG.warning(f"Failed to load saved strategies: {e}")
            return {}
    
    def _save_best_strategies(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
        try:
            data = {}
            for domain, strategy in self.best_strategies.items():
                data[domain] = {
                    "name": strategy.name,
                    "attack_name": getattr(strategy, 'attack_name', strategy.attack_combination[0] if hasattr(strategy, 'attack_combination') and strategy.attack_combination else 'unknown'),
                    "parameters": strategy.parameters,
                    "id": getattr(strategy, 'id', strategy.name),
                    "saved_at": datetime.now().isoformat()
                }
            
            with open(self.config.strategies_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            LOG.info(f"Saved {len(data)} strategies to {self.config.strategies_file}")
        except Exception as e:
            LOG.error(f"Failed to save strategies: {e}")
    
    def _load_negative_knowledge(self) -> Dict[str, List[str]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π (—á—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)"""
        nk_file = Path(self.config.negative_knowledge_file)
        if not nk_file.exists():
            return {}
        
        try:
            with open(nk_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                LOG.info(f"Loaded negative knowledge for {len(data)} domains")
                return data
        except Exception as e:
            LOG.warning(f"Failed to load negative knowledge: {e}")
            return {}
    
    def _load_protocol_preferences(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
        pref_file = Path(self.config.protocol_preferences_file)
        if not pref_file.exists():
            LOG.info("Protocol preferences file not found, starting with empty preferences")
            return
        
        try:
            with open(pref_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
                current_time = datetime.now()
                loaded_count = 0
                
                with self._cache_lock:
                    for domain, pref_data in data.items():
                        try:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
                            if all(key in pref_data for key in ["ip_type", "target_ip", "timestamp", "success_count"]):
                                # –ü–∞—Ä—Å–∏–º timestamp
                                timestamp = datetime.fromisoformat(pref_data["timestamp"])
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É—Å—Ç–∞—Ä–µ–ª–∏ –ª–∏ –¥–∞–Ω–Ω—ã–µ (–º–∞–∫—Å–∏–º—É–º 30 –¥–Ω–µ–π)
                                age_days = (current_time - timestamp).days
                                if age_days <= 30:
                                    self._protocol_preference_cache[domain] = {
                                        "ip_type": pref_data["ip_type"],
                                        "target_ip": pref_data["target_ip"],
                                        "timestamp": timestamp,
                                        "success_count": pref_data["success_count"]
                                    }
                                    loaded_count += 1
                                else:
                                    LOG.debug(f"Skipping outdated preference for {domain} (age: {age_days} days)")
                        except Exception as e:
                            LOG.warning(f"Invalid preference data for {domain}: {e}")
                
                LOG.info(f"Loaded {loaded_count} protocol preferences from {pref_file}")
                
        except Exception as e:
            LOG.warning(f"Failed to load protocol preferences: {e}")
    
    def _save_negative_knowledge(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π"""
        try:
            with open(self.config.negative_knowledge_file, 'w', encoding='utf-8') as f:
                json.dump(self.negative_knowledge, f, indent=2, ensure_ascii=False)
        except Exception as e:
            LOG.error(f"Failed to save negative knowledge: {e}")
    

    
    def _save_protocol_preferences(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –≤ —Ñ–∞–π–ª"""
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            data_to_save = {}
            
            with self._cache_lock:
                for domain, pref_data in self._protocol_preference_cache.items():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                    if self._is_cache_valid(pref_data.get('timestamp', datetime.now())):
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º datetime –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è JSON
                        save_data = pref_data.copy()
                        if 'timestamp' in save_data:
                            save_data['timestamp'] = save_data['timestamp'].isoformat()
                        data_to_save[domain] = save_data
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            with open(self.config.protocol_preferences_file, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, indent=2, ensure_ascii=False)
            
            LOG.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(data_to_save)} –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –≤ {self.config.protocol_preferences_file}")
            
        except Exception as e:
            LOG.error(f"Failed to save protocol preferences: {e}")
    
    def _get_cache_key(self, domain: str, context: str = "") -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
        key_data = f"{domain}:{context}:{self.config.mode}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _is_cache_valid(self, timestamp: datetime) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –∫—ç—à–∞"""
        age = datetime.now() - timestamp
        return age.total_seconds() < (self.config.cache_ttl_hours * 3600)

    def _get_cached_fingerprint(self, domain: str) -> Optional[Any]:
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ DPI fingerprint"""
        if not self.config.enable_caching:
            return None
        
        cache_key = self._get_cache_key(domain, "fingerprint")
        
        with self._cache_lock:
            if cache_key in self._fingerprint_cache:
                cached_data = self._fingerprint_cache[cache_key]
                if self._is_cache_valid(cached_data["timestamp"]):
                    self.stats["cache_hits"] += 1
                    return cached_data["fingerprint"]
                else:
                    # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫—ç—à
                    del self._fingerprint_cache[cache_key]
        
        self.stats["cache_misses"] += 1
        return None
    
    def _cache_fingerprint(self, domain: str, fingerprint: Any):
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ DPI fingerprint"""
        if not self.config.enable_caching:
            return
        
        cache_key = self._get_cache_key(domain, "fingerprint")
        
        with self._cache_lock:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
            if len(self._fingerprint_cache) >= self.config.fingerprint_cache_size:
                # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —ç–ª–µ–º–µ–Ω—Ç
                oldest_key = min(self._fingerprint_cache.keys(), 
                               key=lambda k: self._fingerprint_cache[k]["timestamp"])
                del self._fingerprint_cache[oldest_key]
            
            self._fingerprint_cache[cache_key] = {
                "fingerprint": fingerprint,
                "timestamp": datetime.now()
            }
    
    def _get_cached_strategies(self, domain: str, fingerprint_hash: str) -> Optional[List[Any]]:
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
        if not self.config.enable_caching:
            return None
        
        cache_key = self._get_cache_key(domain, f"strategies_{fingerprint_hash}")
        
        with self._cache_lock:
            if cache_key in self._strategy_cache:
                cached_data = self._strategy_cache[cache_key]
                if self._is_cache_valid(cached_data["timestamp"]):
                    self.stats["cache_hits"] += 1
                    return cached_data["strategies"]
                else:
                    del self._strategy_cache[cache_key]
        
        self.stats["cache_misses"] += 1
        return None
    
    def _cache_strategies(self, domain: str, fingerprint_hash: str, strategies: List[Any]):
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
        if not self.config.enable_caching:
            return
        
        cache_key = self._get_cache_key(domain, f"strategies_{fingerprint_hash}")
        
        with self._cache_lock:
            if len(self._strategy_cache) >= self.config.strategy_cache_size:
                oldest_key = min(self._strategy_cache.keys(),
                               key=lambda k: self._strategy_cache[k]["timestamp"])
                del self._strategy_cache[oldest_key]
            
            self._strategy_cache[cache_key] = {
                "strategies": strategies,
                "timestamp": datetime.now()
            }
    
    def _save_protocol_preference(self, domain: str, ip_type: str, target_ip: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –¥–ª—è –¥–æ–º–µ–Ω–∞"""
        if not self.config.enable_caching:
            return
        
        with self._cache_lock:
            self._protocol_preference_cache[domain] = {
                "ip_type": ip_type,
                "target_ip": target_ip,
                "timestamp": datetime.now(),
                "success_count": self._protocol_preference_cache.get(domain, {}).get("success_count", 0) + 1
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è (FR-5.8)
        self._save_protocol_preferences()
        
        LOG.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª –¥–ª—è {domain}: {ip_type} ({target_ip})")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ IPv6 –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (FR-5.7)
        if ip_type == "IPv6":
            LOG.info(f"üåê IPv6 —É—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è {domain}: {target_ip}")
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è IPv6
            if not hasattr(self, '_ipv6_usage_stats'):
                self._ipv6_usage_stats = {"domains": set(), "total_uses": 0}
            self._ipv6_usage_stats["domains"].add(domain)
            self._ipv6_usage_stats["total_uses"] += 1
        else:
            LOG.info(f"üåê IPv4 —É—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è {domain}: {target_ip}")
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è IPv4
            if not hasattr(self, '_ipv4_usage_stats'):
                self._ipv4_usage_stats = {"domains": set(), "total_uses": 0}
            self._ipv4_usage_stats["domains"].add(domain)
            self._ipv4_usage_stats["total_uses"] += 1
    
    def _get_protocol_preference(self, domain: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –¥–ª—è –¥–æ–º–µ–Ω–∞"""
        if not self.config.enable_caching:
            return None
        
        with self._cache_lock:
            if domain in self._protocol_preference_cache:
                cached_data = self._protocol_preference_cache[domain]
                if self._is_cache_valid(cached_data["timestamp"]):
                    return cached_data
                else:
                    # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫—ç—à
                    del self._protocol_preference_cache[domain]
        
        return None
    
    def get_protocol_preference_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è IPv4/IPv6,
        –≤–∫–ª—é—á–∞—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–º–µ–Ω–æ–≤, —É—Å–ø–µ—à–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤
        """
        stats = {
            "timestamp": datetime.now().isoformat(),
            "total_domains_with_preferences": 0,
            "ipv4_preferred_domains": 0,
            "ipv6_preferred_domains": 0,
            "protocol_distribution": {"IPv4": 0, "IPv6": 0},
            "usage_statistics": {
                "ipv4_total_uses": getattr(self, '_ipv4_usage_stats', {}).get('total_uses', 0),
                "ipv6_total_uses": getattr(self, '_ipv6_usage_stats', {}).get('total_uses', 0),
                "ipv4_unique_domains": len(getattr(self, '_ipv4_usage_stats', {}).get('domains', set())),
                "ipv6_unique_domains": len(getattr(self, '_ipv6_usage_stats', {}).get('domains', set()))
            },
            "cache_info": {
                "cached_preferences": len(self._protocol_preference_cache),
                "cache_hit_rate": 0.0
            }
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤
        with self._cache_lock:
            for domain, pref_data in self._protocol_preference_cache.items():
                if self._is_cache_valid(pref_data.get('timestamp', datetime.now())):
                    stats["total_domains_with_preferences"] += 1
                    
                    ip_type = pref_data.get('ip_type', 'IPv4')
                    if ip_type == "IPv6":
                        stats["ipv6_preferred_domains"] += 1
                    else:
                        stats["ipv4_preferred_domains"] += 1
                    
                    stats["protocol_distribution"][ip_type] += 1
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
        total_prefs = stats["total_domains_with_preferences"]
        if total_prefs > 0:
            stats["ipv4_percentage"] = (stats["ipv4_preferred_domains"] / total_prefs) * 100
            stats["ipv6_percentage"] = (stats["ipv6_preferred_domains"] / total_prefs) * 100
        else:
            stats["ipv4_percentage"] = 0.0
            stats["ipv6_percentage"] = 0.0
        
        # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å IPv6
        total_ipv6_uses = stats["usage_statistics"]["ipv6_total_uses"]
        total_uses = stats["usage_statistics"]["ipv4_total_uses"] + total_ipv6_uses
        if total_uses > 0:
            stats["ipv6_adoption_rate"] = (total_ipv6_uses / total_uses) * 100
        else:
            stats["ipv6_adoption_rate"] = 0.0
        
        return stats
    
    def _run_strategy_validation(self, result: Any, strategy_dict: Dict[str, Any], domain: str):
        """
        Run StrategyValidator to verify strategy application in verification mode.
        
        This method:
        1. Extracts PCAP file and operation log from test result
        2. Runs StrategyValidator to compare expected vs actual operations
        3. Logs validation results
        4. Updates AdaptiveKnowledgeBase with verified flag if validation passes
        
        Args:
            result: Test result from _test_strategy
            strategy_dict: Strategy configuration that was tested
            domain: Domain name being tested
            
        Requirements: 1.3 - Automatic validation after test
        """
        try:
            # Extract PCAP file from result
            pcap_file = None
            if hasattr(result, 'pcap_file'):
                pcap_file = result.pcap_file
            elif isinstance(result, dict):
                pcap_file = result.get('pcap_file') or result.get('capture_path')
            
            if not pcap_file:
                LOG.warning(f"‚ö†Ô∏è [VALIDATION] No PCAP file available for validation")
                return
            
            # Check if PCAP file exists
            from pathlib import Path
            pcap_path = Path(pcap_file)
            if not pcap_path.exists():
                LOG.warning(f"‚ö†Ô∏è [VALIDATION] PCAP file not found: {pcap_file}")
                return
            
            # Extract strategy name from strategy_dict
            strategy_name = strategy_dict.get('attack', strategy_dict.get('type', 'unknown'))
            
            LOG.info(f"üîç [VALIDATION] Running strategy validation for {domain}")
            LOG.info(f"   PCAP file: {pcap_file}")
            LOG.info(f"   Strategy: {strategy_name}")
            
            # Load operation log from the most recent log file
            # The operation logger saves logs with timestamp and domain
            from core.operation_logger import get_operation_logger
            operation_logger = get_operation_logger()
            
            # Find the most recent log file for this domain
            import os
            import glob
            log_dir = operation_logger.log_dir
            domain_safe = domain.replace('.', '_')
            log_pattern = os.path.join(log_dir, f"*_{domain_safe}_*.json")
            log_files = glob.glob(log_pattern)
            
            strategy_log = None
            if not log_files:
                LOG.warning(f"‚ö†Ô∏è [VALIDATION] No operation log found for {domain}")
                LOG.info(f"   Will run PCAP-only analysis without operation log")
            else:
                # Get the most recent log file
                latest_log = max(log_files, key=os.path.getmtime)
                LOG.info(f"   Operation log: {latest_log}")
                
                # Load strategy log
                import json
                try:
                    with open(latest_log, 'r', encoding='utf-8') as f:
                        strategy_log = json.load(f)
                except Exception as e:
                    LOG.warning(f"‚ö†Ô∏è [VALIDATION] Failed to load operation log: {e}")
                    strategy_log = None
            
            # Run validation (works with or without operation log)
            # Pass strategy_name explicitly so it's not 'unknown'
            validation_result = self.strategy_validator.validate_strategy(
                strategy_log=strategy_log,
                pcap_file=pcap_path,
                domain=domain,
                strategy_name=strategy_name  # Pass strategy name explicitly
            )
            
            # Log validation result
            status_symbol = {
                "valid": "‚úÖ",
                "invalid": "‚ùå",
                "partial": "‚ö†Ô∏è",
                "unknown": "‚ùì"
            }.get(validation_result.status.value, "‚ùì")
            
            LOG.info(f"{status_symbol} [VALIDATION] Status: {validation_result.status.value.upper()}")
            LOG.info(f"   Message: {validation_result.message}")
            
            if validation_result.expected_operations:
                LOG.info(f"   Expected operations: {', '.join(validation_result.expected_operations)}")
            if validation_result.actual_operations:
                LOG.info(f"   Actual operations: {', '.join(validation_result.actual_operations)}")
            if validation_result.missing_operations:
                LOG.warning(f"   Missing operations: {', '.join(validation_result.missing_operations)}")
            if validation_result.unexpected_operations:
                LOG.warning(f"   Unexpected operations: {', '.join(validation_result.unexpected_operations)}")
            
            # Task 11.6: Update AdaptiveKnowledgeBase with verified flag
            # If validation is VALID, mark strategy as verified
            if validation_result.status.value == "valid" and self.adaptive_knowledge:
                try:
                    # Extract strategy name and parameters from strategy_log
                    strategy_name = strategy_log.get('strategy_name', 'unknown')
                    strategy_params = {}
                    
                    # Try to extract parameters from operations
                    operations = strategy_log.get('operations', [])
                    for op in operations:
                        op_type = op.get('type')
                        params = op.get('params', {})
                        
                        if op_type == 'split':
                            # Extract split parameters
                            strategy_params['split_pos'] = params.get('position')
                            strategy_params['split_count'] = params.get('count')
                        
                        elif op_type == 'fake':
                            # Extract fake packet parameters
                            strategy_params['fake_ttl'] = params.get('ttl')
                            fake_count = params.get('count')
                            if fake_count:
                                strategy_params['fake_count'] = fake_count
                        
                        elif op_type == 'disorder':
                            # Mark disorder as enabled
                            strategy_params['disorder'] = True
                        
                        elif op_type == 'fooling':
                            # Extract fooling mode
                            fooling_mode = params.get('mode')
                            if fooling_mode:
                                strategy_params['fooling_mode'] = fooling_mode
                    
                    # Mark strategy as verified using the set_verified method
                    self.adaptive_knowledge.set_verified(
                        domain=domain,
                        strategy_name=strategy_name,
                        strategy_params=strategy_params,
                        verified=True
                    )
                    
                    LOG.info(f"‚úÖ [VALIDATION] Marked strategy '{strategy_name}' as verified in AdaptiveKnowledgeBase")
                    LOG.info(f"   Strategy parameters: {strategy_params}")
                    
                except Exception as e:
                    LOG.warning(f"‚ö†Ô∏è [VALIDATION] Failed to update verified flag: {e}")
            
        except Exception as e:
            LOG.error(f"‚ùå [VALIDATION] Validation failed: {e}", exc_info=True)
    
    def _calculate_adaptive_timeout(self, domain: str, fingerprint: Optional[Any] = None, 
                                  failure_report: Optional[Any] = None) -> float:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ç–∞–π–º–∞—É—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ DPI –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏.
        
        –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
        - FR-5.4: –£–≤–µ–ª–∏—á–∏–≤–∞—Ç—å —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ DPI_CONTENT_INSPECTION (factor 1.5-2.0)
        - FR-5.5: –ü—Ä–∏–º–µ–Ω—è—Ç—å timeout factor –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö CDN
        - FR-5.6: –ù–ï —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ RST-–∏–Ω—ä–µ–∫—Ü–∏—è—Ö
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            fingerprint: DPI fingerprint —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–∏–ø–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            failure_report: –û—Ç—á–µ—Ç –æ –Ω–µ—É–¥–∞—á–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—á–∏–Ω
            
        Returns:
            –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        base_timeout = self.config.strategy_timeout
        timeout_factor = 1.0
        adjustment_reason = "base"
        
        # –ê–Ω–∞–ª–∏–∑ DPI fingerprint
        if fingerprint:
            try:
                dpi_type = getattr(fingerprint, 'dpi_type', None)
                if dpi_type:
                    dpi_type_str = dpi_type.value if hasattr(dpi_type, 'value') else str(dpi_type)
                    
                    # FR-5.4: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ DPI_CONTENT_INSPECTION
                    if 'CONTENT_INSPECTION' in dpi_type_str:
                        timeout_factor = self.config.timeout_factor_content_inspection
                        adjustment_reason = "content_inspection"
                        self.timeout_stats["content_inspection_adjustments"] += 1
                        LOG.info(f"üïê –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –¥–ª—è DPI_CONTENT_INSPECTION: {timeout_factor}x")
                    
                    # FR-5.6: –ù–ï —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ RST-–∏–Ω—ä–µ–∫—Ü–∏—è—Ö
                    elif 'RST_INJECTION' in dpi_type_str or 'ACTIVE_RST' in dpi_type_str:
                        timeout_factor = 1.0  # –û—Å—Ç–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—ã–π —Ç–∞–π–º–∞—É—Ç
                        adjustment_reason = "rst_injection_no_change"
                        self.timeout_stats["rst_injection_adjustments"] += 1
                        LOG.info(f"üïê –¢–∞–π–º–∞—É—Ç –ù–ï –∏–∑–º–µ–Ω–µ–Ω –¥–ª—è RST-–∏–Ω—ä–µ–∫—Ü–∏–π: {timeout_factor}x")
                    
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ DPI –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–µ—Ä–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
                    elif 'STATEFUL' in dpi_type_str or 'REASSEMBLES' in dpi_type_str:
                        timeout_factor = 1.3  # –£–º–µ—Ä–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
                        adjustment_reason = "stateful_dpi"
                        self.timeout_stats["network_timeout_adjustments"] += 1
                        LOG.info(f"üïê –£–º–µ—Ä–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞ –¥–ª—è stateful DPI: {timeout_factor}x")
                        
            except Exception as e:
                LOG.debug(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ DPI fingerprint –¥–ª—è —Ç–∞–π–º–∞—É—Ç–∞: {e}")
        
        # –ê–Ω–∞–ª–∏–∑ failure_report –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–æ–∫
        if failure_report:
            try:
                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ CDN –∏–ª–∏ —Å–µ—Ç–∏
                block_timing = getattr(failure_report, 'block_timing', None)
                if block_timing and block_timing > 5.0:  # –ú–µ–¥–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
                    # FR-5.5: –ü—Ä–∏–º–µ–Ω—è–µ–º timeout factor –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö CDN
                    slow_factor = self.config.timeout_factor_slow_cdn
                    timeout_factor = max(timeout_factor, slow_factor)
                    adjustment_reason = "slow_cdn"
                    self.timeout_stats["slow_cdn_adjustments"] += 1
                    LOG.info(f"üïê –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ CDN: {timeout_factor}x")
                
                # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫
                failure_details = getattr(failure_report, 'failure_details', {})
                if failure_details:
                    error_indicators = failure_details.get('error_indicators', [])
                    if 'timeout' in str(error_indicators).lower():
                        # –ï—Å–ª–∏ –±—ã–ª–∞ –æ—à–∏–±–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º
                        timeout_factor = max(timeout_factor, 1.5)
                        adjustment_reason = "previous_timeout"
                        self.timeout_stats["network_timeout_adjustments"] += 1
                        LOG.info(f"üïê –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –∏–∑-–∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ timeout: {timeout_factor}x")
                        
            except Exception as e:
                LOG.debug(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ failure_report –¥–ª—è —Ç–∞–π–º–∞—É—Ç–∞: {e}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º tweaks –∏–∑ –ø—Ä–∞–≤–∏–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        if hasattr(self, '_current_timeout_factor'):
            tweak_factor = getattr(self, '_current_timeout_factor', 1.0)
            if tweak_factor > 1.0:
                timeout_factor = max(timeout_factor, tweak_factor)
                adjustment_reason = "knowledge_base_tweak"
                LOG.info(f"üïê –ü—Ä–∏–º–µ–Ω–µ–Ω tweak –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {timeout_factor}x")
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
        adaptive_timeout = base_timeout * timeout_factor
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if timeout_factor > 1.0:
            self.timeout_stats["adaptive_timeouts_applied"] += 1
            self._update_average_timeout_factor(timeout_factor)
        
        LOG.debug(f"üïê –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è {domain}: {adaptive_timeout:.1f}s "
                 f"(base: {base_timeout}s, factor: {timeout_factor}x, reason: {adjustment_reason})")
        
        return adaptive_timeout
    
    def _update_average_timeout_factor(self, new_factor: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ timeout factor"""
        current_avg = self.timeout_stats["average_timeout_factor"]
        applied_count = self.timeout_stats["adaptive_timeouts_applied"]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        if applied_count == 1:
            self.timeout_stats["average_timeout_factor"] = new_factor
        else:
            # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
            self.timeout_stats["average_timeout_factor"] = (
                (current_avg * (applied_count - 1) + new_factor) / applied_count
            )
    
    def _update_adaptive_timeout_from_failure(self, domain: str, failure_report: Any, 
                                            current_timeout: float) -> float:
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ç–∞–π–º–∞—É—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—É–¥–∞—á–∏.
        
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏—á–∏–Ω—ã –Ω–µ—É–¥–∞—á–∏ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –ø–æ–ø—ã—Ç–æ–∫.
        –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö —Ç–∞–π–º–∞—É—Ç–æ–≤.
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            failure_report: –û—Ç—á–µ—Ç –æ –Ω–µ—É–¥–∞—á–µ –æ—Ç SFA
            current_timeout: –¢–µ–∫—É—â–∏–π —Ç–∞–π–º–∞—É—Ç
            
        Returns:
            –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –ø–æ–ø—ã—Ç–æ–∫
        """
        if not failure_report:
            return current_timeout
        
        try:
            root_cause = getattr(failure_report, 'root_cause', None)
            if not root_cause:
                return current_timeout
            
            root_cause_str = root_cause.value if hasattr(root_cause, 'value') else str(root_cause)
            new_timeout = current_timeout
            adjustment_made = False
            
            # FR-5.4: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ DPI_CONTENT_INSPECTION
            if 'CONTENT_INSPECTION' in root_cause_str:
                factor = self.config.timeout_factor_content_inspection
                new_timeout = max(current_timeout * factor, current_timeout + 5.0)
                adjustment_made = True
                self.timeout_stats["content_inspection_adjustments"] += 1
                LOG.info(f"üïê –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –∏–∑-–∑–∞ CONTENT_INSPECTION: {new_timeout:.1f}s")
            
            # FR-5.6: –ù–ï —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ RST-–∏–Ω—ä–µ–∫—Ü–∏—è—Ö
            elif 'RST_INJECTION' in root_cause_str or 'ACTIVE_RST' in root_cause_str:
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è RST-–∏–Ω—ä–µ–∫—Ü–∏–π
                new_timeout = current_timeout
                self.timeout_stats["rst_injection_adjustments"] += 1
                LOG.info(f"üïê –¢–∞–π–º–∞—É—Ç –ù–ï –∏–∑–º–µ–Ω–µ–Ω –¥–ª—è RST-–∏–Ω—ä–µ–∫—Ü–∏–π: {new_timeout:.1f}s")
            
            # –ê–Ω–∞–ª–∏–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ—É–¥–∞—á–∏
            failure_details = getattr(failure_report, 'failure_details', {})
            if failure_details:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –º–µ–¥–ª–µ–Ω–Ω–æ–π —Å–µ—Ç–∏
                error_indicators = failure_details.get('error_indicators', [])
                if any('timeout' in str(indicator).lower() for indicator in error_indicators):
                    # FR-5.5: –ü—Ä–∏–º–µ–Ω—è–µ–º timeout factor –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                    factor = self.config.timeout_factor_slow_cdn
                    new_timeout = max(new_timeout * factor, new_timeout + 3.0)
                    adjustment_made = True
                    self.timeout_stats["slow_cdn_adjustments"] += 1
                    LOG.info(f"üïê –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –∏–∑-–∑–∞ –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {new_timeout:.1f}s")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–µ—Ç–∏
                if any('network' in str(indicator).lower() for indicator in error_indicators):
                    new_timeout = max(new_timeout * 1.3, new_timeout + 2.0)
                    adjustment_made = True
                    self.timeout_stats["network_timeout_adjustments"] += 1
                    LOG.info(f"üïê –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –∏–∑-–∑–∞ —Å–µ—Ç–µ–≤—ã—Ö –ø—Ä–æ–±–ª–µ–º: {new_timeout:.1f}s")
            
            # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            block_timing = getattr(failure_report, 'block_timing', None)
            if block_timing and block_timing > 3.0:
                # –ï—Å–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –º–µ–¥–ª–µ–Ω–Ω–æ, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç
                timing_factor = min(block_timing / 3.0, 2.0)  # –ú–∞–∫—Å–∏–º—É–º 2x
                new_timeout = max(new_timeout * timing_factor, new_timeout + 2.0)
                adjustment_made = True
                self.timeout_stats["slow_cdn_adjustments"] += 1
                LOG.info(f"üïê –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç –∏–∑-–∑–∞ –º–µ–¥–ª–µ–Ω–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ ({block_timing:.1f}s): {new_timeout:.1f}s")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
            max_timeout = self.config.strategy_timeout * 3.0  # –ú–∞–∫—Å–∏–º—É–º 3x –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ
            new_timeout = min(new_timeout, max_timeout)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –µ—Å–ª–∏ –±—ã–ª —Å–¥–µ–ª–∞–Ω adjustment
            if adjustment_made:
                self.timeout_stats["adaptive_timeouts_applied"] += 1
                timeout_factor = new_timeout / self.config.strategy_timeout
                self._update_average_timeout_factor(timeout_factor)
            
            return new_timeout
            
        except Exception as e:
            LOG.warning(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ —Ç–∞–π–º–∞—É—Ç–∞: {e}")
            return current_timeout
    
    def _profile_operation(self, operation_name: str):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π"""
        def decorator(func):
            async def wrapper(*args, **kwargs):
                if not self.config.enable_profiling:
                    return await func(*args, **kwargs)
                
                start_time = time.time()
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    execution_time = time.time() - start_time
                    
                    if operation_name not in self._profiling_data:
                        self._profiling_data[operation_name] = {
                            "total_time": 0.0,
                            "call_count": 0,
                            "average_time": 0.0,
                            "min_time": float('inf'),
                            "max_time": 0.0
                        }
                    
                    profile = self._profiling_data[operation_name]
                    profile["total_time"] += execution_time
                    profile["call_count"] += 1
                    profile["average_time"] = profile["total_time"] / profile["call_count"]
                    profile["min_time"] = min(profile["min_time"], execution_time)
                    profile["max_time"] = max(profile["max_time"], execution_time)
                    
                    LOG.debug(f"Profile {operation_name}: {execution_time:.3f}s")
            
            return wrapper
        return decorator
    
    def _convert_strategy_to_unified_format(self, strategy: Any) -> Dict[str, Any]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç UnifiedBypassEngine
        
        –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è GeneratedStrategy –≤ zapret —Ñ–æ—Ä–º–∞—Ç
        –†–µ—à–µ–Ω–∏–µ: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ UnifiedStrategyLoader
        """
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ç–∞–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            if hasattr(strategy, 'attack_combination') and strategy.attack_combination:
                attacks = [str(a).lower() for a in strategy.attack_combination]
                params = dict(getattr(strategy, 'parameters', {}) or {})
            elif hasattr(strategy, 'attack_name'):
                attacks = [str(strategy.attack_name).lower()]
                params = dict(getattr(strategy, 'parameters', {}) or {})
            else:
                # Fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
                attacks = ["fake"]
                params = {"ttl": 3}

            LOG.info(f"[CONVERT] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: attacks={attacks}, params={params}")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ï—Å–ª–∏ —ç—Ç–æ smart_combo —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤,
            # –∏—Å–ø–æ–ª—å–∑—É–µ–º UnifiedStrategyLoader –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if len(attacks) == 1 and attacks[0].startswith("smart_combo_") and not params:
                LOG.debug(f"[CONVERT] –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ smart_combo —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {attacks[0]}")
                if hasattr(self, '_strategy_loader') and self._strategy_loader:
                    try:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ UnifiedStrategyLoader —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        normalized = self._strategy_loader.load_strategy(attacks[0])
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∞—Ç–∞–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                        attacks = normalized.attacks
                        params = normalized.params
                        LOG.info(f"[CONVERT] ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã –∞—Ç–∞–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: attacks={attacks}, params={params}")
                    except Exception as e:
                        LOG.warning(f"[CONVERT] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ {attacks[0]}: {e}")

            # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º split_pos –¥–ª—è split/disorder –∞—Ç–∞–∫
            split_like = {"fakeddisorder", "fake_disorder", "fakedisorder",
                          "disorder", "disorder2", "multidisorder", "split", "multisplit"}
            if any(a in split_like for a in attacks):
                if "split_pos" not in params and "positions" not in params:
                    params["split_pos"] = "sni"  # TLS default
                    LOG.debug(f"[CONVERT] –î–æ–±–∞–≤–ª–µ–Ω default split_pos=sni")

            # –°—Ç—Ä–æ–∏–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è UnifiedStrategyLoader
            # –§–∏–ª—å—Ç—Ä—É–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ attacks
            attacks = [a for a in attacks if a is not None and isinstance(a, str)]
            attack_str = ",".join(attacks)
            param_parts = []
            for k, v in params.items():
                if isinstance(v, (list, tuple)):
                    v_str = ",".join(str(x) for x in v)
                else:
                    v_str = str(v)
                param_parts.append(f"{k}={v_str}")
            
            canonical = f"{attack_str}; {'; '.join(param_parts)}" if param_parts else attack_str
            LOG.info(f"[CONVERT] –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä–æ–∫–∞: {canonical}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ UnifiedStrategyLoader
            if hasattr(self, '_strategy_loader') and self._strategy_loader:
                try:
                    normalized = self._strategy_loader.load_strategy(canonical)
                    forced = self._strategy_loader.create_forced_override(normalized)
                    LOG.info(f"[CONVERT] ‚úÖ –£—Å–ø–µ—à–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {forced}")
                    return forced
                except Exception as e:
                    LOG.warning(f"[CONVERT] ‚ö†Ô∏è –û—à–∏–±–∫–∞ UnifiedStrategyLoader: {e}")
                    # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
            
            # Task 6.5: Ensure forced override in fallback format
            # CRITICAL FIX: Include ALL attacks for combination strategies
            fallback_strategy = {
                "type": attacks[0] if attacks else "fake",
                "params": params,
                "forced": True,
                "no_fallbacks": True,  # Task 6.5: Ensure no fallbacks
                "fallback": True,
                "attacks": attacks  # CRITICAL: Include all attacks, not just first one
            }
            LOG.info(f"[CONVERT] ‚úÖ Fallback —Ñ–æ—Ä–º–∞—Ç —Å forced override: {fallback_strategy}")
            LOG.info(f"[CONVERT] üìã All attacks included: {attacks}")
            return fallback_strategy

        except Exception as e:
            LOG.error(f"[CONVERT] ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
            # –ù–∞–¥–µ–∂–Ω—ã–π fallback
            return {
                "type": "fake",
                "params": {"ttl": 3},
                "no_fallbacks": True,
                "forced": True,
                "error": str(e)
            }
    
    async def _test_strategy_real(self, domain: str, strategy: Any) -> Dict[str, Any]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ö–†–ò–¢–ò–ß–ï–°–ö–û–ô –ü–†–û–ë–õ–ï–ú–´: –†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —á–µ—Ä–µ–∑ bypass engine
        
        –ü—Ä–æ–±–ª–µ–º–∞: AdaptiveEngine –Ω–µ —Ä–µ–∞–ª—å–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –ø–æ–∫–∞–∑—ã–≤–∞–ª 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        –†–µ—à–µ–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É–µ–º UnifiedBypassEngine –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        """
        LOG.info(f"[TEST] üéØ –†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {getattr(strategy, 'name', 'unknown')} –¥–ª—è {domain}")
        
        if not self.bypass_engine:
            LOG.error("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: UnifiedBypassEngine –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return {
                "success": False,
                "error": "CRITICAL: UnifiedBypassEngine not available - cannot test strategies",
                "response_time": 0.0
            }
        
        try:
            # Task 6.2: Use DoHIntegration for unified DNS resolution
            import socket
            try:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞–¥—Ä–µ—Å–∞ (IPv4 –∏ IPv6)
                ipv4_addresses = []
                ipv6_addresses = []
                
                if self.doh_integration:
                    # Use DoHIntegration with fallback
                    LOG.info(f"üîç Resolving {domain} via DoHIntegration")
                    try:
                        ips = await self.doh_integration.resolve_with_fallback(
                            domain, 
                            timeout=10.0,
                            retry_on_failure=True
                        )
                        
                        # Separate IPv4 and IPv6
                        for ip in ips:
                            if ":" in ip:
                                ipv6_addresses.append(ip)
                            else:
                                ipv4_addresses.append(ip)
                        
                        LOG.info(f"‚úÖ DoHIntegration resolved {domain} -> IPv4: {ipv4_addresses}, IPv6: {ipv6_addresses}")
                    except Exception as e:
                        LOG.warning(f"‚ö†Ô∏è DoHIntegration failed for {domain}: {e}, falling back to system DNS")
                        # Fallback to system DNS
                        addr_info = socket.getaddrinfo(
                            domain, 443, 
                            family=socket.AF_UNSPEC,
                            type=socket.SOCK_STREAM
                        )
                        for family, type_, proto, canonname, sockaddr in addr_info:
                            ip = sockaddr[0]
                            if family == socket.AF_INET:
                                ipv4_addresses.append(ip)
                            elif family == socket.AF_INET6:
                                ipv6_addresses.append(ip)
                else:
                    # Use system DNS directly
                    addr_info = socket.getaddrinfo(
                        domain, 443, 
                        family=socket.AF_UNSPEC,  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ IPv4 –∏ IPv6
                        type=socket.SOCK_STREAM
                    )
                    
                    for family, type_, proto, canonname, sockaddr in addr_info:
                        ip = sockaddr[0]
                        if family == socket.AF_INET:
                            ipv4_addresses.append(ip)
                        elif family == socket.AF_INET6:
                            ipv6_addresses.append(ip)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è –¥–æ–º–µ–Ω–∞
                protocol_pref = self._get_protocol_preference(domain)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                if protocol_pref:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ
                    if protocol_pref["ip_type"] == "IPv6":
                        all_addresses = ipv6_addresses + ipv4_addresses
                        LOG.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ IPv6 –¥–ª—è {domain}")
                    else:
                        all_addresses = ipv4_addresses + ipv6_addresses
                        LOG.info(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ IPv4 –¥–ª—è {domain}")
                elif self.config.prefer_ipv4:
                    all_addresses = ipv4_addresses + ipv6_addresses
                else:
                    all_addresses = ipv6_addresses + ipv4_addresses
                
                if not all_addresses:
                    LOG.error(f"‚ùå DNS: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è {domain}")
                    return {"success": False, "error": "No addresses found", "response_time": 0.0}
                
                LOG.info(f"‚úÖ DNS: {domain} -> IPv4: {ipv4_addresses}, IPv6: {ipv6_addresses}")
                LOG.info(f"üîÑ –ü–æ—Ä—è–¥–æ–∫ –ø–æ–ø—ã—Ç–æ–∫: {all_addresses}")
                
                # –ü—Ä–æ–±—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞–¥—Ä–µ—Å–∞ –ø–æ –ø–æ—Ä—è–¥–∫—É
                last_error = None
                for i, target_ip in enumerate(all_addresses):
                    ip_type = "IPv6" if ":" in target_ip else "IPv4"
                    LOG.info(f"üéØ –ü–æ–ø—ã—Ç–∫–∞ {i+1}/{len(all_addresses)}: {target_ip} ({ip_type})")
                    
                    try:
                        # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é (—á–µ—Ä–µ–∑ UnifiedStrategyLoader)
                        strategy_dict = self._convert_strategy_to_unified_format(strategy)
                        LOG.info(f"üìã Strategy: {strategy_dict}")
                        
                        # 3. –í—ã—á–∏—Å–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
                        adaptive_timeout = self._calculate_adaptive_timeout(domain)
                        
                        start_time = time.time()
                        
                        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                        LOG.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (service-based –∏–ª–∏ inline)")
                        
                        try:
                            # Task 11.2: Pass verification_mode from config
                            result = self._test_strategy(
                                target_ip=target_ip,
                                strategy_input=strategy_dict,
                                domain=domain,
                                timeout=adaptive_timeout,
                                verification_mode=self.config.verify_with_pcap
                            )
                            
                            success = getattr(result, "success", False)
                            error = getattr(result, "error", None) if not success else None
                            
                            LOG.info(f"[TEST] –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: success={success}, error={error}")
                            
                            # Task 11.5: Run StrategyValidator in verification mode
                            if self.config.verify_with_pcap and self.strategy_validator:
                                self._run_strategy_validation(result, strategy_dict, domain)
                            
                            if success:
                                LOG.info(f"[TEST] ‚úÖ –£–°–ü–ï–• —Å {ip_type}: {getattr(strategy, 'name', 'unknown')}")
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª
                                self._save_protocol_preference(domain, ip_type, target_ip)
                                return {
                                    "success": True,
                                    "error": None,
                                    "response_time": time.time() - start_time,
                                    "real_test": True,
                                    "target_ip": target_ip,
                                    "ip_type": ip_type,
                                    "strategy_name": getattr(strategy, 'name', 'unknown')
                                }
                            else:
                                LOG.warning(f"[TEST] ‚ùå –ù–ï–£–î–ê–ß–ê —Å {ip_type}: {error}")
                                
                                # Task 18: Try adaptive strategy adjustment
                                if self.strategy_adjuster and hasattr(result, 'get'):
                                    pcap_file = result.get("pcap_file") or result.get("capture_path")
                                    if pcap_file:
                                        try:
                                            import os
                                            if os.path.exists(pcap_file):
                                                from core.metrics.clienthello_metrics import ClientHelloMetricsCollector
                                                metrics_collector = ClientHelloMetricsCollector()
                                                clienthello_size = 0
                                                if hasattr(metrics_collector, 'get_average_clienthello_size'):
                                                    clienthello_size = metrics_collector.get_average_clienthello_size(pcap_file)
                                                
                                                if clienthello_size > 0:
                                                    LOG.info(f"[ADAPTIVE] Detected ClientHello size: {clienthello_size} bytes")
                                                    adjusted_strategy = self.strategy_adjuster.adjust_strategy(
                                                        strategy_dict.copy(),
                                                        clienthello_size
                                                    )
                                                    
                                                    if adjusted_strategy != strategy_dict:
                                                        LOG.info(f"[ADAPTIVE] Re-testing with adjusted strategy")
                                                        result_adjusted = self._test_strategy(
                                                            target_ip=target_ip,
                                                            strategy_input=adjusted_strategy,
                                                            domain=domain,
                                                            timeout=adaptive_timeout,
                                                            verification_mode=self.config.verify_with_pcap  # Task 11.2
                                                        )
                                                        
                                                        # Task 11.5: Run validation for adjusted strategy
                                                        if self.config.verify_with_pcap and self.strategy_validator:
                                                            self._run_strategy_validation(result_adjusted, adjusted_strategy, domain)
                                                        
                                                        success_adjusted = getattr(result_adjusted, "success", False)
                                                        if success_adjusted:
                                                            LOG.info(f"[ADAPTIVE] ‚úì Adjusted strategy succeeded!")
                                                            self._save_protocol_preference(domain, ip_type, target_ip)
                                                            return {
                                                                "success": True,
                                                                "error": None,
                                                                "response_time": time.time() - start_time,
                                                                "real_test": True,
                                                                "target_ip": target_ip,
                                                                "ip_type": ip_type,
                                                                "strategy_name": getattr(strategy, 'name', 'unknown'),
                                                                "adjusted": True
                                                            }
                                        except Exception as e:
                                            LOG.warning(f"[ADAPTIVE] Failed to adjust strategy: {e}")
                                
                                last_error = error
                                continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∞–¥—Ä–µ—Å
                        
                        except Exception as e:
                                LOG.error(f"[TEST] ‚ùå –û–®–ò–ë–ö–ê test_strategy_like_testing_mode: {e}")
                                last_error = str(e)
                                continue
                        
                        # FALLBACK: –†—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ bypass engine
                        else:
                            LOG.warning("‚ö†Ô∏è test_strategy_like_testing_mode –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
                            
                            with self._divert_lock:  # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è WinDivert
                                try:
                                    LOG.info(f"[TEST] –ó–∞–ø—É—Å–∫ bypass engine –¥–ª—è {target_ip}")
                                    
                                    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–≤–∏–∂–æ–∫ —Å —ç—Ç–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
                                    self.bypass_engine.start(
                                        target_ips={target_ip},
                                        strategy_map={"default": strategy_dict},
                                        reset_telemetry=True,
                                        strategy_override=strategy_dict
                                    )
                                    
                                    # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é WinDivert
                                    await asyncio.sleep(1.0)
                                    
                                    LOG.info(f"[TEST] –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ {domain}")
                                    # –ü—Ä–æ–±—É–µ–º –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è —á–µ—Ä–µ–∑ bypass
                                    success, error = await self._probe_https(domain, timeout=adaptive_timeout)
                                    
                                    if success:
                                        LOG.info(f"[TEST] ‚úÖ –£–°–ü–ï–• —Å {ip_type}: {getattr(strategy, 'name', 'unknown')}")
                                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª
                                        self._save_protocol_preference(domain, ip_type, target_ip)
                                        return {
                                            "success": True,
                                            "error": None,
                                            "response_time": time.time() - start_time,
                                            "real_test": True,
                                            "target_ip": target_ip,
                                            "ip_type": ip_type,
                                            "strategy_name": getattr(strategy, 'name', 'unknown'),
                                            "method": "manual_bypass_engine"
                                        }
                                    else:
                                        LOG.warning(f"[TEST] ‚ùå –ù–ï–£–î–ê–ß–ê —Å {ip_type}: {error}")
                                        last_error = error
                                        continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∞–¥—Ä–µ—Å
                                        
                                except Exception as e:
                                    LOG.error(f"[TEST] ‚ùå –û–®–ò–ë–ö–ê —Ä—É—á–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {e}")
                                    last_error = str(e)
                                    continue
                                    
                                finally:
                                    # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –í—Å–µ–≥–¥–∞ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫
                                    try:
                                        LOG.debug("[TEST] –û—Å—Ç–∞–Ω–æ–≤–∫–∞ bypass engine")
                                        self.bypass_engine.stop()
                                        await asyncio.sleep(0.2)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –æ—á–∏—Å—Ç–∫—É
                                    except Exception as e:
                                        LOG.warning(f"[TEST] –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ bypass engine: {e}")
                    
                    except Exception as e:
                        LOG.warning(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å {ip_type} ({target_ip}): {e}")
                        last_error = str(e)
                        continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∞–¥—Ä–µ—Å
                
                # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞, –≤—Å–µ –∞–¥—Ä–µ—Å–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
                LOG.error(f"‚ùå –í—Å–µ –∞–¥—Ä–µ—Å–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –¥–ª—è {domain}")
                return {
                    "success": False, 
                    "error": f"All addresses failed. Last error: {last_error}",
                    "response_time": 0.0,
                    "addresses_tried": len(all_addresses)
                }
                
            except Exception as e:
                LOG.error(f"‚ùå DNS failed: {e}")
                return {"success": False, "error": f"DNS failed: {e}", "response_time": 0.0}
                
        except Exception as e:
            LOG.error(f"üí• Test error: {e}")
            import traceback
            LOG.debug(traceback.format_exc())
            return {"success": False, "error": str(e), "response_time": 0.0}

    async def _probe_https(self, domain: str, timeout: float) -> Tuple[bool, Optional[str]]:
        """
        –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ HTTPS –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ curl —Å —ç–º—É–ª—è—Ü–∏–µ–π –±—Ä–∞—É–∑–µ—Ä–∞.
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç ClientHello ~1400 –±–∞–π—Ç –¥–ª—è –æ–±—Ö–æ–¥–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–∞–∫–µ—Ç–∞.
        """
        LOG.debug(f"[PROBE] –ü—Ä–æ–≤–µ—Ä–∫–∞ HTTPS –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {domain} —á–µ—Ä–µ–∑ curl (timeout: {timeout}s)")
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º null —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            null_dev = "NUL" if sys.platform == "win32" else "/dev/null"
            
            # –ò—â–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π curl.exe (–≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞), —Ç–∞–∫ –∫–∞–∫ —Å–∏—Å—Ç–µ–º–Ω—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç–∞—Ä—ã–º
            curl_exe = "curl"
            if sys.platform == "win32":
                import os
                local_curl = Path("curl.exe")
                if local_curl.exists():
                    curl_exe = str(local_curl.absolute())

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É curl
            cmd = [
                curl_exe,
                "-I", "-s", "-k",
                "--http2",                        # –≠–º—É–ª—è—Ü–∏—è HTTP/2
                "--tlsv1.2",                      # –ú–∏–Ω–∏–º—É–º TLS 1.2
                "--ciphers", BROWSER_CIPHER_LIST, # <--- –ö–†–ò–¢–ò–ß–ù–û: –†–∞–∑–¥—É–≤–∞–µ—Ç –ø–∞–∫–µ—Ç –¥–æ ~1400 –±–∞–π—Ç
                "-H", "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "--connect-timeout", str(int(timeout)),
                "--max-time", str(int(timeout) + 2),
                "-o", null_dev,
                "-w", "%{http_code}",
                f"https://{domain}"
            ]
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                try:
                    output = stdout.decode().strip()
                    if not output or output == "000":
                        LOG.debug(f"[PROBE] ‚ùå Curl –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –∫–æ–¥ –∏–ª–∏ 000")
                        return False, "No HTTP response"
                        
                    http_code = int(output)
                    # –õ—é–±–æ–π –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞ (–¥–∞–∂–µ 403/500) –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ TCP/TLS –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ
                    if 0 < http_code < 600:
                        LOG.debug(f"[PROBE] ‚úÖ Curl —É—Å–ø–µ—Ö: HTTP {http_code}")
                        return True, None
                    else:
                        LOG.debug(f"[PROBE] ‚ùå Curl –≤–µ—Ä–Ω—É–ª —Å—Ç—Ä–∞–Ω–Ω—ã–π –∫–æ–¥: {http_code}")
                        return False, f"HTTP {http_code}"
                except ValueError:
                    LOG.debug(f"[PROBE] ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–¥–∞ –æ—Ç–≤–µ—Ç–∞ curl: {stdout}")
                    return False, "Invalid curl output"
            else:
                err_msg = stderr.decode().strip()
                LOG.debug(f"[PROBE] ‚ùå Curl –æ—à–∏–±–∫–∞ (code {process.returncode}): {err_msg}")
                return False, f"Curl error {process.returncode}"

        except Exception as e:
            LOG.debug(f"[PROBE] ‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è curl: {e}")
            return False, f"Execution error: {e}"
    
    async def _probe_https_with_metrics(self, domain: str, timeout: float) -> ConnectionMetrics:
        """
        Task 2.3: Enhanced HTTPS probe that collects ConnectionMetrics.
        
        –ü—Ä–æ–≤–µ—Ä–∫–∞ HTTPS –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º —Å–±–æ—Ä–æ–º –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç curl —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –≤—ã–≤–æ–¥–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–∞–π–º–∏–Ω–≥–æ–≤.
        """
        if not CONNECTION_METRICS_AVAILABLE:
            # Fallback to old method
            success, error = await self._probe_https(domain, timeout)
            return None
        
        LOG.debug(f"[PROBE_METRICS] –ü—Ä–æ–≤–µ—Ä–∫–∞ {domain} —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º —Å–±–æ—Ä–æ–º –º–µ—Ç—Ä–∏–∫ (timeout: {timeout}s)")
        
        metrics = ConnectionMetrics()
        start_time = time.time()
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º null —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            null_dev = "NUL" if sys.platform == "win32" else "/dev/null"
            
            # –ò—â–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π curl.exe
            curl_exe = "curl"
            if sys.platform == "win32":
                import os
                local_curl = Path("curl.exe")
                if local_curl.exists():
                    curl_exe = str(local_curl.absolute())
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ curl –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–∞–π–º–∏–Ω–≥–æ–≤
            # %{time_connect} - TCP handshake time
            # %{time_appconnect} - TLS handshake time (total –¥–æ app layer)
            # %{time_starttransfer} - TTFB
            # %{time_total} - Total time
            # %{http_code} - HTTP status
            # %{size_download} - Bytes received
            format_str = "%{time_connect}|%{time_appconnect}|%{time_starttransfer}|%{time_total}|%{http_code}|%{size_download}"
            
            cmd = [
                curl_exe,
                "-I", "-s", "-k",
                "--http2",
                "--tlsv1.2",
                "--ciphers", BROWSER_CIPHER_LIST,
                "-H", "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "--connect-timeout", str(int(timeout)),
                "--max-time", str(int(timeout) + 2),
                "-o", null_dev,
                "-w", format_str,
                f"https://{domain}"
            ]
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è
            metrics.total_time_ms = (time.time() - start_time) * 1000
            
            if process.returncode == 0:
                try:
                    # –ü–∞—Ä—Å–∏–º –≤—ã–≤–æ–¥ curl
                    output = stdout.decode().strip()
                    parts = output.split('|')
                    
                    if len(parts) == 6:
                        time_connect = float(parts[0]) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                        time_appconnect = float(parts[1]) * 1000
                        time_starttransfer = float(parts[2]) * 1000
                        time_total = float(parts[3]) * 1000
                        http_code = int(parts[4])
                        size_download = int(float(parts[5]))
                        
                        # –ó–∞–ø–æ–ª–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                        metrics.connect_time_ms = time_connect
                        metrics.tls_time_ms = time_appconnect - time_connect if time_appconnect > time_connect else 0.0
                        metrics.ttfb_ms = time_starttransfer
                        metrics.total_time_ms = time_total
                        metrics.http_status = http_code if http_code > 0 else None
                        metrics.bytes_received = size_download
                        metrics.tls_completed = time_appconnect > 0
                        
                        LOG.debug(f"[PROBE_METRICS] ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ–±—Ä–∞–Ω—ã: connect={metrics.connect_time_ms:.1f}ms, "
                                f"tls={metrics.tls_time_ms:.1f}ms, ttfb={metrics.ttfb_ms:.1f}ms, "
                                f"http={metrics.http_status}, bytes={metrics.bytes_received}")
                    else:
                        LOG.warning(f"[PROBE_METRICS] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ curl: {output}")
                        metrics.error = "Invalid curl output format"
                        
                except (ValueError, IndexError) as e:
                    LOG.warning(f"[PROBE_METRICS] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–µ—Ç—Ä–∏–∫: {e}")
                    metrics.error = f"Parse error: {e}"
            else:
                # Curl –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É
                err_msg = stderr.decode().strip()
                metrics.error = f"Curl error {process.returncode}: {err_msg}"
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏
                if "timeout" in err_msg.lower() or "timed out" in err_msg.lower():
                    metrics.timeout = True
                elif "connection refused" in err_msg.lower():
                    metrics.error = "Connection refused"
                elif "reset" in err_msg.lower() or "rst" in err_msg.lower():
                    metrics.rst_received = True
                    metrics.rst_timing_ms = metrics.total_time_ms
                
                LOG.debug(f"[PROBE_METRICS] ‚ùå Curl –æ—à–∏–±–∫–∞: {metrics.error}")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            metrics.block_type = metrics.detect_block_type()
            
            return metrics
            
        except Exception as e:
            LOG.error(f"[PROBE_METRICS] ‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–±–æ—Ä–µ –º–µ—Ç—Ä–∏–∫: {e}")
            metrics.error = f"Exception: {e}"
            metrics.total_time_ms = (time.time() - start_time) * 1000
            metrics.block_type = BlockType.UNKNOWN
            return metrics

    async def _is_domain_accessible(self, domain: str) -> bool:
        """
        === –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: –î–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è 2xx/3xx ===
        Task 6.2: Use DoHIntegration for DNS resolution
        
        –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö connectivity checks, –Ω–µ –¥–ª—è strategy testing.
        Strategy testing –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ test_strategy_like_testing_mode —Å curl.
        """
        # –î–ª—è connectivity check –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        # –†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –±–æ–ª—å—à–∏–º ClientHello –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ test_strategy_like_testing_mode
        success, error = await self._probe_https(domain, self.config.connection_timeout)
        return success

    def clear_caches(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫—ç—à–µ–π"""
        with self._cache_lock:
            self._fingerprint_cache.clear()
            self._strategy_cache.clear()
            self._domain_accessibility_cache.clear()
            self._protocol_preference_cache.clear()
        
        # –û—á–∏—â–∞–µ–º LRU –∫—ç—à –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        # The @lru_cache decorator has been removed, so cache_clear is not available
        
        LOG.info("All caches cleared")
    
    def _convert_strategy_to_string(self, strategy: Any) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è GeneratedStrategy –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è bypass engine (legacy)"""
        try:
            if hasattr(strategy, 'attack_combination') and strategy.attack_combination:
                # –î–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
                attacks = strategy.attack_combination
                params = getattr(strategy, 'parameters', {})
                
                # –°—Ç—Ä–æ–∏–º zapret-style –∫–æ–º–∞–Ω–¥—É
                parts = []
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ attacks
                attacks = [a for a in attacks if a is not None and isinstance(a, str)]
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
                if len(attacks) == 1:
                    parts.append(f"--dpi-desync={attacks[0]}")
                elif len(attacks) > 1:
                    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞—Ç–∞–∫–∏
                    parts.append(f"--dpi-desync={','.join(attacks)}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                if 'ttl' in params:
                    parts.append(f"--dpi-desync-ttl={params['ttl']}")
                if 'split_pos' in params:
                    parts.append(f"--dpi-desync-split-pos={params['split_pos']}")
                if 'split_count' in params:
                    parts.append(f"--dpi-desync-split-count={params['split_count']}")
                if 'fooling' in params:
                    fooling = params['fooling']
                    if isinstance(fooling, list):
                        fooling = ','.join(fooling)
                    parts.append(f"--dpi-desync-fooling={fooling}")
                
                return ' '.join(parts)
            
            elif hasattr(strategy, 'name'):
                # Fallback - –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ –∏–º–µ–Ω–∏
                return f"--dpi-desync={getattr(strategy, 'name', 'fake')} --dpi-desync-ttl=3"
            
            else:
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback
                return "--dpi-desync=fake --dpi-desync-ttl=3"
                
        except Exception as e:
            LOG.warning(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {e}")
            return "--dpi-desync=fake --dpi-desync-ttl=3"
    
    async def _test_with_basic_engine(self, domain: str, strategy_string: str) -> Dict[str, Any]:
        """–ë–∞–∑–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ bypass engine"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ subprocess
            LOG.debug(f"Testing {domain} with strategy: {strategy_string}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º CLI —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            result = await self._run_cli_test(domain, strategy_string)
            
            return {
                "success": getattr(result, 'success', False) if hasattr(result, 'success') else (result.get("success", False) if hasattr(result, 'get') else False),
                "error": getattr(result, 'error', None) if hasattr(result, 'error') else (result.get("error") if hasattr(result, 'get') else None),
                "response_time": getattr(result, 'response_time', 0.0) if hasattr(result, 'response_time') else (result.get("response_time", 0.0) if hasattr(result, 'get') else 0.0)
            }
            
        except Exception as e:
            LOG.warning(f"CLI test failed: {e}, using direct engine test")
            
            # –ü—Ä—è–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ bypass engine
            try:
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–æ–º–µ–Ω–∞ —Å–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
                import tempfile
                
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
                with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                    f.write(strategy_string)
                    strategy_file = f.name
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ CLI
                # –†–∞–∑–±–∏–≤–∞–µ–º strategy_string –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                strategy_parts = strategy_string.split()
                
                cmd = [
                    'python', 'cli.py', domain,
                    '--timeout', '10'
                ] + strategy_parts  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
                
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=15
                )
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                success = result.returncode == 0
                
                return {
                    "success": success,
                    "error": result.stderr if result.stderr else None,
                    "response_time": 0.0
                }
            except Exception as e:
                LOG.error(f"–û—à–∏–±–∫–∞ –±–∞–∑–æ–≤–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "response_time": 0.0
                }
    
    async def _test_with_fallback_method(self, domain: str, strategy: Any, target_ip: str) -> Dict[str, Any]:
        """
        Fallback –º–µ—Ç–æ–¥ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ curl —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É IP.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç --resolve –∏ --ciphers –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —ç–º—É–ª—è—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞.
        """
        LOG.debug(f"Using fallback curl testing for {domain} on IP {target_ip}")
        
        start_time = time.time()
        
        try:
            null_dev = "NUL" if sys.platform == "win32" else "/dev/null"
            
            # –ò—â–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π curl
            curl_exe = "curl"
            if sys.platform == "win32":
                import os
                local_curl = Path("curl.exe")
                if local_curl.exists():
                    curl_exe = str(local_curl.absolute())

            cmd = [
                curl_exe,
                "-I", "-s", "-k",
                "--http2",
                "--tlsv1.2",
                "--ciphers", BROWSER_CIPHER_LIST, # <--- –ö–†–ò–¢–ò–ß–ù–û
                "-H", "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "--connect-timeout", str(int(self.config.connection_timeout)),
                "--max-time", str(int(self.config.connection_timeout) + 2),
                "--resolve", f"{domain}:443:{target_ip}",
                "-o", null_dev,
                "-w", "%{http_code}",
                f"https://{domain}"
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            response_time = time.time() - start_time
            
            if process.returncode == 0:
                try:
                    output = stdout.decode().strip()
                    if not output or output == "000":
                        return {
                            "success": False,
                            "error": "No HTTP response (000)",
                            "response_time": response_time,
                            "real_test": False,
                            "fallback_test": True,
                            "target_ip": target_ip
                        }

                    http_code = int(output)
                    if 0 < http_code < 600:
                        LOG.info(f"[TEST] Fallback curl successful for {domain} on {target_ip} (HTTP {http_code})")
                        return {
                            "success": True,
                            "error": None,
                            "response_time": response_time,
                            "real_test": False,
                            "fallback_test": True,
                            "target_ip": target_ip,
                            "http_code": http_code
                        }
                    else:
                        return {
                            "success": False,
                            "error": f"HTTP {http_code}",
                            "response_time": response_time,
                            "real_test": False,
                            "fallback_test": True,
                            "target_ip": target_ip
                        }
                except ValueError:
                    return {
                        "success": False,
                        "error": "Invalid curl output",
                        "response_time": response_time,
                        "real_test": False,
                        "fallback_test": True,
                        "target_ip": target_ip
                    }
            else:
                err_msg = stderr.decode().strip()
                LOG.debug(f"[TEST] Fallback curl failed for {domain}: {err_msg}")
                return {
                    "success": False,
                    "error": f"Curl error {process.returncode}",
                    "response_time": response_time,
                    "real_test": False,
                    "fallback_test": True,
                    "target_ip": target_ip
                }
                        
        except Exception as e:
            LOG.error(f"Fallback test error: {e}")
            return {
                "success": False,
                "error": f"Fallback execution error: {str(e)}",
                "response_time": 0.0,
                "real_test": False,
                "fallback_test": True
            }
    
    async def _run_cli_test(self, domain: str, strategy_string: str) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ CLI subprocess"""
        try:
            import subprocess
            import tempfile
            import os
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                f.write(strategy_string)
                strategy_file = f.name
            
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ CLI
                # –†–∞–∑–±–∏–≤–∞–µ–º strategy_string –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                strategy_parts = strategy_string.split()
                
                cmd = [
                    'python', 'cli.py', domain,
                    '--timeout', '10',
                    '--quiet'  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
                ] + strategy_parts  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
                
                LOG.debug(f"Running CLI command: {' '.join(cmd)}")
                
                start_time = time.time()
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=15,
                    cwd=os.getcwd()
                )
                response_time = time.time() - start_time
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                success = result.returncode == 0
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –≤—ã–≤–æ–¥—É
                if success and result.stdout:
                    # –ò—â–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —É—Å–ø–µ—Ö–∞ –≤ –≤—ã–≤–æ–¥–µ
                    success_indicators = ["SUCCESS", "[OK]", "WORKING", "BYPASS"]
                    failure_indicators = ["FAILED", "[FAIL]", "ERROR", "BLOCKED"]
                    
                    stdout_upper = result.stdout.upper()
                    
                    if any(indicator in stdout_upper for indicator in failure_indicators):
                        success = False
                    elif not any(indicator in stdout_upper for indicator in success_indicators):
                        # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤, —Å—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º –µ—Å–ª–∏ returncode == 0
                        pass
                
                LOG.debug(f"CLI test result: success={success}, returncode={result.returncode}")
                
                return {
                    "success": success,
                    "error": result.stderr if result.stderr else None,
                    "response_time": response_time,
                    "stdout": result.stdout,
                    "returncode": result.returncode
                }
                
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                try:
                    os.unlink(strategy_file)
                except:
                    pass
                    
        except Exception as e:
            # Check if it's a timeout error
            if "timeout" in str(e).lower() or "timed out" in str(e).lower():
                return {
                    "success": False,
                    "error": "CLI test timeout (15s)",
                    "response_time": 15.0
                }
            else:
                LOG.error(f"CLI test error: {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "response_time": 0.0
                }
    
    def _restore_tweaks(self):
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è tweaks.
        
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏,
        –æ—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è.
        """
        if hasattr(self, '_original_config_values'):
            for key, value in self._original_config_values.items():
                if hasattr(self.config, key):
                    setattr(self.config, key, value)
                    if key == "strategy_timeout":
                        LOG.info(f"üïí –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç: {value}s")
            
            # –û—á–∏—â–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            self._original_config_values.clear()
            LOG.debug("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ tweaks
        if hasattr(self, '_current_ttl_adjustment'):
            delattr(self, '_current_ttl_adjustment')
        if hasattr(self, '_current_split_hint'):
            delattr(self, '_current_split_hint')
        if hasattr(self, '_current_split_multiplier'):
            delattr(self, '_current_split_multiplier')
        if hasattr(self, '_current_disorder_enabled'):
            delattr(self, '_current_disorder_enabled')
        if hasattr(self, '_current_timeout_factor'):
            delattr(self, '_current_timeout_factor')

    def _build_context(self, domain: str, fingerprint: Any) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è Pattern Matcher.
        
        –°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å domain, timestamp, –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ fingerprint 
        (IP, ASN, dpi_type, dpi_mode), —Ä–µ–∞–ª–∏–∑—É–µ—Ç _lookup_asn() –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ASN,
        –¥–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            fingerprint: DPI fingerprint —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è Pattern Matcher
        """
        context = {
            "domain": domain,
            "timestamp": datetime.now().isoformat(),
            "environment": {
                "platform": "windows",
                "engine_version": "adaptive_v2"
            }
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ fingerprint
        if fingerprint:
            try:
                # –û—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ DPI
                context["dpi_type"] = fingerprint.dpi_type.value if hasattr(fingerprint.dpi_type, 'value') else str(fingerprint.dpi_type)
                context["dpi_mode"] = fingerprint.dpi_mode.value if hasattr(fingerprint.dpi_mode, 'value') else str(fingerprint.dpi_mode)
                
                # IP –∞–¥—Ä–µ—Å –∏ ASN
                if hasattr(fingerprint, 'target_ip') and fingerprint.target_ip:
                    context["target_ip"] = fingerprint.target_ip
                    context["asn"] = self._lookup_asn(fingerprint.target_ip)
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å IP —á–µ—Ä–µ–∑ DNS
                    try:
                        import socket
                        target_ip = socket.gethostbyname(domain)
                        context["target_ip"] = target_ip
                        context["asn"] = self._lookup_asn(target_ip)
                    except Exception as e:
                        LOG.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å IP –¥–ª—è {domain}: {e}")
                        context["target_ip"] = None
                        context["asn"] = None
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                if hasattr(fingerprint, 'block_timing'):
                    context["block_timing"] = fingerprint.block_timing
                if hasattr(fingerprint, 'rst_timing_ms'):
                    context["rst_timing_ms"] = fingerprint.rst_timing_ms
                if hasattr(fingerprint, 'connection_established'):
                    context["connection_established"] = fingerprint.connection_established
                    
            except Exception as e:
                LOG.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ fingerprint: {e}")
        
        return context
    
    def _lookup_asn(self, ip_address: str) -> Optional[int]:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ASN –¥–ª—è IP –∞–¥—Ä–µ—Å–∞.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –±–∞–∑—É ip2asn –∏–ª–∏ –≤–Ω–µ—à–Ω–∏–µ —Å–µ—Ä–≤–∏—Å—ã
        –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã.
        
        Args:
            ip_address: IP –∞–¥—Ä–µ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            ASN –Ω–æ–º–µ—Ä –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        if not ip_address:
            return None
            
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ASN –ø–æ IP
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–∞–∑–∞ ip2asn
            
            # Cloudflare
            if ip_address.startswith(('104.16.', '104.17.', '172.64.', '108.162.')):
                return 13335
            # Google
            elif ip_address.startswith(('8.8.', '172.217.', '216.58.', '142.250.')):
                return 15169
            # Amazon AWS
            elif ip_address.startswith(('52.', '54.', '3.', '18.')):
                return 16509
            # Akamai
            elif ip_address.startswith(('23.', '104.64.')):
                return 20940
            # Fastly
            elif ip_address.startswith(('151.101.', '199.232.')):
                return 54113
            else:
                # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö IP –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
                return None
                
        except Exception as e:
            LOG.debug(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è ASN –¥–ª—è {ip_address}: {e}")
            return None

    def _calculate_adaptive_timeout(self, domain: str, fingerprint: Any = None, failure_report: Any = None) -> float:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ DPI –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏.
        
        –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ DPI_CONTENT_INSPECTION (factor 1.5-2.0),
        —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ RST-–∏–Ω—ä–µ–∫—Ü–∏—è—Ö,
        –ø—Ä–∏–º–µ–Ω—è–µ—Ç timeout tweaks –∏–∑ –ø—Ä–∞–≤–∏–ª.
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            fingerprint: DPI fingerprint —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–∏–ø–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            failure_report: –û—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ –Ω–µ—É–¥–∞—á–∏
            
        Returns:
            –í—ã—á–∏—Å–ª–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        base_timeout = self.config.strategy_timeout
        
        # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø DPI –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –∏–∑ fingerprint
        dpi_type = None
        if fingerprint and hasattr(fingerprint, 'dpi_type'):
            dpi_type = fingerprint.dpi_type.value if hasattr(fingerprint.dpi_type, 'value') else str(fingerprint.dpi_type)
        
        # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏–∑ failure_report (–±–æ–ª–µ–µ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
        if failure_report and hasattr(failure_report, 'root_cause'):
            root_cause = failure_report.root_cause.value if hasattr(failure_report.root_cause, 'value') else str(failure_report.root_cause)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –º–Ω–æ–∂–∏—Ç–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            if root_cause == "DPI_CONTENT_INSPECTION":
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –≥–ª—É–±–æ–∫–æ–π –∏–Ω—Å–ø–µ–∫—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                timeout_factor = self.config.timeout_factor_content_inspection
                calculated_timeout = base_timeout * timeout_factor
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.timeout_stats["content_inspection_adjustments"] += 1
                self.timeout_stats["adaptive_timeouts_applied"] += 1
                self._update_average_timeout_factor(timeout_factor)
                
                LOG.info(f"üïí –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞ –¥–ª—è DPI_CONTENT_INSPECTION: "
                        f"{base_timeout}s * {timeout_factor} = {calculated_timeout}s")
                return calculated_timeout
                
            elif root_cause in ["DPI_ACTIVE_RST_INJECTION", "DPI_STATEFUL_TRACKING"]:
                # –ù–ï —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –ø—Ä–∏ RST-–∏–Ω—ä–µ–∫—Ü–∏—è—Ö (–æ–Ω–∏ –±—ã—Å—Ç—Ä—ã–µ)
                self.timeout_stats["rst_injection_adjustments"] += 1
                LOG.info(f"üïí –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è RST-–∏–Ω—ä–µ–∫—Ü–∏–π: {base_timeout}s")
                return base_timeout
                
            elif root_cause in ["DPI_SNI_FILTERING", "DPI_REASSEMBLES_FRAGMENTS"]:
                # –ù–µ–±–æ–ª—å—à–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ DPI
                timeout_factor = 1.3
                calculated_timeout = base_timeout * timeout_factor
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.timeout_stats["adaptive_timeouts_applied"] += 1
                self._update_average_timeout_factor(timeout_factor)
                
                LOG.info(f"üïí –£–º–µ—Ä–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞ –¥–ª—è {root_cause}: "
                        f"{base_timeout}s * {timeout_factor} = {calculated_timeout}s")
                return calculated_timeout
        
        # 3. –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö CDN –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–º–µ–Ω–∞
        slow_cdn_domains = [
            "googlevideo.com", "ytimg.com", "ggpht.com",
            "tiktokcdn.com", "cdninstagram.com", "twimg.com"
        ]
        
        if any(cdn_domain in domain for cdn_domain in slow_cdn_domains):
            timeout_factor = self.config.timeout_factor_slow_cdn
            calculated_timeout = base_timeout * timeout_factor
            self.timeout_stats["slow_cdn_adjustments"] += 1
            self.timeout_stats["adaptive_timeouts_applied"] += 1
            LOG.info(f"üïí –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞ –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ CDN ({domain}): "
                    f"{base_timeout}s * {timeout_factor} = {calculated_timeout}s")
            return calculated_timeout
        
        # 4. –ë–∞–∑–æ–≤—ã–π —Ç–∞–π–º–∞—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        LOG.debug(f"üïí –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π —Ç–∞–π–º–∞—É—Ç: {base_timeout}s")
        return base_timeout

    def _apply_tweaks(self, tweaks: Dict[str, Any]):
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ tweaks –∏–∑ –ø—Ä–∞–≤–∏–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.
        
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç strategy_timeout_factor, ttl_adjustment, split_position_hint,
        enable_ipv6_fallback. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è.
        –õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ tweaks.
        
        Tweaks –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –≤—Ä–µ–º–µ–Ω–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏.
        
        Args:
            tweaks: –°–ª–æ–≤–∞—Ä—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ PatternRule
        """
        if not tweaks:
            return
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if not hasattr(self, '_original_config_values'):
            self._original_config_values = {}
        
        # strategy_timeout_factor
        if "strategy_timeout_factor" in tweaks:
            factor = float(tweaks["strategy_timeout_factor"])
            if "strategy_timeout" not in self._original_config_values:
                self._original_config_values["strategy_timeout"] = self.config.strategy_timeout
            self.config.strategy_timeout *= factor
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º factor –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ _calculate_adaptive_timeout
            self._current_timeout_factor = factor
            LOG.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω tweak: strategy_timeout *= {factor} = {self.config.strategy_timeout}")
        
        # ttl_adjustment
        if "ttl_adjustment" in tweaks:
            adjustment = int(tweaks["ttl_adjustment"])
            # TTL adjustment –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            self._current_ttl_adjustment = adjustment
            LOG.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω tweak: ttl_adjustment = {adjustment}")
        
        # split_position_hint
        if "split_position_hint" in tweaks:
            hint = tweaks["split_position_hint"]
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            self._current_split_hint = hint
            LOG.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω tweak: split_position_hint = {hint}")
        
        # enable_ipv6_fallback
        if "enable_ipv6_fallback" in tweaks:
            enable = bool(tweaks["enable_ipv6_fallback"])
            if "enable_ipv6_fallback" not in self._original_config_values:
                self._original_config_values["enable_ipv6_fallback"] = getattr(self.config, 'enable_ipv6_fallback', False)
            self.config.enable_ipv6_fallback = enable
            LOG.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω tweak: enable_ipv6_fallback = {enable}")
        
        # split_count_multiplier
        if "split_count_multiplier" in tweaks:
            multiplier = int(tweaks["split_count_multiplier"])
            self._current_split_multiplier = multiplier
            LOG.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω tweak: split_count_multiplier = {multiplier}")
        
        # disorder_enabled
        if "disorder_enabled" in tweaks:
            enabled = bool(tweaks["disorder_enabled"])
            self._current_disorder_enabled = enabled
            LOG.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω tweak: disorder_enabled = {enabled}")

    def _merge_queues(self,
                     base: List[Any],
                     extra: List[Any],
                     start_from: int) -> List[Any]:
        """
        –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –¥–ª—è –Ω–æ–≤—ã—Ö –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞.
        
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –±–∞–∑–æ–≤—É—é –æ—á–µ—Ä–µ–¥—å —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏,
        –≤—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º, –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç
        –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é –æ—á–µ—Ä–µ–¥—å, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–æ 50 —Å—Ç—Ä–∞—Ç–µ–≥–∏–π,
        —É–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å –Ω–∏–∑–∫–∏–º expected_success_rate –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞.
        
        Args:
            base: –ë–∞–∑–æ–≤–∞—è –æ—á–µ—Ä–µ–¥—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            extra: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ)
            start_from: –ò–Ω–¥–µ–∫—Å, —Å –∫–æ—Ç–æ—Ä–æ–≥–æ –≤—Å—Ç–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –æ—á–µ—Ä–µ–¥—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (–º–∞–∫—Å–∏–º—É–º 50 —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
        """
        MAX_QUEUE_SIZE = 50  # –ú–∞–∫—Å–∏–º—É–º 50 —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ –æ—á–µ—Ä–µ–¥–∏
        
        if not extra:
            return self._limit_queue_size(base, MAX_QUEUE_SIZE)
        
        if not base:
            deduped = self._dedup_strategies(extra)
            return self._limit_queue_size(deduped, MAX_QUEUE_SIZE)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –æ—á–µ—Ä–µ–¥—å –Ω–∞ –¥–≤–µ —á–∞—Å—Ç–∏
        head = base[:start_from] if start_from > 0 else []
        tail = base[start_from:] if start_from < len(base) else []
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º extra + tail —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π
        merged_tail = self._dedup_strategies(extra + tail)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ—á–µ—Ä–µ–¥—å
        merged = head + merged_tail
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏
        limited_queue = self._limit_queue_size(merged, MAX_QUEUE_SIZE)
        
        LOG.debug(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥–µ–π: {len(base)} + {len(extra)} -> {len(merged)} -> {len(limited_queue)} "
                 f"(–≤—Å—Ç–∞–≤–∫–∞ —Å –ø–æ–∑–∏—Ü–∏–∏ {start_from}, –ª–∏–º–∏—Ç {MAX_QUEUE_SIZE})")
        
        return limited_queue
    
    def _limit_queue_size(self, strategies: List[Any], max_size: int) -> List[Any]:
        """
        –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –æ—á–µ—Ä–µ–¥–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å —É–¥–∞–ª–µ–Ω–∏–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å –Ω–∏–∑–∫–∏–º success_rate.
        
        Args:
            strategies: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            max_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏
            
        Returns:
            –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        """
        if len(strategies) <= max_size:
            return strategies
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ expected_success_rate (—É–±—ã–≤–∞–Ω–∏–µ)
        sorted_strategies = sorted(
            strategies,
            key=lambda s: self._get_strategy_success_rate(s),
            reverse=True
        )
        
        # –ë–µ—Ä–µ–º —Ç–æ–ø max_size —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        limited = sorted_strategies[:max_size]
        removed_count = len(strategies) - len(limited)
        
        LOG.info(f"üö´ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏: —É–¥–∞–ª–µ–Ω–æ {removed_count} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å –Ω–∏–∑–∫–∏–º success_rate, "
                f"–æ—Å—Ç–∞–ª–æ—Å—å {len(limited)}/{max_size}")
        
        return limited
    
    def _get_strategy_success_rate(self, strategy: Any) -> float:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ expected_success_rate —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.
        
        Args:
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            
        Returns:
            Expected success rate (0.0 - 1.0)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—Ç—Ä–∏–±—É—Ç–∞ expected_success_rate
        if hasattr(strategy, 'expected_success_rate'):
            return float(strategy.expected_success_rate)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        if hasattr(strategy, 'metadata') and strategy.metadata:
            if 'expected_success_rate' in strategy.metadata:
                return float(strategy.metadata['expected_success_rate'])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
        if hasattr(strategy, 'parameters') and strategy.parameters:
            if 'success_rate' in strategy.parameters:
                return float(strategy.parameters['success_rate'])
        
        # –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        if hasattr(strategy, 'name'):
            name = strategy.name.lower()
            
            # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
            if any(keyword in name for keyword in ['sni', 'fragment', 'ttl']):
                return 0.8
            
            # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
            if any(keyword in name for keyword in ['disorder', 'overlap', 'timing']):
                return 0.6
            
            # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
            if any(keyword in name for keyword in ['complex', 'multi', 'advanced']):
                return 0.4
        
        # –ë–∞–∑–æ–≤—ã–π success rate –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return 0.5

    def _dedup_strategies(self, strategies: List[Any]) -> List[Any]:
        """
        –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø–æ –∏–º–µ–Ω–∏ –∏ attack_combination.
        
        –°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –∏–∑ attack_combination, —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã
        —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞, –ª–æ–≥–∏—Ä—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
        
        Args:
            strategies: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        """
        if not strategies:
            return []
        
        seen = set()
        unique = []
        
        for strategy in strategies:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –∏–∑ attack_combination –∏ –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if hasattr(strategy, 'attack_combination') and strategy.attack_combination:
                key_parts = [tuple(sorted(strategy.attack_combination))]
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                if hasattr(strategy, 'parameters') and strategy.parameters:
                    params = strategy.parameters
                    key_params = []
                    for param_name in ['ttl', 'split_pos', 'split_count', 'fooling']:
                        if param_name in params:
                            key_params.append(f"{param_name}={params[param_name]}")
                    key_parts.append(tuple(sorted(key_params)))
                
                key = tuple(key_parts)
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
                key = getattr(strategy, 'name', str(strategy))
            
            if key not in seen:
                seen.add(key)
                unique.append(strategy)
        
        removed_count = len(strategies) - len(unique)
        if removed_count > 0:
            LOG.debug(f"–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: —É–¥–∞–ª–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, "
                     f"–æ—Å—Ç–∞–ª–æ—Å—å {len(unique)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
        
        return unique

    async def _augment_strategies_from_failure(self,
                                              domain: str,
                                              strategy: Any,
                                              result: Dict[str, Any],
                                              fingerprint: Any,
                                              context: Dict[str, Any]) -> List[Any]:
        """
        –ù–û–í–´–ô –ú–ï–¢–û–î: –î–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—É–¥–∞—á–∏ —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
        
        Workflow:
        1. –ê–Ω–∞–ª–∏–∑ PCAP —á–µ—Ä–µ–∑ SFA
        2. –ü–æ–ª—É—á–µ–Ω–∏–µ suggested_intents –∏–∑ FailureReport
        3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ PatternMatcher
        4. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ intent'–æ–≤ –∏–∑ SFA –∏ KnowledgeBase
        5. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ tweaks —á–µ—Ä–µ–∑ _apply_tweaks()
        6. –°–æ–∑–¥–∞–Ω–∏–µ StrategyIntent —á–µ—Ä–µ–∑ SIE.from_keys()
        7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —á–µ—Ä–µ–∑ StrategyGenerator
        8. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        9. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ DPI fingerprint
        10. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ negative knowledge
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –æ—à–∏–±–∫–æ–π
            fingerprint: DPI fingerprint
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç (ASN, IP, domain –∏ —Ç.–¥.)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –º–µ—Ç–æ–¥–∞
        method_start_time = time.time()
        
        if not self.knowledge_accumulator or not self.pattern_matcher:
            LOG.warning("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
            return []
        
        # 1) –ê–Ω–∞–ª–∏–∑ PCAP —á–µ—Ä–µ–∑ SFA (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        pcap_file = None
        if hasattr(result, 'pcap_file'):
            pcap_file = getattr(result, 'pcap_file', None)
        elif hasattr(result, 'get'):
            pcap_file = result.get('pcap_file')
        elif hasattr(result, 'artifacts') and hasattr(result.artifacts, 'pcap_file'):
            pcap_file = getattr(result.artifacts, 'pcap_file', None)
        
        if not pcap_file:
            LOG.warning("PCAP —Ñ–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—É–¥–∞—á–∏")
            return []
        
        # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ PCAP
        pcap_analysis_start = time.time()
        try:
            # Ensure pcap_file is a string, not a Path object
            pcap_file_str = str(pcap_file) if pcap_file else None
            failure_report = await self.failure_analyzer.analyze_pcap(
                pcap_file_str, strategy, domain=domain
            )
        except Exception as e:
            LOG.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ PCAP: {e}")
            return []
        
        pcap_analysis_time = time.time() - pcap_analysis_start
        self._record_profiling_data("pcap_analysis", pcap_analysis_time)
        
        if not failure_report:
            LOG.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—É–¥–∞—á—É")
            return []
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
        self._last_failure_report = failure_report
        
        # 2) –î–æ—Å—Ç–∞—ë–º suggested_intents –∏–∑ SFA
        sfa_intents = failure_report.suggested_intents or []
        
        # 3) –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —á–µ—Ä–µ–∑ PatternMatcher
        pattern_matching_start = time.time()
        kb_intents, tweaks = self.pattern_matcher.apply_knowledge_rules(
            failure_report, context
        )
        pattern_matching_time = time.time() - pattern_matching_start
        self._record_profiling_data("pattern_matching", pattern_matching_time)
        
        if kb_intents:
            self.closed_loop_stats["pattern_matches"] += 1
            # Task 8.1: Record pattern match in metrics
            if self.metrics_collector:
                # Find which pattern matched (simplified approach)
                pattern_id = "unknown_pattern"
                if hasattr(failure_report, 'root_cause'):
                    pattern_id = f"pattern_{failure_report.root_cause.value}"
                self.metrics_collector.record_pattern_match(pattern_id, True)
        
        # 4) –û–±—ä–µ–¥–∏–Ω—è–µ–º intent'—ã –∏–∑ SFA –∏ KnowledgeBase
        # –§–∏–ª—å—Ç—Ä—É–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º
        sfa_intents = [intent for intent in (sfa_intents or []) if intent is not None]
        kb_intents = [intent for intent in (kb_intents or []) if intent is not None]
        all_intent_keys = list(dict.fromkeys(sfa_intents + kb_intents))
        
        if not all_intent_keys:
            LOG.debug("–ù–µ—Ç –Ω–æ–≤—ã—Ö intent'–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
            return []
        
        LOG.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(all_intent_keys)} intent'–æ–≤: {all_intent_keys}")
        self.closed_loop_stats["intents_generated"] += len(all_intent_keys)
        
        # Task 8.1: Record intents generated in metrics
        if self.metrics_collector:
            source = "SFA" if sfa_intents else "KnowledgeBase" if kb_intents else "Mixed"
            self.metrics_collector.record_intents_generated(all_intent_keys, source)
        
        # 5) –ü—Ä–∏–º–µ–Ω—è–µ–º tweaks
        if tweaks:
            self._apply_tweaks(tweaks)
        
        # 5.1) –û–±–Ω–æ–≤–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—É–¥–∞—á–∏
        current_timeout = self.config.strategy_timeout
        updated_timeout = self._update_adaptive_timeout_from_failure(domain, failure_report, current_timeout)
        if updated_timeout != current_timeout:
            self.config.strategy_timeout = updated_timeout
            LOG.info(f"üïê –û–±–Ω–æ–≤–ª–µ–Ω –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è {domain}: {updated_timeout:.1f}s")
        
        # 6) –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ StrategyIntent –æ–±—ä–µ–∫—Ç—ã —á–µ—Ä–µ–∑ SIE.from_keys()
        intent_creation_start = time.time()
        try:
            failure_intents = self.intent_engine.from_keys(all_intent_keys, base_weight=0.9)
        except Exception as e:
            LOG.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è StrategyIntent –∏–∑ –∫–ª—é—á–µ–π: {e}")
            return []
        intent_creation_time = time.time() - intent_creation_start
        self._record_profiling_data("intent_creation", intent_creation_time)
        
        # 7) –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø—É–ª —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —á–µ—Ä–µ–∑ StrategyGenerator
        strategy_generation_start = time.time()
        try:
            extra_strategies = await self.strategy_generator.generate_strategies(
                failure_intents, 
                fingerprint,
                max_strategies=10
            )
        except Exception as e:
            LOG.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {e}")
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            import traceback
            LOG.error(f"–ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
            return []
        strategy_generation_time = time.time() - strategy_generation_start
        self._record_profiling_data("strategy_generation", strategy_generation_time)
        
        # 8) –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        dedup_start = time.time()
        unique_strategies = self._dedup_strategies(extra_strategies)
        dedup_time = time.time() - dedup_start
        self._record_profiling_data("strategy_deduplication", dedup_time)
        
        # 9) –û–±–Ω–æ–≤–ª—è–µ–º DPI fingerprint
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º FailureReport –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è fingerprint service
            failure_dict = {
                "root_cause": failure_report.root_cause.value if hasattr(failure_report.root_cause, 'value') else str(failure_report.root_cause),
                "confidence": failure_report.confidence,
                "block_timing": failure_report.block_timing,
                "failure_details": failure_report.failure_details
            }
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ú–µ—Ç–æ–¥ –Ω–µ async, —É–±–∏—Ä–∞–µ–º await
            self.fingerprint_service.update_from_failure(domain, failure_dict)
        except Exception as e:
            LOG.warning(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è fingerprint: {e}")
        
        # 10) –û–±–Ω–æ–≤–ª—è–µ–º negative knowledge
        self.knowledge_accumulator.update_failure_pattern(
            failure_report, strategy, context
        )
        
        # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        total_method_time = time.time() - method_start_time
        self._record_profiling_data("augment_strategies_total", total_method_time)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è augmentation
        self._update_average_augmentation_time(total_method_time)
        
        LOG.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(unique_strategies)} –Ω–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—É–¥–∞—á–∏ "
                f"(–≤—Ä–µ–º—è: {total_method_time:.3f}s)")
        
        return unique_strategies

    async def find_best_strategy(self, domain: str, progress_callback=None, shared_pcap_file=None) -> StrategyResult:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Ä–∞–±–æ—á–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π
        
        –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–æ–∏—Å–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        –†–µ—à–µ–Ω–∏–µ: –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            progress_callback: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            shared_pcap_file: Shared PCAP file for continuous capture across all strategies
            
        Returns:
            StrategyResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞
        """
        start_time = time.time()
        trials_count = 0
        
        # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞
        LOG.info("=" * 80)
        LOG.info(f"üöÄ –ù–ê–ß–ê–õ–û –ê–î–ê–ü–¢–ò–í–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –î–û–ú–ï–ù–ê: {domain}")
        LOG.info(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: mode={self.config.mode}, max_trials={self.config.max_trials}")
        LOG.info(f"üîß –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: fingerprinting={self.config.enable_fingerprinting}, "
                f"failure_analysis={self.config.enable_failure_analysis}")
        LOG.info(f"‚öôÔ∏è Bypass Engine: {type(self.bypass_engine).__name__ if self.bypass_engine else 'None'}")
        LOG.info("=" * 80)
        
        if progress_callback:
            progress_callback(f"[SEARCH] üîç –ê–Ω–∞–ª–∏–∑ –¥–æ–º–µ–Ω–∞ {domain}...")
        
        # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        LOG.info(f"üìà –¢–µ–∫—É—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        LOG.info(f"   - –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–º–µ–Ω–æ–≤: {self.stats['domains_processed']}")
        LOG.info(f"   - –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {self.stats['strategies_found']}")
        LOG.info(f"   - –í—Å–µ–≥–æ –ø–æ–ø—ã—Ç–æ–∫: {self.stats['total_trials']}")
        LOG.info(f"   - Cache hits: {self.stats['cache_hits']}")
        LOG.info(f"   - Cache misses: {self.stats['cache_misses']}")
        
        # Task 11.2: Use shared PCAP file if provided, otherwise create new one
        # FIXED: No longer use shared PCAP file - each test creates its own PCAP
        # This ensures proper isolation and correct metadata for each strategy
        pcap_capturer = None
        pcap_file = None
        
        # Note: Individual PCAP files are created in _test_strategy_with_capture
        # based on strategy name, ensuring proper isolation and metadata
        
        # Task 16.1: Wrap entire method in try/finally to ensure PCAP capture is stopped
        try:
            # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (domain_rules.json - —Ä—É—á–Ω–∞—è –±–∞–∑–∞)
            if domain in self.best_strategies:
                strategy = self.best_strategies[domain]
                if progress_callback:
                    progress_callback(f"[INFO] –ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≤ domain_rules.json: {strategy.name}, –ø—Ä–æ–≤–µ—Ä—è–µ–º...")
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
                LOG.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ domain_rules.json {strategy.name} –¥–ª—è {domain}")
                
                try:
                    # FIXED: Use individual PCAP file for each test (not shared)
                    # This ensures each strategy has its own PCAP file with correct metadata
                    test_result = await self._test_strategy_with_capture(domain, strategy, shared_pcap_file=None)
                    
                    # Fix: Handle both TestResult object and dict
                    test_success = False
                    if test_result:
                        if hasattr(test_result, 'success'):
                            test_success = test_result.success
                        elif isinstance(test_result, dict):
                            test_success = test_result.get('success', False)
                    
                    if test_success:
                        if progress_callback:
                            progress_callback(f"[OK] –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ domain_rules.json —Ä–∞–±–æ—Ç–∞–µ—Ç: {strategy.name}")
                        
                        # Update statistics for saved strategy reuse
                        self.stats["domains_processed"] += 1
                        self.stats["cache_hits"] += 1
                        
                        return StrategyResult(
                            success=True,
                            strategy=strategy,
                            message=f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ domain_rules.json: {strategy.name}",
                            execution_time=time.time() - start_time
                        )
                    else:
                        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - —É–¥–∞–ª—è–µ–º –µ—ë –∏ –∏—â–µ–º –Ω–æ–≤—É—é
                        LOG.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ domain_rules.json {strategy.name} –±–æ–ª—å—à–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è {domain}")
                        if progress_callback:
                            progress_callback(f"[WARNING] –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ domain_rules.json –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º adaptive_knowledge.json...")
                        
                        # –£–¥–∞–ª—è–µ–º –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
                        del self.best_strategies[domain]
                        self.stats["cache_misses"] += 1
                        
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ –ø—Ä–æ–≤–µ—Ä–∫–µ adaptive_knowledge.json
                        LOG.info(f"üîÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º adaptive_knowledge.json –¥–ª—è {domain}")
                        
                except Exception as e:
                    LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ domain_rules.json: {e}")
                    if progress_callback:
                        progress_callback(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º adaptive_knowledge.json...")
                    
                    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
                    del self.best_strategies[domain]
                    self.stats["cache_misses"] += 1
        
            # Task 5.4: –®–∞–≥ 1.5: –ü—Ä–æ–≤–µ—Ä–∫–∞ adaptive_knowledge.json (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞)
            if self.adaptive_knowledge:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ adaptive_knowledge.json, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
                    adaptive_strategies = self.adaptive_knowledge.get_strategies_for_domain(domain)
                    
                    if adaptive_strategies:
                        LOG.info(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(adaptive_strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ adaptive_knowledge.json –¥–ª—è {domain}")
                        if progress_callback:
                            progress_callback(f"[INFO] –ù–∞–π–¥–µ–Ω–æ {len(adaptive_strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ adaptive_knowledge.json")
                        
                        # –ü—Ä–æ–±—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
                        for i, strategy_record in enumerate(adaptive_strategies[:3]):  # –ü—Ä–æ–±—É–µ–º —Ç–æ–ø-3
                            LOG.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {i+1}/{min(3, len(adaptive_strategies))} –∏–∑ adaptive_knowledge.json: "
                                   f"{strategy_record.strategy_name} (success_rate: {strategy_record.success_rate():.2%})")
                            
                            if progress_callback:
                                progress_callback(f"[TEST] –ü—Ä–æ–≤–µ—Ä–∫–∞ {strategy_record.strategy_name} "
                                               f"(success_rate: {strategy_record.success_rate():.2%})...")
                            
                            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ StrategyRecord
                            try:
                                from dataclasses import dataclass
                                
                                @dataclass
                                class AdaptiveStrategy:
                                    name: str
                                    type: str
                                    params: dict
                                    attack_name: str = None
                                    id: str = None
                                    
                                    def __post_init__(self):
                                        if self.attack_name is None:
                                            self.attack_name = self.type
                                        if self.id is None:
                                            self.id = f"adaptive_{self.name}"
                                    
                                    def to_dict(self):
                                        return {
                                            'type': self.type,
                                            'params': self.params
                                        }
                                
                                adaptive_strat = AdaptiveStrategy(
                                    name=strategy_record.strategy_name,
                                    type=strategy_record.strategy_name,
                                    params=strategy_record.strategy_params,
                                    attack_name=strategy_record.strategy_name,
                                    id=f"adaptive_{strategy_record.strategy_name}"
                                )
                                
                                # FIXED: Use individual PCAP file for each test (not shared)
                                # This ensures each strategy has its own PCAP file with correct metadata
                                test_result = await self._test_strategy_with_capture(domain, adaptive_strat, shared_pcap_file=None)
                                
                                # Fix: Handle both TestResult object and dict
                                test_success = False
                                if test_result:
                                    if hasattr(test_result, 'success'):
                                        test_success = test_result.success
                                    elif isinstance(test_result, dict):
                                        test_success = test_result.get('success', False)
                                
                                if test_success:
                                    LOG.info(f"‚úÖ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ adaptive_knowledge.json —Ä–∞–±–æ—Ç–∞–µ—Ç: {strategy_record.strategy_name}")
                                    if progress_callback:
                                        progress_callback(f"[OK] –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ adaptive_knowledge.json —Ä–∞–±–æ—Ç–∞–µ—Ç: {strategy_record.strategy_name}")
                                    
                                    # Update statistics
                                    self.stats["domains_processed"] += 1
                                    self.stats["cache_hits"] += 1
                                    
                                    # Task 7.4: Extract session_id from result for coordinator routing
                                    session_id = None
                                    if hasattr(test_result, 'metadata') and test_result.metadata:
                                        session_id = test_result.metadata.get('session_id')
                                    elif isinstance(test_result, dict):
                                        session_id = test_result.get('session_id')
                                    
                                    # Task 7.4: Save working strategy through coordinator
                                    await self._save_working_strategy(domain, adaptive_strat, pcap_file, session_id)
                                    
                                    return StrategyResult(
                                        success=True,
                                        strategy=adaptive_strat,
                                        message=f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ adaptive_knowledge.json: {strategy_record.strategy_name}",
                                        execution_time=time.time() - start_time
                                    )
                                else:
                                    LOG.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞—Ç–µ–≥–∏—è {strategy_record.strategy_name} –∏–∑ adaptive_knowledge.json –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
                                    
                            except Exception as e:
                                LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ adaptive_knowledge.json: {e}")
                                continue
                    
                        LOG.info(f"üìö –ù–∏ –æ–¥–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ adaptive_knowledge.json –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
                        if progress_callback:
                            progress_callback(f"[INFO] –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ adaptive_knowledge.json –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ...")
                    else:
                        LOG.info(f"üìö –ù–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ adaptive_knowledge.json –¥–ª—è {domain}")
                        
                except Exception as e:
                    LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ adaptive_knowledge.json: {e}")
                    if progress_callback:
                        progress_callback(f"[WARNING] –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ adaptive_knowledge.json")
            
            # –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
            # For certain domains known to use subdomains, we should proceed with strategy testing
            # even if the main domain is accessible
            known_subdomain_domains = [
            "googlevideo.com",
            "ytimg.com",
            "ggpht.com",
            "youtube.com",
            "ytimg.l.google.com"
            ]
        
            domain_needs_bypass_check = any(subdomain_domain in domain for subdomain_domain in known_subdomain_domains)
        
            if await self._is_domain_accessible(domain):
                # If it's not a known subdomain domain, we can skip bypass strategies
                if not domain_needs_bypass_check:
                    if progress_callback:
                        progress_callback("[OK] –î–æ–º–µ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω –±–µ–∑ –æ–±—Ö–æ–¥–∞")
                    
                    # Update statistics for accessible domain
                    self.stats["domains_processed"] += 1
                    
                    return StrategyResult(
                        success=True,
                        message="–î–æ–º–µ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω –±–µ–∑ –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫",
                        execution_time=time.time() - start_time
                    )
                else:
                    if progress_callback:
                        progress_callback("[INFO] –î–æ–º–µ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ö–æ–¥–∞ –¥–ª—è –ø–æ–¥–¥–æ–º–µ–Ω–æ–≤")
            else:
                if progress_callback:
                    progress_callback("[INFO] –î–æ–º–µ–Ω –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω, —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±—Ö–æ–¥")
            
            # –®–∞–≥ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ/—Å–æ–∑–¥–∞–Ω–∏–µ DPI fingerprint —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            if progress_callback:
                progress_callback("[STATS] –ê–Ω–∞–ª–∏–∑ DPI —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫...")
        
            fingerprint_start_time = time.time()
            fingerprint = None
        
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à fingerprint'–æ–≤
                fingerprint = self._get_cached_fingerprint(domain)
                
                if fingerprint is None:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π fingerprint
                    fingerprint = self.fingerprint_service.get_or_create(domain)
                    if fingerprint:
                        self._cache_fingerprint(domain, fingerprint)
                        self.stats["fingerprints_created"] += 1
                
                if fingerprint:
                    if progress_callback:
                        progress_callback(f"[STATS] DPI —Ç–∏–ø: {fingerprint.dpi_type.value}")
                        
            except Exception as e:
                LOG.warning(f"Failed to create DPI fingerprint for {domain}: {e}")
                if progress_callback:
                    progress_callback("[WARN] DPI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏")
            
            fingerprint_time = time.time() - fingerprint_start_time
            self.stats["fingerprint_creation_time"] = (
                (self.stats["fingerprint_creation_time"] * self.stats["domains_processed"] + fingerprint_time) /
                (self.stats["domains_processed"] + 1)
            )
        
            # –®–∞–≥ 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ü–µ–ª–µ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            if progress_callback:
                progress_callback("[TARGET] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ü–µ–ª–µ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π...")
        
            strategy_gen_start_time = time.time()
            strategies = []
        
            try:
                # –°–æ–∑–¥–∞–µ–º —Ö—ç—à fingerprint –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
                fingerprint_hash = ""
                if fingerprint:
                    fingerprint_data = str(fingerprint.dpi_type.value) + str(fingerprint.dpi_mode.value)
                    fingerprint_hash = hashlib.md5(fingerprint_data.encode()).hexdigest()[:8]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
                strategies = self._get_cached_strategies(domain, fingerprint_hash)
                
                if strategies is None:
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
                    intents = self.intent_engine.propose_intents(fingerprint) if fingerprint else []
                    strategies = await self.strategy_generator.generate_strategies(intents, fingerprint)
                    
                    # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    self._cache_strategies(domain, fingerprint_hash, strategies)
                    
            except Exception as e:
                LOG.warning(f"Failed to generate strategies for {domain}: {e}")
                if progress_callback:
                    progress_callback("[WARN] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                strategies = []
        
            # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –µ—ë –ü–ï–†–í–û–ô
            # –ü—Ä–∏—á–∏–Ω–∞: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ –æ–Ω–∞ –µ—â—ë, –∏ –µ—Å–ª–∏ –¥–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–∞–∑—É
            # –ï—Å–ª–∏ –Ω–µ—Ç - –∏—â–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
            existing_strategy = None
            if self._strategy_manager:
                existing_strategy = self._strategy_manager.get_strategy(domain)
        
            if existing_strategy:
                LOG.info(f"‚úÖ Found existing strategy for {domain}: {existing_strategy.strategy}")
                LOG.info(f"   Will test it FIRST to verify it still works")
                
                # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç, —á—Ç–æ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
                try:
                    from dataclasses import dataclass
                    
                    @dataclass
                    class ExistingStrategy:
                        name: str
                        type: str
                        params: dict
                        attack_name: str = None
                        id: str = None
                        
                        def __post_init__(self):
                            # –ï—Å–ª–∏ attack_name –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º type
                            if self.attack_name is None:
                                self.attack_name = self.type
                            # –ï—Å–ª–∏ id –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∫–∞–∫ –µ—Å—Ç—å
                            if self.id is None:
                                self.id = self.name
                        
                        def to_dict(self):
                            return {
                                'type': self.type,
                                'params': self.params
                            }
                    
                    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∏–∑ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "fake+multisplit+disorder")
                    strategy_parts = existing_strategy.strategy.split('+')
                    strategy_type = strategy_parts[0] if strategy_parts else 'unknown'
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ DomainStrategy
                    params = {}
                    if existing_strategy.split_pos is not None:
                        params['split_pos'] = existing_strategy.split_pos
                    if existing_strategy.split_count is not None:
                        params['split_count'] = existing_strategy.split_count
                    if existing_strategy.ttl is not None:
                        params['ttl'] = existing_strategy.ttl
                    if existing_strategy.fake_ttl is not None:
                        params['fake_ttl'] = existing_strategy.fake_ttl
                    if existing_strategy.disorder_method is not None:
                        params['disorder_method'] = existing_strategy.disorder_method
                    if existing_strategy.fooling_modes is not None:
                        params['fooling'] = existing_strategy.fooling_modes
                    if existing_strategy.raw_params:
                        params.update(existing_strategy.raw_params)
                    
                    # Task 17.2: Use strategy name as-is without adding prefix
                    # The prefix was causing issues with attack registry lookup
                    strategy_name = existing_strategy.strategy
                    
                    existing_strat_obj = ExistingStrategy(
                        name=strategy_name,
                        type=strategy_type,
                        params=params,
                        attack_name=strategy_type,
                        id=strategy_name
                    )
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –í –ù–ê–ß–ê–õ–û —Å–ø–∏—Å–∫–∞
                    strategies.insert(0, existing_strat_obj)
                    LOG.info(f"   Added existing strategy to the beginning of test queue")
                    
                except Exception as e:
                    LOG.warning(f"‚ö†Ô∏è Failed to add existing strategy to queue: {e}")
        
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º –∑–Ω–∞–Ω–∏–º
            failed_strategies = set()
            if domain in self.negative_knowledge:
                failed_strategies = set(self.negative_knowledge[domain])
            strategies = [s for s in strategies if s.name not in failed_strategies]
        
            strategy_gen_time = time.time() - strategy_gen_start_time
            self.stats["strategy_generation_time"] = (
            (self.stats["strategy_generation_time"] * self.stats["domains_processed"] + strategy_gen_time) /
            (self.stats["domains_processed"] + 1)
            )
        
            if progress_callback:
                progress_callback(f"[TARGET] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(strategies)} —Ü–µ–ª–µ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
        
            LOG.info(f"Generated {len(strategies)} strategies for {domain}")
            LOG.info("[PROCESS] Using SEQUENTIAL testing (parallel testing disabled for DPI strategies)")
        
            # –®–∞–≥ 5: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∞–Ω–∞–ª–∏–∑–æ–º –Ω–µ—É–¥–∞—á (–¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –¥–ª—è DPI —Å—Ç—Ä–∞—Ç–µ–≥–∏–π)
            # –í–ê–ñ–ù–û: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ DPI —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏–∑-–∑–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤:
            # - WinDivert –¥—Ä–∞–π–≤–µ—Ä –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º
            # - –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ —Å–æ–∑–¥–∞–µ—Ç —Ö–∞–æ—Å
            # - TCP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ª–æ–º–∞—é—Ç—Å—è –æ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if False:  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–û–¢–ö–õ–Æ–ß–ï–ù–û –¥–ª—è DPI)
                successful_strategy, tested_count = await self._test_strategies_parallel(
                    domain, strategies[:self.config.max_trials], progress_callback
                )
                
                trials_count = tested_count  # –£—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
                
                if successful_strategy:
                    # Update statistics for successful strategy finding
                    self.stats["domains_processed"] += 1
                    self.stats["total_trials"] += trials_count
                    self.stats["parallel_tests_executed"] += 1
                    
                    return StrategyResult(
                        success=True,
                        strategy=successful_strategy,
                        message=f"–ù–∞–π–¥–µ–Ω–∞ —Ä–∞–±–æ—á–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ): {successful_strategy.name}",
                        execution_time=time.time() - start_time,
                        trials_count=trials_count,
                        fingerprint_updated=bool(fingerprint)
                    )
            else:
                # –ù–û–í–û–ï: –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –æ—á–µ—Ä–µ–¥—å—é
                strategies_queue = strategies[:self.config.max_trials]  # –ù–∞—á–∞–ª—å–Ω–∞—è –æ—á–µ—Ä–µ–¥—å
                iteration_count = 0
                max_iterations = 5  # –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
                
                # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è Pattern Matcher
                context = self._build_context(domain, fingerprint)
            
            # PCAP capture already initialized at the beginning of the method
            
            LOG.info(f"üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {domain}")
            LOG.info(f"üìã –ù–∞—á–∞–ª—å–Ω–∞—è –æ—á–µ—Ä–µ–¥—å: {len(strategies_queue)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
            
            try:
                while strategies_queue and trials_count < self.config.max_trials and iteration_count < max_iterations:
                    iteration_count += 1
                    self.closed_loop_stats["iterations_total"] += 1
                    
                    # Task 8.1: Record iteration start in metrics
                    if self.metrics_collector:
                        self.metrics_collector.record_iteration_start(domain, iteration_count)
                    
                    LOG.info(f"üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration_count}: {len(strategies_queue)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ –æ—á–µ—Ä–µ–¥–∏")
                    
                    if progress_callback:
                        progress_callback(f"[ITER] –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration_count}: —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(strategies_queue)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
                    
                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ —Ç–µ–∫—É—â–µ–π –æ—á–µ—Ä–µ–¥–∏
                    current_queue = strategies_queue.copy()
                    strategies_queue = []  # –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å –¥–ª—è –Ω–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
                    
                    for i, strategy in enumerate(current_queue):
                        if trials_count >= self.config.max_trials:
                            break
                            
                        trials_count += 1
                        
                        if progress_callback:
                            progress_callback(f"[TEST] –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration_count}, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è {i+1}/{len(current_queue)}: {strategy.name}")
                        
                        test_start_time = time.time()
                        # FIXED: Use individual PCAP file for each test (not shared)
                        # This ensures each strategy has its own PCAP file with correct metadata
                        result = await self._test_strategy_with_capture(domain, strategy, shared_pcap_file=None)
                        test_time = time.time() - test_start_time
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                        self.stats["average_test_time"] = (
                            (self.stats["average_test_time"] * (trials_count - 1) + test_time) / trials_count
                        )
                        
                        # Task 3.4: Structured logging of strategy test results
                        # –õ–æ–≥–∏—Ä—É–µ–º domain, strategy_name, strategy_params (–∫—Ä–∞—Ç–∫–æ)
                        strategy_params = {}
                        if hasattr(strategy, 'params'):
                            strategy_params = strategy.params
                        elif hasattr(strategy, 'to_dict'):
                            strategy_dict = strategy.to_dict()
                            strategy_params = strategy_dict.get('params', {})
                        
                        LOG.info(f"üéØ –¢–µ—Å—Ç {trials_count}: {strategy.name} -> {'‚úÖ SUCCESS' if result.success else '‚ùå FAIL'}")
                        LOG.info(f"[STRATEGY_TEST] domain={domain}, strategy_name={strategy.name}, "
                               f"strategy_params={strategy_params}, test_time={test_time:.3f}s")
                        
                        # Task 3.4: Log ConnectionMetrics and EvaluationResult from metadata
                        if hasattr(result, 'metadata') and result.metadata:
                            if 'connection_metrics' in result.metadata:
                                cm = result.metadata['connection_metrics']
                                LOG.info(f"[CONNECTION_METRICS] connect_time_ms={cm.get('connect_time_ms', 0):.1f}, "
                                       f"tls_time_ms={cm.get('tls_time_ms', 0):.1f}, "
                                       f"ttfb_ms={cm.get('ttfb_ms', 0):.1f}, "
                                       f"http_status={cm.get('http_status')}, "
                                       f"bytes_received={cm.get('bytes_received', 0)}, "
                                       f"block_type={cm.get('block_type', 'unknown')}")
                            
                            if 'evaluation_result' in result.metadata:
                                er = result.metadata['evaluation_result']
                                LOG.info(f"[EVALUATION_RESULT] success={er.get('success')}, "
                                       f"block_type={er.get('block_type', 'unknown')}, "
                                       f"confidence={er.get('confidence', 0):.2f}, "
                                       f"reason={er.get('reason', 'N/A')}")
                        
                        if result.success:
                            # –£–°–ü–ï–•: –û–±–Ω–æ–≤–ª—è–µ–º KnowledgeAccumulator –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
                            if self.knowledge_accumulator and hasattr(self, '_last_failure_report'):
                                try:
                                    self.knowledge_accumulator.update_success_pattern(
                                        self._last_failure_report, strategy, context
                                    )
                                    self.closed_loop_stats["knowledge_updates"] += 1
                                    
                                    # Task 8.1: Record knowledge base update in metrics
                                    if self.metrics_collector:
                                        rules_count = len(self.knowledge_accumulator.get_all_patterns())
                                        self.metrics_collector.record_knowledge_base_update(rules_count)
                                        
                                        # Record pattern success
                                        pattern_id = "unknown_pattern"
                                        if hasattr(self._last_failure_report, 'root_cause'):
                                            pattern_id = f"pattern_{self._last_failure_report.root_cause.value}"
                                        self.metrics_collector.record_pattern_success(pattern_id, True)
                                    
                                    LOG.info("üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—Ö–∞")
                                except Exception as e:
                                    LOG.warning(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
                        
                        # Task 5.4: Save successful strategy to adaptive_knowledge.json
                        if self.adaptive_knowledge:
                            try:
                                # Extract ConnectionMetrics from result
                                connection_metrics = None
                                if hasattr(result, 'metadata') and result.metadata:
                                    if 'connection_metrics' in result.metadata:
                                        # Reconstruct ConnectionMetrics from dict
                                        cm_dict = result.metadata['connection_metrics']
                                        if CONNECTION_METRICS_AVAILABLE and ConnectionMetrics:
                                            connection_metrics = ConnectionMetrics(
                                                connect_time_ms=cm_dict.get('connect_time_ms', 0.0),
                                                tls_time_ms=cm_dict.get('tls_time_ms', 0.0),
                                                ttfb_ms=cm_dict.get('ttfb_ms', 0.0),
                                                total_time_ms=cm_dict.get('total_time_ms', 0.0),
                                                http_status=cm_dict.get('http_status'),
                                                bytes_received=cm_dict.get('bytes_received', 0),
                                                tls_completed=cm_dict.get('tls_completed', False),
                                                error=cm_dict.get('error'),
                                                rst_received=cm_dict.get('rst_received', False),
                                                rst_timing_ms=cm_dict.get('rst_timing_ms'),
                                                timeout=cm_dict.get('timeout', False),
                                                block_type=BlockType(cm_dict.get('block_type', 'unknown')) if BlockType else None
                                            )
                                
                                # If no ConnectionMetrics, create a basic one
                                if connection_metrics is None and CONNECTION_METRICS_AVAILABLE and ConnectionMetrics:
                                    connection_metrics = ConnectionMetrics(
                                        connect_time_ms=test_time * 1000,  # Convert to ms
                                        http_status=200,  # Assume success
                                        block_type=BlockType.NONE
                                    )
                                
                                # Extract strategy parameters
                                strategy_params = {}
                                if hasattr(strategy, 'params'):
                                    strategy_params = strategy.params
                                elif hasattr(strategy, 'parameters'):
                                    strategy_params = strategy.parameters
                                elif hasattr(strategy, 'to_dict'):
                                    strategy_dict = strategy.to_dict()
                                    strategy_params = strategy_dict.get('params', {})
                                
                                # Record success in adaptive_knowledge.json
                                self.adaptive_knowledge.record_success(
                                    domain=domain,
                                    strategy_name=strategy.name if hasattr(strategy, 'name') else 'unknown',
                                    strategy_params=strategy_params,
                                    metrics=connection_metrics
                                )
                                
                                LOG.info(f"üìö –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≤ adaptive_knowledge.json: {strategy.name if hasattr(strategy, 'name') else 'unknown'}")
                            except Exception as e:
                                LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ adaptive_knowledge.json: {e}")
                        
                        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tweaks –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º
                        self._restore_tweaks()
                        
                        # Task 6.4: Extract pcap_file from result for PCAP analysis
                        pcap_file = None
                        if hasattr(result, 'artifacts') and hasattr(result.artifacts, 'pcap_file'):
                            pcap_file = result.artifacts.pcap_file
                        elif hasattr(result, 'pcap_file'):
                            pcap_file = result.pcap_file
                        
                        # Task 7.4: Extract session_id from result for coordinator routing
                        session_id = None
                        if hasattr(result, 'metadata') and result.metadata:
                            session_id = result.metadata.get('session_id')
                        elif isinstance(result, dict):
                            session_id = result.get('session_id')
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–±–æ—á—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å PCAP –∞–Ω–∞–ª–∏–∑–æ–º
                        # Task 7.4: Pass session_id for coordinator save routing (Requirements 1.4, 1.5, 9.4)
                        await self._save_working_strategy(domain, strategy, pcap_file, session_id)
                        
                        if progress_callback:
                            progress_callback(f"[OK] –ù–∞–π–¥–µ–Ω–∞ —Ä–∞–±–æ—á–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy.name}")
                        
                        # Update statistics for successful strategy finding
                        self.stats["domains_processed"] += 1
                        self.stats["total_trials"] += trials_count
                        
                        # Task 8.1: Record iteration success in metrics
                        if self.metrics_collector:
                            self.metrics_collector.record_iteration_success(domain, iteration_count)
                        
                        LOG.info(f"üéâ –£—Å–ø–µ—Ö –∑–∞ {iteration_count} –∏—Ç–µ—Ä–∞—Ü–∏–π, {trials_count} –ø–æ–ø—ã—Ç–æ–∫")
                        
                        # Task 11.5: Generate validation report if in verification mode
                        if self.config.verify_with_pcap and self.strategy_validator:
                            try:
                                validation_report = self.strategy_validator.generate_report()
                                LOG.info("\n" + validation_report)
                                
                                # Save validation report to file
                                from pathlib import Path
                                report_dir = Path("data/validation_reports")
                                report_dir.mkdir(parents=True, exist_ok=True)
                                
                                from datetime import datetime
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                domain_safe = domain.replace('.', '_')
                                report_file = report_dir / f"validation_report_{domain_safe}_{timestamp}.txt"
                                
                                with open(report_file, 'w', encoding='utf-8') as f:
                                    f.write(validation_report)
                                
                                LOG.info(f"üìÑ Validation report saved to: {report_file}")
                                
                                # Also save JSON results
                                json_file = report_dir / f"validation_results_{domain_safe}_{timestamp}.json"
                                self.strategy_validator.save_results(json_file)
                                
                            except Exception as e:
                                LOG.error(f"‚ùå Failed to generate validation report: {e}", exc_info=True)
                        
                        return StrategyResult(
                            success=True,
                            strategy=strategy,
                            message=f"–ù–∞–π–¥–µ–Ω–∞ —Ä–∞–±–æ—á–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞ {iteration_count} –∏—Ç–µ—Ä–∞—Ü–∏–π: {strategy.name}",
                            execution_time=time.time() - start_time,
                            trials_count=trials_count,
                            fingerprint_updated=bool(fingerprint),
                            metadata={
                                "iterations": iteration_count,
                                "closed_loop_learning": True,
                                "knowledge_updates": self.closed_loop_stats["knowledge_updates"]
                            }
                        )
                    else:
                        # –ù–ï–£–î–ê–ß–ê: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
                        await self._analyze_strategy_failure(domain, strategy, result, fingerprint, progress_callback)
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —á–µ—Ä–µ–∑ –∑–∞–º–∫–Ω—É—Ç—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
                        try:
                            augmented_strategies = await self._augment_strategies_from_failure(
                                domain, strategy, result, fingerprint, context
                            )
                            
                            if augmented_strategies:
                                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å –æ—Å—Ç–∞–≤—à–µ–π—Å—è –æ—á–µ—Ä–µ–¥—å—é
                                strategies_queue = self._merge_queues(
                                    strategies_queue, augmented_strategies, start_from=0
                                )
                                
                                self.closed_loop_stats["strategies_augmented"] += len(augmented_strategies)
                                
                                # Task 8.1: Record strategies generated in metrics
                                if self.metrics_collector:
                                    self.metrics_collector.record_strategies_generated(len(augmented_strategies))
                                
                                LOG.info(f"üîÑ –î–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(augmented_strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π, "
                                        f"–æ—á–µ—Ä–µ–¥—å: {len(strategies_queue)}")
                                
                                if progress_callback:
                                    progress_callback(f"[LEARN] –î–æ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(augmented_strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
                        
                        except Exception as e:
                            LOG.warning(f"–û—à–∏–±–∫–∞ –¥–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {e}")
                            # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                            import traceback
                            LOG.debug(f"–ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:\n{traceback.format_exc()}")
                
                # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é
                LOG.info(f"üìä –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration_count} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: "
                        f"–ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(current_queue)}, "
                        f"–≤ –æ—á–µ—Ä–µ–¥–∏ {len(strategies_queue)}, "
                        f"–≤—Å–µ–≥–æ –ø–æ–ø—ã—Ç–æ–∫ {trials_count}")
            
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tweaks –≤ —Å–ª—É—á–∞–µ –Ω–µ—É–¥–∞—á–∏
                self._restore_tweaks()
                
                LOG.info(f"‚ùå –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω –±–µ–∑ —É—Å–ø–µ—Ö–∞: {iteration_count} –∏—Ç–µ—Ä–∞—Ü–∏–π, {trials_count} –ø–æ–ø—ã—Ç–æ–∫")
            
            except Exception as e:
                LOG.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è: {e}")
                import traceback
                LOG.debug(f"–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞:\n{traceback.format_exc()}")
        
        finally:
            # FIXED: No shared PCAP cleanup needed - individual PCAP files are managed per test
            # Each test in _test_strategy_with_capture creates and manages its own PCAP file
            pass
            
            # Legacy code removed - shared PCAP is no longer used
            if False and pcap_capturer:
                try:
                    pcap_capturer.stop_capture()
                    LOG.info(f"üé• PCAP capture stopped: {pcap_file}")
                    
                    # Run PCAP analysis and validation
                    if pcap_file and pcap_file.exists():
                        LOG.info(f"üìä Analyzing complete PCAP file: {pcap_file}")
                        
                        # Task 11.5: Run StrategyValidator with complete PCAP file
                        if self.strategy_validator:
                            try:
                                validation_result = self.strategy_validator.validate_strategy(
                                    strategy_log=None,  # No operation log available
                                    pcap_file=pcap_file,
                                    domain=domain,
                                    strategy_name=f"domain_analysis_{domain}"
                                )
                                LOG.info(f"‚úÖ Final validation complete: {validation_result.status}")
                            except Exception as e:
                                LOG.warning(f"‚ö†Ô∏è Final validation failed: {e}")
                except Exception as e:
                    LOG.error(f"‚ùå Error stopping PCAP capture: {e}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["domains_processed"] += 1
        self.stats["total_trials"] += trials_count
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
        self._save_negative_knowledge()
        
        # Task 11.5: Generate validation report if in verification mode
        if self.config.verify_with_pcap and self.strategy_validator:
            try:
                validation_report = self.strategy_validator.generate_report()
                LOG.info("\n" + validation_report)
                
                # Save validation report to file
                from pathlib import Path
                report_dir = Path("data/validation_reports")
                report_dir.mkdir(parents=True, exist_ok=True)
                
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                domain_safe = domain.replace('.', '_')
                report_file = report_dir / f"validation_report_{domain_safe}_{timestamp}.txt"
                
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(validation_report)
                
                LOG.info(f"üìÑ Validation report saved to: {report_file}")
                
                # Also save JSON results
                json_file = report_dir / f"validation_results_{domain_safe}_{timestamp}.json"
                self.strategy_validator.save_results(json_file)
                
            except Exception as e:
                LOG.error(f"‚ùå Failed to generate validation report: {e}", exc_info=True)
        
        return StrategyResult(
            success=False,
            message=f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—á–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø–æ—Å–ª–µ {trials_count} –ø–æ–ø—ã—Ç–æ–∫",
            execution_time=time.time() - start_time,
            trials_count=trials_count,
            fingerprint_updated=bool(fingerprint)
        )
    
    async def _save_working_strategy(self, domain: str, strategy: Any, pcap_file: Optional[str] = None, session_id: Optional[str] = None):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—á–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.
        
        Task 6.1: Use StrategyManager for unified strategy persistence
        Task 6.4: Analyze PCAP after successful strategy test
        Task 7.4: Route saves through coordinator (Requirements 1.4, 1.5, 9.4)
        Task 12.2: In batch mode, save only to adaptive_knowledge.json, not domain_rules.json (Requirement 6.1, 6.2)
        
        Args:
            domain: Target domain
            strategy: Strategy object to save
            pcap_file: Optional PCAP file path for analysis
            session_id: Optional test session ID for coordinator routing
        """
        # Task 7.4: Check coordinator approval before saving (Requirements 1.4, 1.5, 9.4)
        if self.test_result_coordinator and session_id:
            if not self.test_result_coordinator.should_save_strategy(session_id):
                LOG.warning(f"üö´ Coordinator blocked save for {domain}: Test verdict is not SUCCESS")
                return
            LOG.info(f"‚úÖ Coordinator approved save for {domain}")
        
        # Task 7.4: Route saves through StrategySaver for deduplication (Requirements 5.1, 5.2, 5.3, 5.4, 5.5)
        if self.strategy_saver and self.test_result_coordinator and session_id:
            try:
                # Get test session to access verdict
                session = self.test_result_coordinator.get_session(session_id)
                if not session:
                    LOG.warning(f"‚ö†Ô∏è No test session found for {session_id}, falling back to legacy save")
                else:
                    # Extract strategy information
                    strategy_name = self._get_strategy_name(strategy)
                    
                    # Extract parameters
                    parameters = {}
                    if hasattr(strategy, 'params'):
                        parameters = strategy.params
                    elif hasattr(strategy, 'parameters'):
                        parameters = strategy.parameters
                    elif hasattr(strategy, 'to_dict'):
                        strategy_dict = strategy.to_dict()
                        parameters = strategy_dict.get('params', {})
                    
                    # Extract attacks list
                    attacks = self._extract_attack_combination(strategy)
                    
                    # Extract parameters from PCAP analysis if available (override strategy parameters)
                    pcap_parameters = None
                    if session.pcap_analysis and hasattr(session.pcap_analysis, 'parameters'):
                        pcap_parameters = session.pcap_analysis.parameters
                        LOG.debug(f"üìä Using PCAP parameters for saving: {pcap_parameters}")
                        
                        # Override strategy parameters with PCAP parameters
                        if pcap_parameters:
                            parameters = {**parameters, **pcap_parameters}
                            LOG.debug(f"üìä Merged parameters: {parameters}")
                        
                        # Update attacks list from PCAP if available
                        if hasattr(session.pcap_analysis, 'detected_attacks') and session.pcap_analysis.detected_attacks:
                            pcap_attacks = session.pcap_analysis.detected_attacks
                            LOG.debug(f"üìä PCAP detected attacks: {pcap_attacks}")
                            # Use PCAP attacks if they are more specific
                            if len(pcap_attacks) > len(attacks):
                                attacks = pcap_attacks
                                LOG.debug(f"üìä Using PCAP attacks: {attacks}")
                    
                    # Use StrategySaver for atomic, deduplicated saves
                    save_result = self.strategy_saver.save_strategy(
                        domain=domain,
                        strategy_name=strategy_name,
                        parameters=parameters,
                        verdict=session.verdict,
                        attacks=attacks,
                        success_rate=1.0,
                        verified=True
                    )
                    
                    if save_result.success:
                        if save_result.was_duplicate:
                            LOG.info(f"‚úÖ Strategy save deduplicated for {domain}: {strategy_name}")
                        else:
                            LOG.info(f"‚úÖ Strategy saved via StrategySaver for {domain}: {strategy_name}")
                            LOG.info(f"   Files updated: {', '.join(save_result.files_updated)}")
                        
                        # Update in-memory cache
                        self.best_strategies[domain] = strategy
                        self.stats["strategies_found"] += 1
                        
                        # PCAP analysis already done by coordinator, just log
                        if pcap_file and session.pcap_analysis:
                            LOG.info(f"‚úÖ PCAP Analysis: {len(session.pcap_analysis.detected_attacks)} attacks detected")
                            LOG.info(f"   Detected attacks: {session.pcap_analysis.detected_attacks}")
                            LOG.info(f"   Parameters: {session.pcap_analysis.parameters}")
                        
                        return  # Success - exit early
                    else:
                        LOG.error(f"‚ùå StrategySaver failed: {save_result.error}")
                        LOG.warning(f"‚ö†Ô∏è Falling back to legacy save method")
                        
            except Exception as e:
                LOG.error(f"‚ùå Error using StrategySaver: {e}", exc_info=True)
                LOG.warning(f"‚ö†Ô∏è Falling back to legacy save method")
        
        # Task 7.4: Legacy save path (only used when coordinator/saver not available)
        # This maintains backward compatibility but bypasses deduplication
        LOG.info(f"‚ÑπÔ∏è Using legacy save path for {domain} (coordinator/saver not available)")
        
        self.best_strategies[domain] = strategy
        self.stats["strategies_found"] += 1
        
        # Task 6.4: Analyze PCAP if available
        # Task 7.3: Route PCAP analysis through coordinator (Requirements 6.1, 6.2, 6.3)
        if pcap_file:
            try:
                # Ensure pcap_file is a string, not a Path object
                pcap_file_str = str(pcap_file) if pcap_file else None
                if not pcap_file_str:
                    raise ValueError("Invalid PCAP file path")
                
                # Task 7.3: Route PCAP analysis through coordinator (Requirements 6.1, 6.2, 6.3)
                # All PCAP analysis must go through coordinator to ensure caching and consistency
                if self.test_result_coordinator:
                    # Route through coordinator to ensure caching (Requirement 6.1, 6.2, 6.3)
                    LOG.info(f"üîç Analyzing PCAP: {pcap_file}")
                    pcap_analysis = self.test_result_coordinator.get_pcap_analysis(pcap_file_str)
                    
                    if pcap_analysis:
                        LOG.info(f"‚úÖ PCAP Analysis: {len(pcap_analysis.detected_attacks)} attacks detected in {pcap_file}")
                        LOG.info(f"   Detected attacks: {pcap_analysis.detected_attacks}")
                        LOG.info(f"   Parameters: {pcap_analysis.parameters}")
                        LOG.info(f"   Packet count: {pcap_analysis.packet_count}")
                        
                        # Store analysis results for later comparison
                        if not hasattr(self, '_pcap_analysis_results'):
                            self._pcap_analysis_results = {}
                        self._pcap_analysis_results[domain] = pcap_analysis
                    else:
                        LOG.warning(f"‚ö†Ô∏è PCAP Analysis: Failed to analyze {pcap_file}")
                else:
                    # Fallback to direct analyzer if coordinator not available (backward compatibility)
                    # Note: This fallback bypasses caching and should only be used when coordinator is disabled
                    LOG.warning(f"‚ö†Ô∏è TestResultCoordinator not available, using direct PCAPAnalyzer (no caching)")
                    from core.pcap.analyzer import PCAPAnalyzer
                    analyzer = PCAPAnalyzer()
                    
                    # Analyze strategy application
                    strategy_dict = {
                        'attack': getattr(strategy, 'attack_name', 'unknown'),
                        'type': getattr(strategy, 'name', 'unknown'),
                        'params': getattr(strategy, 'parameters', {})
                    }
                    
                    LOG.info(f"üîç Analyzing PCAP: {pcap_file}")
                    analysis_result = analyzer.analyze_strategy_application(pcap_file_str, strategy_dict)
                    
                    if analysis_result.strategy_detected:
                        LOG.info(f"‚úÖ PCAP Analysis: Strategy detected in {pcap_file}")
                        LOG.info(f"   Split positions: {analysis_result.split_positions}")
                        LOG.info(f"   SNI values: {analysis_result.sni_values}")
                        LOG.info(f"   Packet count: {analysis_result.packet_count}")
                        
                        # Store analysis results for later comparison
                        if not hasattr(self, '_pcap_analysis_results'):
                            self._pcap_analysis_results = {}
                        self._pcap_analysis_results[domain] = analysis_result
                    else:
                        LOG.warning(f"‚ö†Ô∏è PCAP Analysis: Strategy not detected in {pcap_file}")
                    
            except Exception as e:
                LOG.warning(f"‚ö†Ô∏è PCAP analysis failed: {e}")
        
        # Task 12.2: Save to adaptive_knowledge.json in both normal and batch mode (Requirement 6.2)
        if self.adaptive_knowledge:
            try:
                # Extract strategy parameters
                strategy_params = {}
                if hasattr(strategy, 'params'):
                    strategy_params = strategy.params
                elif hasattr(strategy, 'parameters'):
                    strategy_params = strategy.parameters
                elif hasattr(strategy, 'to_dict'):
                    strategy_dict = strategy.to_dict()
                    strategy_params = strategy_dict.get('params', {})
                
                # Create basic ConnectionMetrics for successful strategy
                if CONNECTION_METRICS_AVAILABLE and ConnectionMetrics:
                    connection_metrics = ConnectionMetrics(
                        connect_time_ms=0.0,  # Will be updated with actual timing if available
                        http_status=200,  # Assume success
                        block_type=BlockType.NONE
                    )
                else:
                    connection_metrics = None
                
                # Record success in adaptive_knowledge.json
                self.adaptive_knowledge.record_success(
                    domain=domain,
                    strategy_name=strategy.name if hasattr(strategy, 'name') else 'unknown',
                    strategy_params=strategy_params,
                    metrics=connection_metrics
                )
                
                LOG.info(f"üìö Saved successful strategy to adaptive_knowledge.json: {strategy.name if hasattr(strategy, 'name') else 'unknown'}")
            except Exception as e:
                LOG.warning(f"‚ö†Ô∏è Error saving to adaptive_knowledge.json: {e}")
        
        # Task 12.2: In batch mode, skip saving to domain_rules.json (Requirement 6.1)
        # Only save to adaptive_knowledge.json (done above)
        if not self.config.batch_mode:
            # Task 3: Save strategy with complete attack combination information
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–µ—Ä–µ–¥–∞—ë–º pcap_file –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            try:
                self._save_strategy(domain, strategy, pcap_file)
            except Exception as e:
                LOG.error(f"‚ùå Failed to save strategy with new method: {e}")
                # Fallback to old method
                self._save_best_strategies()
            
            # Task 6.1: Also save using StrategyManager for backward compatibility
            if self._strategy_manager:
                try:
                    strategy_name = getattr(strategy, 'name', 'unknown')
                    attack_name = getattr(strategy, 'attack_name', 
                                        strategy.attack_combination[0] if hasattr(strategy, 'attack_combination') and strategy.attack_combination else 'unknown')
                    parameters = getattr(strategy, 'parameters', {})
                    
                    # Add forced override parameters
                    if 'no_fallbacks' not in parameters:
                        parameters['no_fallbacks'] = True
                    if 'forced' not in parameters:
                        parameters['forced'] = True
                    
                    # ‚úÖ FIX: –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –í–°–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                    # Decompose smart_combo_ attack names into constituent attacks
                    raw_attacks = getattr(strategy, 'attack_combination', [attack_name])
                    attacks = []
                    for attack in raw_attacks:
                        if isinstance(attack, str) and (attack.startswith('smart_combo_') or attack.startswith('existing_smart_combo_')):
                            # Decompose smart_combo_ names
                            name_without_prefix = attack.replace('existing_smart_combo_', '').replace('smart_combo_', '')
                            parts = name_without_prefix.split('_')
                            known_attacks = {'fake', 'split', 'disorder', 'multisplit', 'seqovl'}
                            for part in parts:
                                if part in known_attacks:
                                    attacks.append(part)
                        else:
                            attacks.append(attack)
                    
                    # Fallback if decomposition resulted in empty list
                    if not attacks:
                        attacks = raw_attacks
                    
                    save_params = {
                        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                        'split_pos': parameters.get('split_pos'),
                        'overlap_size': parameters.get('split_seqovl') or parameters.get('overlap_size'),
                        'fooling_modes': parameters.get('fooling'),
                        # ‚úÖ FIX: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–Ω—å—à–µ —Ç–µ—Ä—è–ª–∏—Å—å
                        'split_count': parameters.get('split_count'),
                        'ttl': parameters.get('ttl'),
                        'fake_ttl': parameters.get('fake_ttl'),
                        'disorder_method': parameters.get('disorder_method'),
                        'ack_first': parameters.get('ack_first'),
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                        'strategy_name': strategy_name,
                        'attack_type': attack_name,
                        'attacks': attacks,  # ‚úÖ FIX: Use decomposed attacks
                        'raw_params': parameters.copy(),  # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                        'discovered_at': datetime.now().isoformat(),
                    }
                    
                    # Save using StrategyManager
                    self._strategy_manager.add_strategy(
                        domain=domain,
                        strategy=strategy_name,
                        success_rate=1.0,  # Successful strategy
                        avg_latency_ms=0.0,  # Will be updated with actual latency
                        **save_params  # ‚úÖ FIX: –ü–µ—Ä–µ–¥–∞–µ–º –í–°–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    )
                    self._strategy_manager.save_strategies()
                    LOG.info(f"‚úÖ Saved working strategy for {domain} via StrategyManager: {strategy_name}")
                    LOG.debug(f"   Saved parameters: {save_params}")
                except Exception as e:
                    LOG.error(f"‚ùå Failed to save strategy via StrategyManager: {e}")
        else:
            # Task 12.2: In batch mode, only log that we're skipping domain_rules.json save (Requirement 6.1)
            LOG.info(f"üìö Batch mode: Skipping domain_rules.json save for {domain}, strategy saved to adaptive_knowledge.json only")
        
        LOG.info(f"Saved working strategy for {domain}: {getattr(strategy, 'name', 'unknown')}")
    
    def _extract_attack_combination(self, strategy: Any) -> List[str]:
        """
        Extract ordered list of attacks from strategy object.
        
        This method detects attack combinations from strategy objects by checking:
        1. Explicit attack_combination attribute
        2. Strategy name patterns (e.g., "multisplit_disorder")
        3. Parameters that indicate combinations (e.g., disorder_method)
        
        Args:
            strategy: Strategy object to analyze
            
        Returns:
            List of attack names in execution order
        """
        # Check if strategy has explicit attack list
        if hasattr(strategy, 'attack_combination') and strategy.attack_combination:
            attacks = [str(a).lower() for a in strategy.attack_combination]
            LOG.debug(f"üìã Extracted attacks from attack_combination: {attacks}")
            return attacks
        
        # Check if strategy name indicates combination
        if hasattr(strategy, 'name'):
            name = strategy.name.lower()
            
            # Common combination patterns
            if 'multisplit' in name and 'disorder' in name:
                LOG.debug(f"üìã Detected multisplit+disorder combination from name: {name}")
                return ['multisplit', 'disorder']
            if 'fake' in name and 'disorder' in name:
                LOG.debug(f"üìã Detected fake+disorder combination from name: {name}")
                return ['fake', 'disorder']
            if 'split' in name and 'disorder' in name:
                LOG.debug(f"üìã Detected split+disorder combination from name: {name}")
                return ['split', 'disorder']
        
        # Check parameters for combination indicators
        params = getattr(strategy, 'parameters', {})
        
        # disorder_method indicates disorder attack is involved
        if 'disorder_method' in params:
            base_attack = getattr(strategy, 'attack_name', None)
            if not base_attack:
                # Try to infer from parameters
                if 'split_count' in params or 'positions' in params:
                    base_attack = 'multisplit'
                elif 'split_pos' in params:
                    base_attack = 'split'
                else:
                    base_attack = 'unknown'
            
            LOG.debug(f"üìã Detected disorder_method parameter, combination: [{base_attack}, disorder]")
            return [base_attack, 'disorder']
        
        # Single attack
        attack_name = getattr(strategy, 'attack_name', None)
        if attack_name:
            LOG.debug(f"üìã Single attack detected: {attack_name}")
            return [attack_name]
        
        # Fallback: try to infer from parameters
        if 'split_count' in params or 'positions' in params:
            LOG.debug(f"üìã Inferred multisplit from parameters")
            return ['multisplit']
        elif 'split_pos' in params:
            LOG.debug(f"üìã Inferred split from parameters")
            return ['split']
        elif 'fake_packets' in params or 'fake_count' in params:
            LOG.debug(f"üìã Inferred fake from parameters")
            return ['fake']
        
        LOG.warning(f"‚ö†Ô∏è Could not determine attack combination, using 'unknown'")
        return ['unknown']
    
    def _save_strategy(self, domain: str, strategy: Any, pcap_file: str = None):
        """
        Save strategy with complete attack combination information to domain_rules.json.
        
        This method extracts the complete attack combination from the strategy object
        and saves it in the domain_rules.json format with all required metadata.
        
        –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –¢–µ–ø–µ—Ä—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç PCAP —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é,
        –∞ –Ω–µ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ strategy.
        
        Args:
            domain: Domain name for the strategy
            strategy: Strategy object to save
            pcap_file: Path to PCAP file for analysis (optional)
        """
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∏–∑ PCAP
            real_attacks = None
            real_params = None
            
            if pcap_file:
                try:
                    real_strategy = self._extract_real_strategy_from_pcap(pcap_file, domain)
                    if real_strategy:
                        real_attacks = real_strategy.get('attacks')
                        real_params = real_strategy.get('params')
                        LOG.info(f"üìä –†–µ–∞–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∏–∑ PCAP: {real_attacks}")
                except Exception as e:
                    LOG.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∏–∑ PCAP: {e}")
            
            # Extract attack combination from strategy object (fallback)
            attacks_from_object = self._extract_attack_combination(strategy)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –∞—Ç–∞–∫–∏ –∏–∑ PCAP –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –∏–∑ –æ–±—ä–µ–∫—Ç–∞
            attacks = real_attacks if real_attacks else attacks_from_object
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            if real_attacks and real_attacks != attacks_from_object:
                LOG.warning(f"‚ö†Ô∏è –ù–ï–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï –°–¢–†–ê–¢–ï–ì–ò–ô!")
                LOG.warning(f"   –ù–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞: {attacks_from_object}")
                LOG.warning(f"   –†–µ–∞–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ: {real_attacks}")
                LOG.warning(f"   üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –†–ï–ê–õ–¨–ù–û –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω—É—é: {real_attacks}")
            
            # Get strategy parameters
            parameters = real_params if real_params else getattr(strategy, 'parameters', {})
            
            # Ensure forced override parameters are set
            if 'no_fallbacks' not in parameters:
                parameters['no_fallbacks'] = True
            if 'forced' not in parameters:
                parameters['forced'] = True
            
            # Determine primary attack type
            attack_type = attacks[0] if attacks else 'unknown'
            
            # Get strategy name and rationale
            strategy_name = getattr(strategy, 'name', f"{attack_type}_strategy")
            original_name = strategy_name
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            # –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω: —Å–Ω–∞—á–∞–ª–∞ —É–±–∏—Ä–∞–µ–º existing_, –ø–æ—Ç–æ–º smart_combo_
            
            # 1. –£–±–∏—Ä–∞–µ–º existing_ –ø—Ä–µ—Ñ–∏–∫—Å –µ—Å–ª–∏ –µ—Å—Ç—å (–æ–Ω –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ)
            if strategy_name.startswith("existing_"):
                strategy_name = strategy_name.replace("existing_", "")
            
            # 2. –£–±–∏—Ä–∞–µ–º smart_combo_ –ø—Ä–µ—Ñ–∏–∫—Å - —ç—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ "–∫—Ä–∏–≤—ã—Ö" –∏–º—ë–Ω
            if strategy_name.startswith("smart_combo_"):
                # –ó–∞–º–µ–Ω—è–µ–º smart_combo_ –Ω–∞ combo_ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
                strategy_name = strategy_name.replace("smart_combo_", "combo_")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –µ—Å–ª–∏ –±—ã–ª–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
            if strategy_name != original_name:
                LOG.info(f"üìù Normalized strategy name: {original_name} -> {strategy_name}")
            
            rationale = getattr(strategy, 'rationale', '')
            
            # If no rationale, generate one from attacks
            if not rationale and len(attacks) > 1:
                rationale = f"–£–º–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è: {', '.join(attacks)}"
            elif not rationale:
                rationale = f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {attack_type}"
            
            # Build strategy data structure
            strategy_data = {
                "type": attack_type,
                "attacks": attacks,
                "params": parameters,
                "metadata": {
                    "source": "adaptive_engine_cli",
                    "discovered_at": datetime.now().isoformat(),
                    "success_rate": getattr(strategy, 'success_rate', 100.0),
                    "rationale": rationale,
                    "strategy_name": strategy_name,
                    "strategy_id": getattr(strategy, 'id', f"{domain}_{attack_type}"),
                    "attack_count": len(attacks),
                    "validation_status": "validated",
                    "validated_at": datetime.now().isoformat(),
                    "pcap_verified": real_attacks is not None  # –§–ª–∞–≥ —á—Ç–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ –ø–æ PCAP
                }
            }
            
            LOG.info(f"üíæ Saving strategy for {domain}:")
            LOG.info(f"   Type: {attack_type}")
            LOG.info(f"   Attacks: {attacks}")
            LOG.info(f"   Parameters: {len(parameters)} params")
            LOG.info(f"   Rationale: {rationale}")
            LOG.info(f"   PCAP Verified: {real_attacks is not None}")
            
            # Update domain_rules.json
            self._update_domain_rules(domain, strategy_data)
            
            LOG.info(f"‚úÖ Strategy saved successfully for {domain}")
            
        except Exception as e:
            LOG.error(f"‚ùå Failed to save strategy for {domain}: {e}")
            import traceback
            LOG.error(traceback.format_exc())
    
    def _extract_real_strategy_from_pcap(self, pcap_file: str, domain: str) -> Optional[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∏–∑ PCAP —Ñ–∞–π–ª–∞.
        
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞–∫–µ—Ç—ã —á—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫–∞—è –∞—Ç–∞–∫–∞ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω–∏–ª–∞—Å—å:
        - split: –ø–∞–∫–µ—Ç—ã —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ —á–∞—Å—Ç–∏ (–º–∞–ª–µ–Ω—å–∫–∏–µ payload)
        - disorder: –ø–∞–∫–µ—Ç—ã –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (seq –Ω–µ —Ä–∞—Å—Ç—ë—Ç)
        - fake: –ø–∞–∫–µ—Ç—ã —Å –Ω–∏–∑–∫–∏–º TTL
        
        Args:
            pcap_file: Path to PCAP file
            domain: Domain name for filtering
            
        Returns:
            Dict with 'attacks' and 'params' or None if cannot determine
        """
        try:
            import os
            # Ensure pcap_file is a string, not a Path object
            pcap_file_str = str(pcap_file) if pcap_file else None
            if not pcap_file_str or not os.path.exists(pcap_file_str):
                LOG.debug(f"PCAP file not found: {pcap_file}")
                return None
            
            from scapy.all import rdpcap, TCP, IP, Raw
            
            packets = rdpcap(pcap_file_str)
            LOG.debug(f"üìä Analyzing PCAP: {len(packets)} packets")
            
            # –ò—â–µ–º –∏—Å—Ö–æ–¥—è—â–∏–µ TCP –ø–∞–∫–µ—Ç—ã —Å payload
            outgoing_packets = []
            for pkt in packets:
                if pkt.haslayer(IP) and pkt.haslayer(TCP) and pkt.haslayer(Raw):
                    # –ò—Å—Ö–æ–¥—è—â–∏–µ –ø–∞–∫–µ—Ç—ã (–æ—Ç –Ω–∞—Å)
                    if pkt[IP].src.startswith('192.168.') or pkt[IP].src.startswith('10.'):
                        outgoing_packets.append(pkt)
            
            if len(outgoing_packets) < 2:
                LOG.debug(f"Not enough packets for analysis: {len(outgoing_packets)}")
                return None
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ TCP –ø–æ—Ç–æ–∫–∞–º
            flows = {}
            for pkt in outgoing_packets:
                flow_key = (pkt[IP].src, pkt[TCP].sport, pkt[IP].dst, pkt[TCP].dport)
                if flow_key not in flows:
                    flows[flow_key] = []
                flows[flow_key].append(pkt)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π –ø–æ—Ç–æ–∫
            if not flows:
                return None
            
            flow_packets = list(flows.values())[0]
            if len(flow_packets) < 2:
                return None
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            flow_packets.sort(key=lambda p: float(p.time))
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∞—Ç–∞–∫
            seq_numbers = [pkt[TCP].seq for pkt in flow_packets[:10]]
            ttls = [pkt[IP].ttl for pkt in flow_packets[:10]]
            payload_sizes = [len(pkt[Raw].load) for pkt in flow_packets[:10]]
            
            detected_attacks = []
            params = {}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º disorder (seq –Ω–µ —Ä–∞—Å—Ç—ë—Ç –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ)
            if len(seq_numbers) >= 2:
                is_ordered = all(seq_numbers[i] < seq_numbers[i+1] for i in range(len(seq_numbers)-1))
                if not is_ordered:
                    detected_attacks.append('disorder')
                    LOG.debug(f"‚úÖ Detected: disorder (seq not monotonic)")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º fake (–Ω–∏–∑–∫–∏–π TTL)
            if any(ttl <= 5 for ttl in ttls):
                detected_attacks.append('fake')
                params['ttl'] = min(ttl for ttl in ttls if ttl <= 5)
                LOG.debug(f"‚úÖ Detected: fake (TTL={params['ttl']})")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º split (–º–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞–∫–µ—Ç—ã)
            small_packets = [s for s in payload_sizes if s < 100]
            if small_packets and len(small_packets) >= 1:
                detected_attacks.append('split')
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º split_pos –ø–æ —Ä–∞–∑–º–µ—Ä—É –ø–µ—Ä–≤–æ–≥–æ –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –ø–∞–∫–µ—Ç–∞
                first_small = min(small_packets)
                params['split_pos'] = first_small
                params['split_count'] = 2
                LOG.debug(f"‚úÖ Detected: split (pos={first_small})")
            
            if not detected_attacks:
                LOG.debug("No attacks detected in PCAP")
                return None
            
            LOG.info(f"üìä PCAP Analysis Result: {detected_attacks}")
            return {
                'attacks': detected_attacks,
                'params': params
            }
            
        except Exception as e:
            LOG.warning(f"Error analyzing PCAP: {e}")
            return None
    
    def _update_domain_rules(self, domain: str, strategy_data: Dict[str, Any]):
        """
        Update domain_rules.json with new strategy data.
        
        Args:
            domain: Domain name
            strategy_data: Strategy data dictionary
        """
        # –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ attacks —Å–ø–∏—Å–æ–∫ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç smart_combo_ –∏–º—ë–Ω
        attacks = strategy_data.get('attacks', [])
        if any(a.startswith('smart_combo_') for a in attacks):
            LOG.error(f"‚ùå VALIDATION ERROR: attacks list contains smart_combo_ names: {attacks}")
            LOG.error(f"   This should have been decomposed earlier!")
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ä—É–µ–º
            decomposed_attacks = []
            for attack in attacks:
                if attack.startswith('smart_combo_'):
                    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ _
                    parts = attack.replace('smart_combo_', '').split('_')
                    known_attacks = {'fake', 'split', 'disorder', 'multisplit', 'seqovl'}
                    for part in parts:
                        if part in known_attacks:
                            decomposed_attacks.append(part)
                else:
                    decomposed_attacks.append(attack)
            
            LOG.warning(f"‚ö†Ô∏è Auto-decomposed attacks: {attacks} -> {decomposed_attacks}")
            strategy_data['attacks'] = decomposed_attacks
            
            # –û–±–Ω–æ–≤–ª—è–µ–º type –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if strategy_data.get('type', '').startswith('smart_combo_'):
                strategy_data['type'] = decomposed_attacks[0] if decomposed_attacks else 'unknown'
        
        domain_rules_file = Path("domain_rules.json")
        
        try:
            # Load existing rules
            if domain_rules_file.exists():
                with open(domain_rules_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            else:
                data = {
                    "version": "1.0",
                    "last_updated": datetime.now().isoformat(),
                    "domain_rules": {}
                }
            
            # Ensure domain_rules key exists
            if "domain_rules" not in data:
                data["domain_rules"] = {}
            
            # Update strategy for domain
            data["domain_rules"][domain] = strategy_data
            data["last_updated"] = datetime.now().isoformat()
            
            # Save back to file
            with open(domain_rules_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            LOG.debug(f"üìù Updated domain_rules.json for {domain}")
            
        except Exception as e:
            LOG.error(f"‚ùå Failed to update domain_rules.json: {e}")
            raise
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã"""
        return self.stats.copy()
    
    def get_closed_loop_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è.
        
        –°–æ–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É closed_loop, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É knowledge_base,
        –≤—ã—á–∏—Å–ª—è–µ—Ç cache efficiency, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞
        """
        # Task 8.1: Update metrics from components before returning statistics
        if self.metrics_collector:
            try:
                self.metrics_collector.update_from_adaptive_engine(self)
                if self.knowledge_accumulator:
                    self.metrics_collector.update_from_knowledge_accumulator(self.knowledge_accumulator)
            except Exception as e:
                LOG.warning(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–º–∫–Ω—É—Ç–æ–≥–æ —Ü–∏–∫–ª–∞
        closed_loop_stats = self.closed_loop_stats.copy()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        knowledge_base_stats = {}
        if self.knowledge_accumulator:
            try:
                patterns = self.knowledge_accumulator.get_all_patterns()
                knowledge_base_stats = {
                    "total_patterns": len(patterns),
                    "active_patterns": len([p for p in patterns if p.metadata.get("confidence", 0) > 0.3]),
                    "high_confidence_patterns": len([p for p in patterns if p.metadata.get("confidence", 0) > 0.7]),
                    "total_applications": sum(p.metadata.get("success_count", 0) for p in patterns),
                    "average_confidence": sum(p.metadata.get("confidence", 0) for p in patterns) / len(patterns) if patterns else 0.0
                }
            except Exception as e:
                LOG.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
                knowledge_base_stats = {"error": str(e)}
        
        # Cache efficiency
        cache_efficiency = {}
        if self.stats["cache_hits"] + self.stats["cache_misses"] > 0:
            cache_efficiency = {
                "hit_rate": self.stats["cache_hits"] / (self.stats["cache_hits"] + self.stats["cache_misses"]),
                "total_requests": self.stats["cache_hits"] + self.stats["cache_misses"],
                "cache_sizes": {
                    "fingerprints": len(self._fingerprint_cache),
                    "strategies": len(self._strategy_cache),
                    "domain_accessibility": len(self._domain_accessibility_cache)
                }
            }
        
        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        return {
            "timestamp": datetime.now().isoformat(),
            "closed_loop": closed_loop_stats,
            "knowledge_base": knowledge_base_stats,
            "cache_efficiency": cache_efficiency,
            "performance_metrics": {
                "average_test_time": self.stats["average_test_time"],
                "fingerprint_creation_time": self.stats["fingerprint_creation_time"],
                "strategy_generation_time": self.stats["strategy_generation_time"]
            },
            "success_metrics": {
                "domains_processed": self.stats["domains_processed"],
                "strategies_found": self.stats["strategies_found"],
                "total_trials": self.stats["total_trials"],
                "success_rate": self.stats["strategies_found"] / self.stats["domains_processed"] if self.stats["domains_processed"] > 0 else 0.0
            },
            "learning_effectiveness": {
                "iterations_per_success": closed_loop_stats["iterations_total"] / self.stats["strategies_found"] if self.stats["strategies_found"] > 0 else 0.0,
                "strategies_per_iteration": closed_loop_stats["strategies_augmented"] / closed_loop_stats["iterations_total"] if closed_loop_stats["iterations_total"] > 0 else 0.0,
                "pattern_match_rate": closed_loop_stats["pattern_matches"] / closed_loop_stats["iterations_total"] if closed_loop_stats["iterations_total"] > 0 else 0.0
            },
            "adaptive_timeouts": self.timeout_stats.copy(),
            "protocol_preferences": self.get_protocol_preference_statistics(),
            "profiling": self.get_profiling_statistics(),
            "batch_operations": (
                self.knowledge_accumulator.get_batch_statistics() 
                if self.knowledge_accumulator else {}
            )
        }
    
    async def _test_strategies_parallel(self, domain: str, strategies: List[Any], progress_callback=None) -> Tuple[Optional[Any], int]:
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
        if not self._executor:
            LOG.warning("Executor not available for parallel testing")
            return None, 0
        
        if progress_callback:
            progress_callback(f"[START] –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π...")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        loop = asyncio.get_event_loop()
        tasks = []
        
        for i, strategy in enumerate(strategies):
            task = loop.run_in_executor(
                self._executor,
                self._test_strategy_sync,
                domain,
                strategy
            )
            tasks.append((strategy, task))
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á –∏–ª–∏ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—Ö–∞
        successful_strategy = None
        completed_tasks = 0
        
        try:
            for strategy, task in tasks:
                try:
                    result = await task
                    completed_tasks += 1
                    
                    if result.success:
                        successful_strategy = strategy
                        
                        # Task 6.4: Extract pcap_file from result
                        pcap_file = None
                        if hasattr(result, 'artifacts') and hasattr(result.artifacts, 'pcap_file'):
                            pcap_file = result.artifacts.pcap_file
                        elif hasattr(result, 'pcap_file'):
                            pcap_file = result.pcap_file
                        
                        # Task 7.4: Extract session_id from result for coordinator routing
                        session_id = None
                        if hasattr(result, 'metadata') and result.metadata:
                            session_id = result.metadata.get('session_id')
                        elif isinstance(result, dict):
                            session_id = result.get('session_id')
                        
                        # Task 7.4: Pass session_id for coordinator save routing (Requirements 1.4, 1.5, 9.4)
                        await self._save_working_strategy(domain, strategy, pcap_file, session_id)
                        
                        if progress_callback:
                            progress_callback(f"[OK] –ù–∞–π–¥–µ–Ω–∞ —Ä–∞–±–æ—á–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ): {strategy.name}")
                        
                        # –û—Ç–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–¥–∞—á–∏
                        for remaining_strategy, remaining_task in tasks:
                            if not remaining_task.done():
                                remaining_task.cancel()
                        
                        break
                    else:
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ—É–¥–∞—á—É –≤ —Ñ–æ–Ω–µ
                        asyncio.create_task(
                            self._analyze_strategy_failure(domain, strategy, result, None, None)
                        )
                        
                except Exception as e:
                    LOG.warning(f"Error in parallel strategy test {strategy.name}: {e}")
                    completed_tasks += 1
        
        except Exception as e:
            LOG.error(f"Error in parallel testing: {e}")
        
        LOG.info(f"Parallel testing completed: {completed_tasks}/{len(strategies)} strategies tested")
        return successful_strategy, completed_tasks
    
    async def test_strategy_on_multiple_domains(self, domains: List[str], strategy: Any, 
                                              progress_callback=None) -> Dict[str, bool]:
        """
        –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–∞—Ö –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
        
        –≠—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –∫–∞–∂–¥—ã–π –¥–æ–º–µ–Ω —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ,
        –Ω–æ –≤—Å–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–Ω—É –∏ —Ç—É –∂–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é.
        
        Args:
            domains: –°–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            progress_callback: Callback –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            
        Returns:
            Dict[str, bool]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è {domain: success}
        """
        if not self._executor:
            LOG.warning("Executor not available for parallel domain testing")
            # Fallback –∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º—É —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é
            results = {}
            for domain in domains:
                result = await self._test_strategy_with_capture(domain, strategy)
                results[domain] = result.success
            return results
        
        if progress_callback:
            progress_callback(f"[START] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {strategy.name} –Ω–∞ {len(domains)} –¥–æ–º–µ–Ω–∞—Ö –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–º–µ–Ω–æ–≤
        loop = asyncio.get_event_loop()
        tasks = []
        
        for domain in domains:
            task = loop.run_in_executor(
                self._executor,
                self._test_strategy_sync,
                domain,
                strategy
            )
            tasks.append((domain, task))
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        results = {}
        completed_tasks = 0
        
        try:
            for domain, task in tasks:
                try:
                    result = await task
                    completed_tasks += 1
                    results[domain] = result.success
                    
                    status = "[OK] –£–°–ü–ï–•" if result.success else "[FAIL] –ù–ï–£–î–ê–ß–ê"
                    LOG.info(f"[TEST] {domain}: {status} (—Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy.name})")
                    
                    if result.success:
                        # Task 6.4: Extract pcap_file from result
                        pcap_file = None
                        if hasattr(result, 'artifacts') and hasattr(result.artifacts, 'pcap_file'):
                            pcap_file = result.artifacts.pcap_file
                        elif hasattr(result, 'pcap_file'):
                            pcap_file = result.pcap_file
                        
                        # Task 7.4: Extract session_id from result for coordinator routing
                        session_id = None
                        if hasattr(result, 'metadata') and result.metadata:
                            session_id = result.metadata.get('session_id')
                        elif isinstance(result, dict):
                            session_id = result.get('session_id')
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–±–æ—á—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –¥–æ–º–µ–Ω–∞ —Å PCAP –∞–Ω–∞–ª–∏–∑–æ–º
                        # Task 7.4: Pass session_id for coordinator save routing (Requirements 1.4, 1.5, 9.4)
                        await self._save_working_strategy(domain, strategy, pcap_file, session_id)
                        
                except Exception as e:
                    LOG.warning(f"Error testing {domain} with {strategy.name}: {e}")
                    results[domain] = False
                    completed_tasks += 1
        
        except Exception as e:
            LOG.error(f"Error in parallel domain testing: {e}")
        
        successful_domains = [d for d, success in results.items() if success]
        LOG.info(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {strategy.name}: {len(successful_domains)}/{len(domains)} –¥–æ–º–µ–Ω–æ–≤ —É—Å–ø–µ—à–Ω–æ")
        
        return results
    
    def _test_strategy_sync(self, domain: str, strategy: Any) -> Any:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ executor"""
        try:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π event loop –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                if TestResult and TrialArtifacts:
                    return loop.run_until_complete(self._test_strategy_with_capture(domain, strategy))
                else:
                    # Fallback implementation
                    return {
                        "success": False,
                        "error": "Components not available",
                        "artifacts": {}
                    }
            finally:
                loop.close()
                
        except Exception as e:
            if TestResult and TrialArtifacts:
                return TestResult(
                    success=False,
                    error=str(e),
                    artifacts=TrialArtifacts()
                )
            else:
                return {
                    "success": False,
                    "error": str(e),
                    "artifacts": {}
                }
    
    async def _analyze_strategy_failure(self, domain: str, strategy: Any, result: Any, 
                                      fingerprint: Optional[Any], progress_callback=None):
        """–ê–Ω–∞–ª–∏–∑ –Ω–µ—É–¥–∞—á–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        if not self.config.enable_failure_analysis or not result.artifacts:
            return
        
        try:
            # Create a mock pcap file path for testing
            pcap_file = getattr(result.artifacts, 'pcap_file', None) if result.artifacts else None
            if pcap_file and str(pcap_file).startswith('<Mock'):
                pcap_file = None  # Skip analysis for mock objects
            
            if pcap_file:
                # Ensure pcap_file is a string, not a Path object
                pcap_file_str = str(pcap_file)
                failure_report = await self.failure_analyzer.analyze_pcap(pcap_file_str, strategy, domain=domain)
            else:
                # Skip failure analysis if no valid pcap file
                failure_report = None
            
            if fingerprint and failure_report:
                # Convert FailureReport to dictionary format expected by update_from_failure
                failure_dict = {
                    "root_cause": failure_report.root_cause.value,
                    "confidence": failure_report.confidence,
                    "block_timing": failure_report.block_timing
                }
                self.fingerprint_service.update_from_failure(
                    domain, failure_dict
                )
            
            # –ù–û–í–û–ï: –û–±–Ω–æ–≤–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—É–¥–∞—á–∏
            if failure_report:
                current_timeout = self.config.strategy_timeout
                updated_timeout = self._update_adaptive_timeout_from_failure(
                    domain, failure_report, current_timeout
                )
                
                if updated_timeout != current_timeout:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω
                    if not hasattr(self, '_original_config_values'):
                        self._original_config_values = {}
                    if "strategy_timeout" not in self._original_config_values:
                        self._original_config_values["strategy_timeout"] = current_timeout
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–π —Ç–∞–π–º–∞—É—Ç
                    self.config.strategy_timeout = updated_timeout
                    LOG.info(f"üïê –û–±–Ω–æ–≤–ª–µ–Ω –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è {domain}: {updated_timeout:.1f}s")
                    
                    if progress_callback:
                        progress_callback(f"[TIMEOUT] –¢–∞–π–º–∞—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω: {updated_timeout:.1f}s")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞–Ω–∏—è
            if domain not in self.negative_knowledge:
                self.negative_knowledge[domain] = []
            self.negative_knowledge[domain].append(getattr(strategy, 'name', 'unknown'))
            
            # Task 5.4: Record failure in adaptive_knowledge.json
            if self.adaptive_knowledge:
                try:
                    # Extract ConnectionMetrics from result
                    connection_metrics = None
                    if hasattr(result, 'metadata') and result.metadata:
                        if 'connection_metrics' in result.metadata:
                            # Reconstruct ConnectionMetrics from dict
                            cm_dict = result.metadata['connection_metrics']
                            if CONNECTION_METRICS_AVAILABLE and ConnectionMetrics:
                                connection_metrics = ConnectionMetrics(
                                    connect_time_ms=cm_dict.get('connect_time_ms', 0.0),
                                    tls_time_ms=cm_dict.get('tls_time_ms', 0.0),
                                    ttfb_ms=cm_dict.get('ttfb_ms', 0.0),
                                    total_time_ms=cm_dict.get('total_time_ms', 0.0),
                                    http_status=cm_dict.get('http_status'),
                                    bytes_received=cm_dict.get('bytes_received', 0),
                                    tls_completed=cm_dict.get('tls_completed', False),
                                    error=cm_dict.get('error'),
                                    rst_received=cm_dict.get('rst_received', False),
                                    rst_timing_ms=cm_dict.get('rst_timing_ms'),
                                    timeout=cm_dict.get('timeout', False),
                                    block_type=BlockType(cm_dict.get('block_type', 'unknown')) if BlockType else None
                                )
                    
                    # If no ConnectionMetrics, create a basic one for failure
                    if connection_metrics is None and CONNECTION_METRICS_AVAILABLE and ConnectionMetrics:
                        connection_metrics = ConnectionMetrics(
                            timeout=True,
                            block_type=BlockType.PASSIVE_DROP
                        )
                    
                    # Extract strategy parameters
                    strategy_params = {}
                    if hasattr(strategy, 'params'):
                        strategy_params = strategy.params
                    elif hasattr(strategy, 'parameters'):
                        strategy_params = strategy.parameters
                    elif hasattr(strategy, 'to_dict'):
                        strategy_dict = strategy.to_dict()
                        strategy_params = strategy_dict.get('params', {})
                    
                    # Record failure in adaptive_knowledge.json
                    self.adaptive_knowledge.record_failure(
                        domain=domain,
                        strategy_name=strategy.name if hasattr(strategy, 'name') else 'unknown',
                        strategy_params=strategy_params,
                        metrics=connection_metrics
                    )
                    
                    LOG.debug(f"üìö –ó–∞–ø–∏—Å–∞–Ω–∞ –Ω–µ—É–¥–∞—á–∞ –≤ adaptive_knowledge.json: {strategy.name if hasattr(strategy, 'name') else 'unknown'}")
                except Exception as e:
                    LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –Ω–µ—É–¥–∞—á–∏ –≤ adaptive_knowledge.json: {e}")
            
            self.stats["failures_analyzed"] += 1
            
            if progress_callback and failure_report:
                progress_callback(f"[FAIL] –ù–µ—É–¥–∞—á–∞: {failure_report.root_cause.value}")
            
        except Exception as e:
            LOG.warning(f"Failed to analyze failure: {e}")
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        cache_hit_rate = 0.0
        if self.stats["cache_hits"] + self.stats["cache_misses"] > 0:
            cache_hit_rate = self.stats["cache_hits"] / (self.stats["cache_hits"] + self.stats["cache_misses"])
        
        return {
            "cache_hit_rate": cache_hit_rate,
            "cache_sizes": {
                "fingerprints": len(self._fingerprint_cache),
                "strategies": len(self._strategy_cache),
                "domain_accessibility": len(self._domain_accessibility_cache),
                "protocol_preferences": len(self._protocol_preference_cache)
            },
            "average_times": {
                "test_time": self.stats["average_test_time"],
                "fingerprint_creation": self.stats["fingerprint_creation_time"],
                "strategy_generation": self.stats["strategy_generation_time"]
            },
            "parallel_testing": {
                "enabled": self.config.enable_parallel_testing,
                "max_workers": self.config.max_parallel_workers,
                "tests_executed": self.stats["parallel_tests_executed"]
            },
            "profiling_data": self._profiling_data.copy() if self.config.enable_profiling else {}
        }
    
    def optimize_caches(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫—ç—à–µ–π - —É–¥–∞–ª–µ–Ω–∏–µ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        current_time = datetime.now()
        total_expired = 0
        
        with self._cache_lock:
            # –û—á–∏—Å—Ç–∫–∞ fingerprint –∫—ç—à–∞
            expired_keys = [
                key for key, data in self._fingerprint_cache.items()
                if not self._is_cache_valid(data["timestamp"])
            ]
            for key in expired_keys:
                del self._fingerprint_cache[key]
            total_expired += len(expired_keys)
            
            # –û—á–∏—Å—Ç–∫–∞ strategy –∫—ç—à–∞
            expired_keys = [
                key for key, data in self._strategy_cache.items()
                if not self._is_cache_valid(data["timestamp"])
            ]
            for key in expired_keys:
                del self._strategy_cache[key]
            total_expired += len(expired_keys)
            
            # –û—á–∏—Å—Ç–∫–∞ protocol preference –∫—ç—à–∞
            expired_keys = [
                key for key, data in self._protocol_preference_cache.items()
                if not self._is_cache_valid(data["timestamp"])
            ]
            for key in expired_keys:
                del self._protocol_preference_cache[key]
            total_expired += len(expired_keys)
        
        LOG.info(f"Cache optimization completed, removed {total_expired} expired entries")
    
    async def _test_strategy_with_capture(self, domain: str, strategy: Any, shared_pcap_file: Optional[Any] = None) -> Any:
        """
        –¢–µ—Å—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å –ø–æ–ø—ã—Ç–∫–æ–π PCAP-–∑–∞—Ö–≤–∞—Ç–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç TestResult.
        –°–æ–≤–º–µ—Å—Ç–∏–º —Å StrategyFailureAnalyzer (SFA) —á–µ—Ä–µ–∑ TrialArtifacts.
        
        Task 7.2: Integrated with TestResultCoordinator for consistent test verdicts.
        
        Args:
            domain: Domain name
            strategy: Strategy to test
            shared_pcap_file: Optional shared PCAP file for continuous capture (Requirement 1.1)
        """
        # Task 7.2: Start test session with coordinator (Requirement 9.1)
        session_id = None
        strategy_name = self._get_strategy_name(strategy)
        
        if self.test_result_coordinator:
            # Use shared PCAP file if provided, otherwise create domain-specific file
            # Note: Using shared PCAP ensures all packets are captured properly
            # Individual metadata files track which strategy was tested
            if shared_pcap_file:
                pcap_file = shared_pcap_file
            else:
                # Create domain-specific PCAP file (shared across all strategies for this domain)
                safe_domain = domain.replace(".", "_")
                timestamp = int(time.time())
                pcap_file = f"temp_pcap/capture_{safe_domain}_{timestamp}.pcap"
            
            session_id = self.test_result_coordinator.start_test(domain, strategy_name, pcap_file)
            LOG.info(f"üöÄ Starting test: [{strategy_name}] for [{domain}] (session: {session_id})")
        
        if not self.bypass_engine:
            # Fallback: –¥–≤–∏–∂–æ–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            if session_id and self.test_result_coordinator:
                self.test_result_coordinator.record_response(session_id, timeout=True)
                verdict = self.test_result_coordinator.finalize_test(session_id)
                LOG.warning(f"‚ùå Test result: [{verdict.value}] for [{strategy_name}]")
            
            real = await self._test_strategy_real(domain, strategy)
            # Task 7.4: Include session_id in result for coordinator routing
            if TestResult and TrialArtifacts:
                test_result = TestResult(
                    success=bool(getattr(real, 'success', False) if hasattr(real, 'success') else (real.get("success", False) if hasattr(real, 'get') else False)),
                    error=getattr(real, 'error', None) if hasattr(real, 'error') else (real.get("error") if hasattr(real, 'get') else None),
                    artifacts=TrialArtifacts(
                        pcap_file=None
                    )
                )
                if session_id:
                    if not hasattr(test_result, 'metadata') or test_result.metadata is None:
                        test_result.metadata = {}
                    test_result.metadata['session_id'] = session_id
                return test_result
            result_dict = {"success": False, "error": "Bypass engine not available", "artifacts": {}}
            if session_id:
                result_dict['session_id'] = session_id
            return result_dict

        try:
            import socket
            try:
                target_ip = socket.gethostbyname(domain)
            except Exception as e:
                # Task 7.4: Include session_id in result for coordinator routing
                if TestResult and TrialArtifacts:
                    test_result = TestResult(success=False, error=f"DNS failed: {e}", artifacts=TrialArtifacts())
                    if session_id:
                        if not hasattr(test_result, 'metadata') or test_result.metadata is None:
                            test_result.metadata = {}
                        test_result.metadata['session_id'] = session_id
                    return test_result
                result_dict = {"success": False, "error": f"DNS failed: {e}", "artifacts": {}}
                if session_id:
                    result_dict['session_id'] = session_id
                return result_dict

            strategy_dict = self._convert_strategy_to_unified_format(strategy)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
            adaptive_timeout = self._calculate_adaptive_timeout(domain)

            start_time = time.time()
            with self._divert_lock:
                # Task 11.2: Pass verification_mode from config
                verification_mode = self.config.verify_with_pcap
                
                # Requirement 1.2: Use shared PCAP file instead of creating separate files
                # If shared_pcap_file is provided, disable individual capture
                enable_individual_capture = verification_mode and not shared_pcap_file
                
                # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –µ–¥–∏–Ω—ã–π —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∑–∞—Ö–≤–∞—Ç–æ–º, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                try:
                    result = self._test_strategy(
                        target_ip=target_ip,
                        strategy_input=strategy_dict,
                            domain=domain,
                            timeout=adaptive_timeout,
                            enable_capture=enable_individual_capture,  # Only if no shared PCAP
                            verification_mode=verification_mode  # Task 11.2
                        )
                    
                    # Requirement 1.2: Process result and return immediately
                    # Use shared PCAP file if provided
                    if shared_pcap_file:
                        if hasattr(result, 'pcap_file'):
                            result.pcap_file = shared_pcap_file
                        elif isinstance(result, dict):
                            result['pcap_file'] = shared_pcap_file
                        LOG.info(f"[TEST] Using shared PCAP file: {shared_pcap_file}")
                    
                    success = bool(getattr(result, 'success', False) if hasattr(result, 'success') else (result.get("success", False) if isinstance(result, dict) else False))
                    error = getattr(result, 'error', None) if hasattr(result, 'error') else (result.get("error") if isinstance(result, dict) else None)
                    pcap_file_result = shared_pcap_file or (getattr(result, 'pcap_file', None) if hasattr(result, 'pcap_file') else (result.get("pcap_file") if isinstance(result, dict) else None))
                    
                    # FIX: Update session with actual PCAP file path from result
                    # The predicted path may not match the actual path created by bypass engine
                    if session_id and self.test_result_coordinator and pcap_file_result:
                        session = self.test_result_coordinator.get_session(session_id)
                        if session and session.pcap_file != pcap_file_result:
                            LOG.debug(f"üìù Updating session PCAP path: {session.pcap_file} -> {pcap_file_result}")
                            session.pcap_file = pcap_file_result
                    
                    # Task 7.2: Record test evidence with coordinator (Requirement 9.1)
                    if session_id and self.test_result_coordinator:
                        # Record retransmissions (extract from result if available)
                        retransmission_count = 0
                        if isinstance(result, dict):
                            retransmission_count = result.get('retransmissions', 0) or result.get('retransmission_count', 0)
                        elif hasattr(result, 'retransmissions'):
                            retransmission_count = result.retransmissions
                        elif hasattr(result, 'retransmission_count'):
                            retransmission_count = result.retransmission_count
                        
                        # FIX: Relax retransmission threshold for complex domains
                        # If retransmissions are present but not excessive (<= 10), mask them to 0
                        # This ensures the coordinator doesn't fail the test purely on retransmissions
                        # when the site actually opened successfully (especially for complex domains like pagead2)
                        if 0 < retransmission_count <= 10 and success:
                            LOG.info(f"‚ÑπÔ∏è Masking retransmission count {retransmission_count} -> 0 (site opened successfully)")
                            retransmission_count = 0
                        
                        self.test_result_coordinator.record_retransmission(session_id, retransmission_count)
                        
                        # Record response
                        response_status = None
                        if isinstance(result, dict):
                            response_status = result.get('status_code') or result.get('http_status')
                        elif hasattr(result, 'status_code'):
                            response_status = result.status_code
                        elif hasattr(result, 'http_status'):
                            response_status = result.http_status
                        
                        timeout_occurred = error and ('timeout' in str(error).lower() or 'timed out' in str(error).lower())
                        self.test_result_coordinator.record_response(session_id, response_status, timeout=timeout_occurred)
                        
                        # Task 7.2: Finalize test and get verdict (Requirement 9.2, 9.3)
                        verdict = self.test_result_coordinator.finalize_test(session_id)
                        LOG.info(f"‚úÖ Test result: [{verdict.value}] for [{strategy_name}]")
                        
                        # Override success based on coordinator verdict
                        success = verdict.value == 'success'
                        if not success and not error:
                            error = f"Test verdict: {verdict.value}"
                    
                    # Task 7.4: Include session_id in result for coordinator routing
                    if TestResult and TrialArtifacts:
                        test_result = TestResult(
                            success=success,
                            error=error,
                            artifacts=TrialArtifacts(
                                pcap_file=pcap_file_result
                            )
                        )
                        # Store session_id in metadata for coordinator routing
                        if session_id:
                            if not hasattr(test_result, 'metadata') or test_result.metadata is None:
                                test_result.metadata = {}
                            test_result.metadata['session_id'] = session_id
                        return test_result
                    result_dict = {"success": success, "error": error, "artifacts": {"pcap_file": pcap_file_result}}
                    if session_id:
                        result_dict['session_id'] = session_id
                    return result_dict
                    
                except TypeError as te:
                    # –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ —Å–∏–≥–Ω–∞—Ç—É—Ä–∞–º–∏ (–±–µ–∑ enable_capture)
                    LOG.warning(f"[TEST] TypeError in _test_strategy, retrying without enable_capture: {te}")
                    result = self._test_strategy(
                        target_ip=target_ip,
                        strategy_input=strategy_dict,
                            domain=domain,
                            timeout=adaptive_timeout,
                            verification_mode=verification_mode  # Task 11.2
                        )

                    # Requirement 1.2: Use shared PCAP file if provided
                    # Override result's pcap_file with shared_pcap_file
                    if shared_pcap_file:
                        if hasattr(result, 'pcap_file'):
                            result.pcap_file = shared_pcap_file
                        elif hasattr(result, 'get'):
                            result['pcap_file'] = shared_pcap_file
                        LOG.info(f"[TEST] Using shared PCAP file: {shared_pcap_file}")

                    # Task 11.5: Run validation in verification mode (deferred to end of testing)
                    # Validation will be run once at the end with the complete PCAP file

                    # –û–∂–∏–¥–∞–µ–º—ã–µ –∫–ª—é—á–∏ result: success, error, pcap_file, telemetry, response_time ...
                    success = bool(getattr(result, 'success', False) if hasattr(result, 'success') else (result.get("success", False) if hasattr(result, 'get') else False))
                    error = getattr(result, 'error', None) if hasattr(result, 'error') else (result.get("error") if hasattr(result, 'get') else None)
                    pcap_file_result = (getattr(result, 'pcap_file', None) if hasattr(result, 'pcap_file') else (result.get("pcap_file") if hasattr(result, 'get') else None)) or \
                               (getattr(result, 'capture_path', None) if hasattr(result, 'capture_path') else (result.get("capture_path") if hasattr(result, 'get') else None)) or shared_pcap_file
                    
                    # FIX: Update session with actual PCAP file path from result
                    # The predicted path may not match the actual path created by bypass engine
                    if session_id and self.test_result_coordinator and pcap_file_result:
                        session = self.test_result_coordinator.get_session(session_id)
                        if session and session.pcap_file != pcap_file_result:
                            LOG.debug(f"üìù Updating session PCAP path: {session.pcap_file} -> {pcap_file_result}")
                            session.pcap_file = pcap_file_result
                    
                    # Task 7.2: Record test evidence with coordinator (Requirement 9.1)
                    if session_id and self.test_result_coordinator:
                        # Record retransmissions (extract from result if available)
                        retransmission_count = 0
                        if isinstance(result, dict):
                            retransmission_count = result.get('retransmissions', 0) or result.get('retransmission_count', 0)
                        elif hasattr(result, 'retransmissions'):
                            retransmission_count = result.retransmissions
                        elif hasattr(result, 'retransmission_count'):
                            retransmission_count = result.retransmission_count
                        
                        # FIX: Relax retransmission threshold for complex domains
                        # If retransmissions are present but not excessive (<= 10), mask them to 0
                        # This ensures the coordinator doesn't fail the test purely on retransmissions
                        # when the site actually opened successfully (especially for complex domains like pagead2)
                        if 0 < retransmission_count <= 10 and success:
                            LOG.info(f"‚ÑπÔ∏è Masking retransmission count {retransmission_count} -> 0 (site opened successfully)")
                            retransmission_count = 0
                        
                        self.test_result_coordinator.record_retransmission(session_id, retransmission_count)
                        
                        # Record response
                        response_status = None
                        if isinstance(result, dict):
                            response_status = result.get('status_code') or result.get('http_status')
                        elif hasattr(result, 'status_code'):
                            response_status = result.status_code
                        elif hasattr(result, 'http_status'):
                            response_status = result.http_status
                        
                        timeout_occurred = error and ('timeout' in str(error).lower() or 'timed out' in str(error).lower())
                        self.test_result_coordinator.record_response(session_id, response_status, timeout=timeout_occurred)

                    # Task 18: Adaptive strategy adjustment based on ClientHello size
                    if not success and pcap_file_result and self.strategy_adjuster:
                        try:
                            import os
                            if os.path.exists(pcap_file_result):
                                # Detect ClientHello size from PCAP
                                from core.metrics.clienthello_metrics import ClientHelloMetricsCollector
                                metrics_collector = ClientHelloMetricsCollector()
                                
                                # Get average ClientHello size
                                clienthello_size = 0
                                if hasattr(metrics_collector, 'get_average_clienthello_size'):
                                    clienthello_size = metrics_collector.get_average_clienthello_size(pcap_file_result)
                                
                                if clienthello_size > 0:
                                    LOG.info(f"[ADAPTIVE] Detected ClientHello size: {clienthello_size} bytes")
                                    
                                    # Adjust strategy based on ClientHello size
                                    adjusted_strategy = self.strategy_adjuster.adjust_strategy(
                                        strategy_dict.copy(),
                                        clienthello_size
                                    )
                                    
                                    # Re-test with adjusted strategy if parameters changed
                                    if adjusted_strategy != strategy_dict:
                                        LOG.info(f"[ADAPTIVE] Re-testing with adjusted strategy")
                                        
                                        # Re-test with adjusted strategy
                                        result_adjusted = self._test_strategy(
                                            target_ip=target_ip,
                                            strategy_input=adjusted_strategy,
                                            domain=domain,
                                            timeout=adaptive_timeout,
                                            verification_mode=verification_mode  # Task 11.2
                                        )
                                        
                                        # Task 11.5: Run validation for adjusted strategy (deferred to end)
                                        # Validation will be run once at the end with the complete PCAP file
                                        
                                        # Update result if adjusted strategy succeeded
                                        success_adjusted = bool(getattr(result_adjusted, 'success', False) if hasattr(result_adjusted, 'success') else (result_adjusted.get("success", False) if hasattr(result_adjusted, 'get') else False))
                                        if success_adjusted:
                                            LOG.info(f"[ADAPTIVE] ‚úì Adjusted strategy succeeded!")
                                            success = True
                                            error = None
                                            pcap_file_result = (getattr(result_adjusted, 'pcap_file', None) if hasattr(result_adjusted, 'pcap_file') else (result_adjusted.get("pcap_file") if hasattr(result_adjusted, 'get') else None)) or pcap_file_result
                                        else:
                                            LOG.warning(f"[ADAPTIVE] Adjusted strategy also failed")
                        except Exception as e:
                            LOG.warning(f"[ADAPTIVE] Failed to adjust strategy: {e}")

                    # Task 7.2: Finalize test and get verdict (Requirement 9.2, 9.3)
                    if session_id and self.test_result_coordinator:
                        verdict = self.test_result_coordinator.finalize_test(session_id)
                        LOG.info(f"‚úÖ Test result: [{verdict.value}] for [{strategy_name}]")
                        
                        # Override success based on coordinator verdict
                        success = verdict.value == 'success'
                        if not success and not error:
                            error = f"Test verdict: {verdict.value}"
                    
                    # Task 7.4: Include session_id in result for coordinator routing
                    if TestResult and TrialArtifacts:
                        test_result = TestResult(
                            success=success,
                            error=error,
                            artifacts=TrialArtifacts(
                                pcap_file=pcap_file_result
                            )
                        )
                        # Store session_id in metadata for coordinator routing
                        if session_id:
                            if not hasattr(test_result, 'metadata') or test_result.metadata is None:
                                test_result.metadata = {}
                            test_result.metadata['session_id'] = session_id
                        return test_result
                    result_dict = {"success": success, "error": error, "artifacts": {"pcap_file": pcap_file_result}}
                    if session_id:
                        result_dict['session_id'] = session_id
                    return result_dict

                # This code should never be reached - both try and except TypeError have return statements
                # If we get here, something went wrong
                LOG.error("‚ö†Ô∏è Unexpected code path in _test_strategy_with_capture - this should not happen")
                
                # Task 7.2: Finalize test even on unexpected path
                if session_id and self.test_result_coordinator:
                    self.test_result_coordinator.record_response(session_id, timeout=True)
                    verdict = self.test_result_coordinator.finalize_test(session_id)
                    LOG.warning(f"‚ùå Test result: [{verdict.value}] for [{strategy_name}]")
                
                # Task 7.4: Include session_id in result for coordinator routing
                if TestResult and TrialArtifacts:
                    test_result = TestResult(
                        success=False,
                        error="Unexpected code path",
                        artifacts=TrialArtifacts(pcap_file=shared_pcap_file)
                    )
                    if session_id:
                        if not hasattr(test_result, 'metadata') or test_result.metadata is None:
                            test_result.metadata = {}
                        test_result.metadata['session_id'] = session_id
                    return test_result
                result_dict = {"success": False, "error": "Unexpected code path", "artifacts": {"pcap_file": shared_pcap_file}}
                if session_id:
                    result_dict['session_id'] = session_id
                return result_dict

        except Exception as e:
            LOG.error(f"_test_strategy_with_capture error: {e}")
            
            # Task 7.2: Finalize test on exception
            if session_id and self.test_result_coordinator:
                self.test_result_coordinator.record_response(session_id, timeout=True)
                verdict = self.test_result_coordinator.finalize_test(session_id)
                LOG.warning(f"‚ùå Test result: [{verdict.value}] for [{strategy_name}]")
            
            # Task 7.4: Include session_id in result for coordinator routing
            if TestResult and TrialArtifacts:
                test_result = TestResult(
                    success=False,
                    error=str(e),
                    artifacts=TrialArtifacts()
                )
                if session_id:
                    if not hasattr(test_result, 'metadata') or test_result.metadata is None:
                        test_result.metadata = {}
                    test_result.metadata['session_id'] = session_id
                return test_result
            result_dict = {"success": False, "error": str(e), "artifacts": {}}
            if session_id:
                result_dict['session_id'] = session_id
            return result_dict
    
    def export_results(self, format: str = "json") -> Dict[str, Any]:
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        results = {
            "timestamp": datetime.now().isoformat(),
            "stats": self.get_stats(),
            "performance_metrics": self.get_performance_metrics(),
            "best_strategies": {},
            "fingerprints_count": len(self.fingerprint_service.fingerprints),
            "negative_knowledge_domains": len(self.negative_knowledge)
        }
        
        # –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        for domain, strategy in self.best_strategies.items():
            results["best_strategies"][domain] = {
                "name": strategy.name,
                "attack_name": strategy.attack_name,
                "parameters": strategy.parameters
            }
        
        return results
    
    def get_diagnostics_summary(self) -> Dict[str, Any]:
        """
        Task 7.4: Get comprehensive diagnostics summary including
        structured logs, performance metrics, and validation results.
        """
        summary = {
            "timestamp": datetime.now().isoformat(),
            "engine_stats": self.get_stats(),
            "performance_metrics": self.get_performance_metrics()
        }
        
        # Add structured logging statistics
        if self.structured_logger:
            try:
                summary["logging_stats"] = self.structured_logger.get_statistics()
            except Exception as e:
                LOG.debug(f"Failed to get logging stats: {e}")
                summary["logging_stats"] = {"error": str(e)}
        
        # Add performance monitoring summary
        if self.performance_monitor:
            try:
                summary["performance_summary"] = self.performance_monitor.get_performance_summary()
                summary["bottleneck_analysis"] = self.performance_monitor.get_bottleneck_analysis()
            except Exception as e:
                LOG.debug(f"Failed to get performance summary: {e}")
                summary["performance_summary"] = {"error": str(e)}
        
        return summary
    
    def export_diagnostics(self, output_file: str = "adaptive_diagnostics.json") -> bool:
        """
        Task 7.4: Export comprehensive diagnostics data to file.
        """
        try:
            diagnostics = self.get_diagnostics_summary()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(diagnostics, f, indent=2, ensure_ascii=False, default=str)
            
            LOG.info(f"Diagnostics exported to: {output_file}")
            
            # Also export structured logs if available
            if self.structured_logger:
                try:
                    log_file = output_file.replace('.json', '_logs.json')
                    self.structured_logger.export_logs(log_file)
                except Exception as e:
                    LOG.warning(f"Failed to export structured logs: {e}")
            
            # Export performance metrics if available
            if self.performance_monitor:
                try:
                    perf_file = output_file.replace('.json', '_performance.json')
                    self.performance_monitor.export_metrics(perf_file)
                except Exception as e:
                    LOG.warning(f"Failed to export performance metrics: {e}")
            
            return True
            
        except Exception as e:
            LOG.error(f"Failed to export diagnostics: {e}")
            return False
    
    def _save_protocol_preferences(self):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –≤ —Ñ–∞–π–ª –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è.
        
        –†–µ–∞–ª–∏–∑—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ FR-5.8: THE —Å–∏—Å—Ç–µ–º–∞ SHALL —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª (IPv4/IPv6) –¥–ª—è –¥–æ–º–µ–Ω–∞.
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏.
        """
        if not self.config.enable_caching:
            return
        
        try:
            preferences_file = Path(self.config.protocol_preferences_file)
            preferences_file.parent.mkdir(parents=True, exist_ok=True)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            preferences_data = {}
            
            with self._cache_lock:
                for domain, pref_data in self._protocol_preference_cache.items():
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
                    if self._is_cache_valid(pref_data.get("timestamp", datetime.now())):
                        preferences_data[domain] = {
                            "ip_type": pref_data.get("ip_type", "IPv4"),
                            "target_ip": pref_data.get("target_ip", ""),
                            "timestamp": pref_data.get("timestamp", datetime.now()).isoformat(),
                            "success_count": pref_data.get("success_count", 1)
                        }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            with open(preferences_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "version": "1.0",
                    "last_updated": datetime.now().isoformat(),
                    "preferences": preferences_data
                }, f, indent=2, ensure_ascii=False)
            
            LOG.debug(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(preferences_data)} –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –≤ {preferences_file}")
            
        except Exception as e:
            LOG.warning(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {e}")
    
    def _load_protocol_preferences(self):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
        
        –†–µ–∞–ª–∏–∑—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ FR-5.8: THE —Å–∏—Å—Ç–µ–º–∞ SHALL —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª (IPv4/IPv6) –¥–ª—è –¥–æ–º–µ–Ω–∞.
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏—Ö –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å.
        """
        if not self.config.enable_caching:
            return
        
        try:
            preferences_file = Path(self.config.protocol_preferences_file)
            
            if not preferences_file.exists():
                LOG.debug("–§–∞–π–ª –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –∫—ç—à")
                return
            
            with open(preferences_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            preferences = data.get("preferences", {})
            loaded_count = 0
            expired_count = 0
            
            with self._cache_lock:
                for domain, pref_data in preferences.items():
                    try:
                        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º timestamp –∏–∑ —Å—Ç—Ä–æ–∫–∏
                        timestamp_str = pref_data.get("timestamp")
                        if timestamp_str:
                            timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                        else:
                            timestamp = datetime.now()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å (–º–∞–∫—Å–∏–º—É–º 30 –¥–Ω–µ–π)
                        if self._is_cache_valid(timestamp):
                            self._protocol_preference_cache[domain] = {
                                "ip_type": pref_data.get("ip_type", "IPv4"),
                                "target_ip": pref_data.get("target_ip", ""),
                                "timestamp": timestamp,
                                "success_count": pref_data.get("success_count", 1)
                            }
                            loaded_count += 1
                        else:
                            expired_count += 1
                            
                    except Exception as e:
                        LOG.debug(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è {domain}: {e}")
                        expired_count += 1
            
            LOG.info(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤, "
                    f"–ø—Ä–æ–ø—É—â–µ–Ω–æ {expired_count} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ, –ø–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            if expired_count > 0:
                self._save_protocol_preferences()
                
        except Exception as e:
            LOG.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {e}")
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –∫—ç—à –ø—Ä–∏ –æ—à–∏–±–∫–µ
            with self._cache_lock:
                self._protocol_preference_cache.clear()

    def enable_profiling(self, enable: bool = True):
        """
        –í–∫–ª—é—á–µ–Ω–∏–µ/–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
        
        Args:
            enable: True –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.config.enable_profiling = enable
        
        if enable:
            LOG.info("üîç –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∫–ª—é—á–µ–Ω–æ")
        else:
            LOG.info("üîç –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—ã–∫–ª—é—á–µ–Ω–æ")
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            with self._profiling_lock:
                self._profiling_data.clear()
                self._avg_augmentation_time = 0.0
                self._augmentation_count = 0

    def __del__(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
        # Task 7.4: Export diagnostics on shutdown if enabled
        try:
            if hasattr(self, 'config') and getattr(self.config, 'export_diagnostics_on_shutdown', False):
                self.export_diagnostics()
        except Exception as e:
            LOG.debug(f"Failed to export diagnostics on shutdown: {e}")
        
        if hasattr(self, '_executor') and self._executor:
            self._executor.shutdown(wait=False)