"""
PCAP Analyzer for Strategy Application Analysis

This module provides enhanced PCAP analysis capabilities for verifying
strategy application in both testing and service modes. It extends the
existing IntelligentPCAPAnalyzer with strategy-specific analysis.

Requirements: 8.1, 8.2, 8.4, 8.5, 8.6, 8.7
"""

import logging
import struct
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Any, Set, Tuple
from datetime import datetime

# Import RawPCAPReader instead of Scapy
from core.packet.raw_pcap_reader import RawPCAPReader
from core.packet.raw_packet_engine import RawPacket, RawPacketEngine, ProtocolType
from core.bypass.sni.manipulator import SNIManipulator

LOG = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# DATA CLASSES
# ---------------------------------------------------------------------------


@dataclass
class StrategyAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ PCAP."""

    strategy_detected: bool  # –°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤ PCAP
    split_positions: List[int] = field(default_factory=list)  # –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ split
    sni_values: List[str] = field(default_factory=list)  # –ù–∞–π–¥–µ–Ω–Ω—ã–µ SNI –∑–Ω–∞—á–µ–Ω–∏—è
    checksums_valid: Dict[str, bool] = field(default_factory=dict)  # –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å checksums
    packet_count: int = 0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤
    anomalies: List[str] = field(default_factory=list)  # –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
    strategy_type: Optional[str] = None  # –¢–∏–ø –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–≤–∫–ª—é—á–∞—è combo)
    parameters: Dict[str, Any] = field(default_factory=dict)  # –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    detected_attacks: List[str] = field(
        default_factory=list
    )  # –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ –∞—Ç–∞–∫–∏ (Task 3.1)
    fake_packets_detected: int = 0  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–µ–π–∫–æ–≤—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ (Task 3.2)
    combo_attacks: List[str] = field(
        default_factory=list
    )  # –í—ã—è–≤–ª–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –∞—Ç–∞–∫ (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è)

    def matches_expected(self, expected_strategy: Dict[str, Any]) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.

        Args:
            expected_strategy: –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è

        Returns:
            True –µ—Å–ª–∏ PCAP —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        """
        if not self.strategy_detected:
            return False

        # Check strategy type
        expected_type = expected_strategy.get("attack", expected_strategy.get("type"))
        if expected_type and self.strategy_type != expected_type:
            return False

        # Check split positions if specified
        expected_split = expected_strategy.get("params", {}).get("split_pos")
        if expected_split and self.split_positions:
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ int, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞
            if isinstance(expected_split, str) and expected_split.isdigit():
                expected_split = int(expected_split)
            if expected_split not in self.split_positions:
                return False

        # Check SNI if specified
        expected_sni = expected_strategy.get("params", {}).get("sni")
        if expected_sni and self.sni_values:
            if expected_sni not in self.sni_values:
                return False

        # Check combo attacks list if –∑–∞–¥–∞–Ω–æ –≤ expected
        expected_attacks = expected_strategy.get("attacks")
        if expected_attacks and self.combo_attacks:
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤—É, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç –ø–æ—Ä—è–¥–∫–∞ –≤ expected
            if set(expected_attacks) != set(self.combo_attacks):
                return False

        return True


@dataclass
class ComparisonResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è PCAP –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏."""

    testing_pcap: str  # –ü—É—Ç—å –∫ PCAP –∏–∑ testing mode
    service_pcap: str  # –ü—É—Ç—å –∫ PCAP –∏–∑ service mode
    differences: List[Dict[str, Any]] = field(default_factory=list)  # –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è
    similarity_score: float = 0.0  # –û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0-1.0)
    testing_analysis: Optional[StrategyAnalysisResult] = None
    service_analysis: Optional[StrategyAnalysisResult] = None

    def generate_report(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏.

        Returns:
            –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        """
        lines: List[str] = []
        lines.append("=" * 80)
        lines.append("PCAP Comparison Report")
        lines.append("=" * 80)
        lines.append(f"Testing PCAP: {self.testing_pcap}")
        lines.append(f"Service PCAP: {self.service_pcap}")
        lines.append(f"Similarity Score: {self.similarity_score:.2%}")
        lines.append("")

        if self.differences:
            lines.append(f"Found {len(self.differences)} differences:")
            for i, diff in enumerate(self.differences, 1):
                lines.append(
                    f"  {i}. {diff.get('type', 'Unknown')}: "
                    f"{diff.get('description', 'No description')}"
                )
        else:
            lines.append("No significant differences found.")

        lines.append("")
        lines.append("=" * 80)

        return "\n".join(lines)


# ---------------------------------------------------------------------------
# COMBO DETECTION CONSTANTS
# ---------------------------------------------------------------------------

# –ë–∞–∑–æ–≤—ã–µ –∞—Ç–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å—á–∏—Ç–∞—é—Ç—Å—è "–æ—Å–Ω–æ–≤–Ω—ã–º–∏" –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
CORE_ATTACKS_ORDER: Dict[str, int] = {
    "disorder": 0,
    "fake": 1,
    "split": 2,
    "multisplit": 2,
    "seqovl": 4,
}

# –ú–µ—Ç–∫–∏, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ fooling/low-level –ø—Ä–∏—ë–º–∞–º, –∞ –Ω–µ –∫ –æ—Å–Ω–æ–≤–Ω—ã–º –∞—Ç–∞–∫–∞–º
FOOLING_LABELS: Set[str] = {"badsum", "badseq", "ttl_manipulation"}


class PCAPAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä PCAP —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π.

    –†–∞—Å—à–∏—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π IntelligentPCAPAnalyzer —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é
    –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏.

    Requirements: 8.1, 8.2, 8.4, 8.5, 8.6, 8.7
    """

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."""
        self.logger = LOG
        self.analysis_cache: Dict[str, StrategyAnalysisResult] = {}
        self.pcap_reader = RawPCAPReader()
        self.packet_engine = RawPacketEngine()
        self.logger.info("‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è RawPCAPReader –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ PCAP")

    # ------------------------------------------------------------------ #
    # –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–Ω–∞–ª–∏–∑ (PCAPAnalysisResult)
    # ------------------------------------------------------------------ #

    def analyze_pcap(
        self,
        pcap_file: str,
        strategy_name: Optional[str] = None,
        test_start_time: Optional[float] = None,
    ) -> "PCAPAnalysisResult":
        """
        Analyzes PCAP file and returns structured PCAPAnalysisResult.

        This is the main entry point for PCAP analysis that returns
        the standardized PCAPAnalysisResult dataclass.

        Implements error handling for:
        - PCAP file not found ‚Üí returns result with errors
        - PCAP file corrupted ‚Üí returns result with errors
        - Empty PCAP ‚Üí returns result with warnings

        Args:
            pcap_file: Path to PCAP file
            strategy_name: Strategy name for loading metadata (optional)
            test_start_time: Timestamp of test start for packet filtering (optional)

        Returns:
            PCAPAnalysisResult with all analysis data

        Requirements: 4.3 (Task 3.4), 6.1 (Task 8.2)
        """
        from core.test_result_models import PCAPAnalysisResult
        from core.pcap.metadata_saver import load_pcap_metadata
        import time

        start_time = time.time()
        errors: List[str] = []
        warnings: List[str] = []

        # Task: Testing-Production Parity - Load executed attacks from metadata (single source of truth)
        metadata = load_pcap_metadata(pcap_file, strategy_name)
        executed_attacks_from_log = metadata.get("executed_attacks") if metadata else None

        # Use provided test_start_time if available, otherwise try to load from metadata
        if test_start_time is None and metadata:
            test_start_time = metadata.get("test_start_time")

        if executed_attacks_from_log:
            self.logger.info(
                f"‚úÖ Loaded executed attacks from metadata: {executed_attacks_from_log}"
            )
        else:
            self.logger.debug("‚ö†Ô∏è No metadata found, will use PCAP-based detection")

        if test_start_time:
            self.logger.info(f"‚úÖ Using test_start_time for filtering: {test_start_time}")

        # Task 8.2: Handle PCAP file not found ‚Üí INCONCLUSIVE verdict
        if not Path(pcap_file).exists():
            error_msg = f"PCAP file not found: {pcap_file}"
            self.logger.error(f"‚ùå {error_msg}")
            errors.append(error_msg)
            return PCAPAnalysisResult(
                pcap_file=pcap_file,
                packet_count=0,
                detected_attacks=[],
                executed_attacks_from_log=executed_attacks_from_log,
                parameters={},
                split_positions=[],
                fake_packets_detected=0,
                sni_values=[],
                analysis_time=time.time() - start_time,
                analyzer_version="1.0",
                errors=errors,
                warnings=warnings,
            )

        try:
            # Use existing analysis method with timestamp filtering
            # Pass test_start_time directly (not from metadata)
            strategy_result = self.analyze_strategy_application(
                pcap_file, test_start_time=test_start_time, strategy_name=strategy_name
            )

            # Task 8.2: Handle empty PCAP ‚Üí INCONCLUSIVE verdict
            if strategy_result.packet_count == 0:
                warning_msg = "Empty PCAP file: no packets found"
                self.logger.warning(f"‚ö†Ô∏è {warning_msg}")
                warnings.append(warning_msg)

            # Convert to PCAPAnalysisResult
            result = PCAPAnalysisResult(
                pcap_file=pcap_file,
                packet_count=strategy_result.packet_count,
                detected_attacks=strategy_result.detected_attacks,
                executed_attacks_from_log=executed_attacks_from_log,
                strategy_type=strategy_result.strategy_type,
                combo_attacks=strategy_result.combo_attacks,
                parameters=strategy_result.parameters,
                split_positions=strategy_result.split_positions,
                fake_packets_detected=strategy_result.fake_packets_detected,
                sni_values=strategy_result.sni_values,
                analysis_time=time.time() - start_time,
                analyzer_version="1.0",
                errors=errors,
                warnings=warnings + strategy_result.anomalies,
            )

            return result

        except Exception as e:
            # Task 8.2: Handle PCAP file corrupted ‚Üí INCONCLUSIVE verdict
            error_msg = f"PCAP file corrupted or unreadable: {e}"
            self.logger.error(f"‚ùå {error_msg}", exc_info=True)
            errors.append(error_msg)
            return PCAPAnalysisResult(
                pcap_file=pcap_file,
                packet_count=0,
                detected_attacks=[],
                executed_attacks_from_log=executed_attacks_from_log,
                parameters={},
                split_positions=[],
                fake_packets_detected=0,
                sni_values=[],
                analysis_time=time.time() - start_time,
                analyzer_version="1.0",
                errors=errors,
                warnings=warnings,
            )

    # ------------------------------------------------------------------ #
    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    # ------------------------------------------------------------------ #

    def analyze_strategy_application(
        self,
        pcap_file: str,
        expected_strategy: Optional[Dict[str, Any]] = None,
        test_start_time: Optional[float] = None,
        strategy_name: Optional[str] = None,
    ) -> StrategyAnalysisResult:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ PCAP.

        Args:
            pcap_file: –ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É
            expected_strategy: –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            test_start_time: Timestamp –Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–∞–∫–µ—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            strategy_name: –ò–º—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            StrategyAnalysisResult —Å –¥–µ—Ç–∞–ª—è–º–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è

        Requirements: 8.4, 8.5
        """
        self.logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ {pcap_file}")

        # Use provided test_start_time if available, otherwise try to load from metadata
        if test_start_time is None:
            from core.pcap.metadata_saver import load_pcap_metadata

            metadata = load_pcap_metadata(pcap_file, strategy_name)
            if metadata:
                test_start_time = metadata.get("test_start_time")

        if test_start_time:
            self.logger.info(f"‚úÖ Using test_start_time for packet filtering: {test_start_time}")

        # Check cache (include test_start_time in cache key for unique caching per test)
        cache_key = self._get_cache_key(pcap_file, test_start_time, strategy_name)
        if cache_key in self.analysis_cache:
            self.logger.debug("üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            return self.analysis_cache[cache_key]

        try:
            # Read PCAP file using RawPCAPReader
            packets = self._read_pcap(pcap_file)
            if not packets:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –ø–∞–∫–µ—Ç–æ–≤ –≤ {pcap_file}")
                return StrategyAnalysisResult(strategy_detected=False, packet_count=0)

            # Use Flow-Based Isolation instead of unreliable timestamp filtering
            # This is more robust and avoids analyzing packets from other tests
            total_packets = len(packets)
            target_packets = self._extract_best_flow(packets, test_start_time)

            if not target_packets:
                self.logger.warning(
                    f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π TLS –ø–æ—Ç–æ–∫ —Å—Ä–µ–¥–∏ {total_packets} –ø–∞–∫–µ—Ç–æ–≤"
                )
                return StrategyAnalysisResult(strategy_detected=False, packet_count=0)

            self.logger.info(
                f"‚úÖ –í—ã–¥–µ–ª–µ–Ω —Ü–µ–ª–µ–≤–æ–π –ø–æ—Ç–æ–∫: {len(target_packets)} –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ {total_packets}"
            )
            packets = target_packets

            self.logger.info(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(packets)} –ø–∞–∫–µ—Ç–æ–≤")

            # Extract parameters from packets
            split_positions = self.find_split_positions(packets)
            sni_values = self.find_sni_values(packets)
            checksums = self.validate_checksums(packets)

            # Detect fake packets (Task 3.2)
            fake_packets_detected = self._detect_fake_packets(packets, checksums)

            # Detect all attacks present in PCAP (Task 3.1)
            detected_attacks = self._detect_attacks(
                packets, split_positions, fake_packets_detected, checksums
            )

            # Determine combo strategy type –∏ —Å–ø–∏—Å–æ–∫ –∞—Ç–∞–∫-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç
            strategy_type, combo_attacks = self._determine_strategy_type_from_attacks(
                detected_attacks
            )

            # Extract parameters (Task 3.3)
            parameters = self._extract_all_parameters(
                packets, split_positions, sni_values, checksums
            )

            # Find anomalies
            anomalies = self._find_anomalies(packets, checksums)

            result = StrategyAnalysisResult(
                strategy_detected=bool(strategy_type or detected_attacks),
                split_positions=split_positions,
                sni_values=sni_values,
                checksums_valid=checksums,
                packet_count=len(packets),
                anomalies=anomalies,
                strategy_type=strategy_type,
                parameters=parameters,
                detected_attacks=detected_attacks,
                fake_packets_detected=fake_packets_detected,
                combo_attacks=combo_attacks,
            )

            # Cache result
            self.analysis_cache[cache_key] = result

            self.logger.info(
                "‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: strategy=%s, combo=%s, attacks=%s, splits=%d, fake=%d, sni=%d",
                strategy_type,
                combo_attacks,
                detected_attacks,
                len(split_positions),
                fake_packets_detected,
                len(sni_values),
            )

            return result

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}", exc_info=True)
            return StrategyAnalysisResult(strategy_detected=False)

    # ------------------------------------------------------------------ #
    # –ù–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä—ã
    # ------------------------------------------------------------------ #

    def find_split_positions(self, packets: List[RawPacket]) -> List[int]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –ø–æ–∑–∏—Ü–∏–∏ split –≤ –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–∞—Ö.

        IMPROVED: Now analyzes TCP sequence numbers and payload fragmentation,
        focusing only on ClientHello sequence range to avoid counting retransmissions.
        This matches analyze_raw_pcap.py logic.

        Args:
            packets: –°–ø–∏—Å–æ–∫ RawPacket –æ–±—ä–µ–∫—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ–∑–∏—Ü–∏–π split (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∞—á–∞–ª–∞ –ø–æ—Ç–æ–∫–∞)

        Requirements: 8.4, 8.7
        """
        split_positions: List[int] = []

        try:
            from core.packet.raw_packet_engine import IPHeader, TCPHeader

            # Step 1: Find ClientHello packet to get sequence range
            clienthello_seq = None
            clienthello_len = None

            for pkt in packets:
                if pkt.protocol != ProtocolType.TCP or not pkt.payload:
                    continue

                # Check if this is ClientHello
                if self.packet_engine.is_client_hello(pkt.payload):
                    try:
                        ip_header = IPHeader.unpack(pkt.data[:20])
                        ip_header_size = ip_header.ihl * 4
                        tcp_data = pkt.data[ip_header_size:]
                        tcp_header = TCPHeader.unpack(tcp_data)

                        clienthello_seq = tcp_header.seq_num
                        clienthello_len = len(pkt.payload)
                        break
                    except Exception:
                        continue

            if clienthello_seq is None:
                self.logger.debug("‚ö†Ô∏è ClientHello –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ split")
                return []

            # Step 2: Filter for REAL TCP packets in ClientHello sequence range (TTL > 5)
            clienthello_end_seq = clienthello_seq + clienthello_len
            real_packets = []

            for pkt in packets:
                if pkt.protocol != ProtocolType.TCP or not pkt.payload:
                    continue

                try:
                    # Check TTL - skip fake packets
                    ip_header = IPHeader.unpack(pkt.data[:20])
                    if ip_header.ttl <= 5:
                        continue

                    # Extract TCP info
                    ip_header_size = ip_header.ihl * 4
                    tcp_data = pkt.data[ip_header_size:]
                    if len(tcp_data) < 20:
                        continue

                    tcp_header = TCPHeader.unpack(tcp_data)
                    tcp_header_size = tcp_header.data_offset * 4
                    payload_len = len(tcp_data) - tcp_header_size

                    if payload_len == 0:
                        continue

                    # Only include packets in ClientHello sequence range
                    seq = tcp_header.seq_num
                    if seq >= clienthello_seq and seq < clienthello_end_seq:
                        real_packets.append({"seq": seq, "payload_len": payload_len, "pkt": pkt})
                except Exception as e:
                    self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–∞–∫–µ—Ç–∞: {e}")
                    continue

            if not real_packets:
                return []

            # Sort by sequence number
            real_packets.sort(key=lambda x: x["seq"])

            # Calculate split positions based on sequence numbers
            base_seq = real_packets[0]["seq"]

            # Each fragment end is a split position (except the last one)
            for pkt_info in real_packets[:-1]:
                seq = pkt_info["seq"]
                length = pkt_info["payload_len"]
                relative_end = (seq - base_seq) + length
                if relative_end > 0:
                    split_positions.append(relative_end)

            split_positions = sorted(set(split_positions))
            self.logger.debug(
                f"üîç –ù–∞–π–¥–µ–Ω–æ {len(split_positions)} –ø–æ–∑–∏—Ü–∏–π split "
                f"(–∏–∑ {len(real_packets)} —Ä–µ–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ ClientHello range)"
            )

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ split –ø–æ–∑–∏—Ü–∏–π: {e}")

        return split_positions

    def find_sni_values(self, packets: List[RawPacket]) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç SNI –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –ø–∞–∫–µ—Ç–æ–≤.

        Args:
            packets: –°–ø–∏—Å–æ–∫ RawPacket –æ–±—ä–µ–∫—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ SNI –∑–Ω–∞—á–µ–Ω–∏–π

        Requirements: 8.4, 8.7
        """
        sni_values: List[str] = []

        try:
            for pkt in packets:
                if pkt.protocol != ProtocolType.TCP or not pkt.payload:
                    continue

                payload = pkt.payload
                if not self.packet_engine.is_client_hello(payload):
                    continue

                sni = self.packet_engine.extract_tls_sni(payload)
                if sni:
                    sni_values.append(sni)

            # Remove duplicates while preserving order
            seen: Set[str] = set()
            unique_sni: List[str] = []
            for sni in sni_values:
                if sni not in seen:
                    seen.add(sni)
                    unique_sni.append(sni)

            self.logger.debug(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(unique_sni)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SNI –∑–Ω–∞—á–µ–Ω–∏–π")
            return unique_sni

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è SNI: {e}")
            return []

    def validate_checksums(self, packets: List[RawPacket]) -> Dict[str, bool]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç checksums –≤ –ø–∞–∫–µ—Ç–∞—Ö.

        Args:
            packets: –°–ø–∏—Å–æ–∫ RawPacket –æ–±—ä–µ–∫—Ç–æ–≤

        Returns:
            –°–ª–æ–≤–∞—Ä—å {packet_id: is_valid}

        Requirements: 8.4, 8.7
        """
        checksums: Dict[str, bool] = {}

        try:
            from core.packet.raw_packet_engine import IPHeader, TCPHeader

            for i, pkt in enumerate(packets):
                packet_id = f"packet_{i}"

                if pkt.protocol != ProtocolType.TCP:
                    continue

                try:
                    ip_header = IPHeader.unpack(pkt.data[:20])
                    ip_header_size = ip_header.ihl * 4

                    tcp_data = pkt.data[ip_header_size:]
                    if len(tcp_data) < 20:
                        checksums[packet_id] = False
                        continue

                    tcp_header = TCPHeader.unpack(tcp_data)
                    original_checksum = tcp_header.checksum

                    tcp_header_size = tcp_header.data_offset * 4
                    tcp_payload = (
                        tcp_data[tcp_header_size:] if len(tcp_data) > tcp_header_size else b""
                    )

                    tcp_header.checksum = 0
                    calculated_checksum = tcp_header.calculate_checksum(
                        pkt.src_ip,
                        pkt.dst_ip,
                        tcp_payload,
                    )

                    is_valid = original_checksum == calculated_checksum
                    checksums[packet_id] = is_valid

                except Exception as e:
                    self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ checksum –¥–ª—è –ø–∞–∫–µ—Ç–∞ {i}: {e}")
                    checksums[packet_id] = False

            valid_count = sum(1 for v in checksums.values() if v)
            self.logger.debug(f"üîç –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ {len(checksums)} checksums, –≤–∞–ª–∏–¥–Ω—ã—Ö: {valid_count}")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ checksums: {e}")

        return checksums

    # ------------------------------------------------------------------ #
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –æ–∂–∏–¥–∞–µ–º–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π / –¥—Ä—É–≥–∏–º–∏ PCAP
    # ------------------------------------------------------------------ #

    def compare_with_expected(
        self,
        pcap_file: str,
        expected_strategy: Dict[str, Any],
    ) -> ComparisonResult:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç PCAP —Å –æ–∂–∏–¥–∞–µ–º–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π.

        Args:
            pcap_file: –ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É
            expected_strategy: –û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è

        Returns:
            ComparisonResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Requirements: 8.5, 8.6
        """
        self.logger.info("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ PCAP —Å –æ–∂–∏–¥–∞–µ–º–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π")

        analysis = self.analyze_strategy_application(pcap_file, expected_strategy)

        differences: List[Dict[str, Any]] = []

        # Compare strategy type
        expected_type = expected_strategy.get("attack", expected_strategy.get("type"))
        if expected_type and analysis.strategy_type != expected_type:
            differences.append(
                {
                    "type": "strategy_type",
                    "description": f"Expected {expected_type}, found {analysis.strategy_type}",
                    "expected": expected_type,
                    "actual": analysis.strategy_type,
                }
            )

        # Compare split positions
        expected_split = expected_strategy.get("params", {}).get("split_pos")
        if expected_split:
            if isinstance(expected_split, str) and expected_split.isdigit():
                expected_split = int(expected_split)
            if expected_split not in analysis.split_positions:
                differences.append(
                    {
                        "type": "split_position",
                        "description": (
                            f"Expected split at {expected_split}, "
                            f"found {analysis.split_positions}"
                        ),
                        "expected": expected_split,
                        "actual": analysis.split_positions,
                    }
                )

        # Compare SNI
        expected_sni = expected_strategy.get("params", {}).get("sni")
        if expected_sni and expected_sni not in analysis.sni_values:
            differences.append(
                {
                    "type": "sni_value",
                    "description": (f"Expected SNI '{expected_sni}', found {analysis.sni_values}"),
                    "expected": expected_sni,
                    "actual": analysis.sni_values,
                }
            )

        # Compare attacks list (–¥–ª—è combo-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π)
        expected_attacks = expected_strategy.get("attacks")
        if expected_attacks:
            if set(expected_attacks) != set(analysis.combo_attacks or analysis.detected_attacks):
                differences.append(
                    {
                        "type": "attack_combination",
                        "description": (
                            f"Expected attacks {expected_attacks}, "
                            f"found {analysis.combo_attacks or analysis.detected_attacks}"
                        ),
                        "expected": expected_attacks,
                        "actual": analysis.combo_attacks or analysis.detected_attacks,
                    }
                )

        similarity_score = self._calculate_similarity(analysis, expected_strategy)

        result = ComparisonResult(
            testing_pcap=pcap_file,
            service_pcap="",
            differences=differences,
            similarity_score=similarity_score,
            testing_analysis=analysis,
        )

        self.logger.info(
            "‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: %d —Ä–∞–∑–ª–∏—á–∏–π, similarity=%.2f%%",
            len(differences),
            similarity_score * 100.0,
        )

        return result

    def compare_pcaps(self, testing_pcap: str, service_pcap: str) -> ComparisonResult:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–≤–∞ PCAP —Ñ–∞–π–ª–∞ (testing vs service mode).

        Args:
            testing_pcap: PCAP –∏–∑ testing mode
            service_pcap: PCAP –∏–∑ service mode

        Returns:
            ComparisonResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

        Requirements: 8.5, 8.6
        """
        self.logger.info("üîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ PCAP —Ñ–∞–π–ª–æ–≤: testing vs service")

        testing_analysis = self.analyze_strategy_application(testing_pcap)
        service_analysis = self.analyze_strategy_application(service_pcap)

        differences: List[Dict[str, Any]] = []

        # Compare strategy types
        if testing_analysis.strategy_type != service_analysis.strategy_type:
            differences.append(
                {
                    "type": "strategy_type",
                    "description": (
                        f"Testing: {testing_analysis.strategy_type}, "
                        f"Service: {service_analysis.strategy_type}"
                    ),
                    "testing": testing_analysis.strategy_type,
                    "service": service_analysis.strategy_type,
                }
            )

        # Compare split positions
        if set(testing_analysis.split_positions) != set(service_analysis.split_positions):
            differences.append(
                {
                    "type": "split_positions",
                    "description": (
                        f"Testing: {testing_analysis.split_positions}, "
                        f"Service: {service_analysis.split_positions}"
                    ),
                    "testing": testing_analysis.split_positions,
                    "service": service_analysis.split_positions,
                }
            )

        # Compare SNI values
        if set(testing_analysis.sni_values) != set(service_analysis.sni_values):
            differences.append(
                {
                    "type": "sni_values",
                    "description": (
                        f"Testing: {testing_analysis.sni_values}, "
                        f"Service: {service_analysis.sni_values}"
                    ),
                    "testing": testing_analysis.sni_values,
                    "service": service_analysis.sni_values,
                }
            )

        # Compare packet counts (—Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 5 –ø–∞–∫–µ—Ç–æ–≤)
        if abs(testing_analysis.packet_count - service_analysis.packet_count) > 5:
            differences.append(
                {
                    "type": "packet_count",
                    "description": (
                        f"Testing: {testing_analysis.packet_count}, "
                        f"Service: {service_analysis.packet_count}"
                    ),
                    "testing": testing_analysis.packet_count,
                    "service": service_analysis.packet_count,
                }
            )

        similarity_score = self._calculate_pcap_similarity(testing_analysis, service_analysis)

        result = ComparisonResult(
            testing_pcap=testing_pcap,
            service_pcap=service_pcap,
            differences=differences,
            similarity_score=similarity_score,
            testing_analysis=testing_analysis,
            service_analysis=service_analysis,
        )

        self.logger.info(
            "‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: %d —Ä–∞–∑–ª–∏—á–∏–π, similarity=%.2f%%",
            len(differences),
            similarity_score * 100.0,
        )

        return result

    # ------------------------------------------------------------------ #
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã —á—Ç–µ–Ω–∏—è –∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä—ã –∞—Ç–∞–∫
    # ------------------------------------------------------------------ #

    def _read_pcap(self, pcap_file: str) -> List[RawPacket]:
        """–ß–∏—Ç–∞–µ—Ç PCAP —Ñ–∞–π–ª –∏—Å–ø–æ–ª—å–∑—É—è RawPCAPReader."""
        try:
            if not Path(pcap_file).exists():
                self.logger.warning(f"‚ö†Ô∏è PCAP —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pcap_file}")
                return []

            packets = self.pcap_reader.read_pcap_file(pcap_file)
            return packets

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PCAP: {e}")
            return []

    def _extract_best_flow(
        self, packets: List[RawPacket], test_start_time: Optional[float] = None
    ) -> List[RawPacket]:
        """
        –í—ã–¥–µ–ª—è–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ü–µ–ª–µ–≤–æ–π –ø–æ—Ç–æ–∫ (TCP Flow) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

        –õ–æ–≥–∏–∫–∞:
        1. –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–∞–∫–µ—Ç—ã –ø–æ 4-tuple (src_ip, src_port, dst_ip, dst_port)
        2. –ò—â–µ—Ç –ø–æ—Ç–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ ClientHello
        3. –ï—Å–ª–∏ –µ—Å—Ç—å test_start_time, –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ—Ç–æ–∫, –±–ª–∏–∂–∞–π—à–∏–π –∫ —ç—Ç–æ–º—É –≤—Ä–µ–º–µ–Ω–∏
        4. –ï—Å–ª–∏ –Ω–µ—Ç, –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ—Ç–æ–∫ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–±—Ö–æ–¥–∞ (—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è)

        Args:
            packets: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ PCAP
            test_start_time: Unix timestamp –Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ —Ü–µ–ª–µ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞
        """
        from collections import defaultdict

        flows = defaultdict(list)

        # 1. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ TCP flow
        for pkt in packets:
            if pkt.protocol != ProtocolType.TCP:
                continue

            # –ö–ª—é—á –ø–æ—Ç–æ–∫–∞: (src_ip, src_port, dst_ip, dst_port)
            key = (pkt.src_ip, pkt.src_port, pkt.dst_ip, pkt.dst_port)
            flows[key].append(pkt)

        # 2. –û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–æ–∫–æ–≤
        candidates = []

        for key, flow_packets in flows.items():
            has_client_hello = False
            fragment_count = 0
            first_timestamp = (
                flow_packets[0].timestamp
                if hasattr(flow_packets[0], "timestamp") and flow_packets[0].timestamp
                else 0
            )

            for pkt in flow_packets:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ ClientHello
                if pkt.payload and self.packet_engine.is_client_hello(pkt.payload):
                    has_client_hello = True

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é (–º–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞–∫–µ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏)
                if pkt.payload and len(pkt.payload) < 100:
                    fragment_count += 1

            # ClientHello - –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û–ï —É—Å–ª–æ–≤–∏–µ –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
            if not has_client_hello:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏ –±–µ–∑ ClientHello

            # –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤ —Å ClientHello)
            score = 100  # –ë–∞–∑–æ–≤—ã–π score –∑–∞ –Ω–∞–ª–∏—á–∏–µ ClientHello
            score += fragment_count * 10  # –§—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è - –ø—Ä–∏–∑–Ω–∞–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω–æ), –Ω–æ –º—è–≥–∫–∞—è
            time_diff = float("inf")
            if test_start_time and first_timestamp:
                time_diff = abs(first_timestamp - test_start_time)
                # –ï—Å–ª–∏ –ø–æ—Ç–æ–∫ –Ω–∞—á–∞–ª—Å—è —Å–∏–ª—å–Ω–æ —Ä–∞–Ω—å—à–µ —Ç–µ—Å—Ç–∞ (>10 —Å–µ–∫) –∏–ª–∏ —Å–∏–ª—å–Ω–æ –ø–æ–∑–∂–µ, —à—Ç—Ä–∞—Ñ—É–µ–º
                if time_diff > 10.0:
                    score -= 500

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Ç–æ–∫–∏ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º score
            if score > 0:
                candidates.append(
                    {"key": key, "packets": flow_packets, "score": score, "time_diff": time_diff}
                )

        if not candidates:
            return []

        # 3. –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ –ø–æ score (ClientHello + —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è), –ø–æ—Ç–æ–º –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ –≤—Ä–µ–º–µ–Ω–∏
        candidates.sort(key=lambda x: (-x["score"], x["time_diff"]))

        best_flow = candidates[0]
        self.logger.debug(
            f"üåä –í—ã–±—Ä–∞–Ω –ª—É—á—à–∏–π –ø–æ—Ç–æ–∫: {best_flow['key'][0]}:{best_flow['key'][1]} -> "
            f"{best_flow['key'][2]}:{best_flow['key'][3]} "
            f"(Score: {best_flow['score']}, TimeDiff: {best_flow['time_diff']:.3f}s)"
        )

        return best_flow["packets"]

    def _filter_packets_by_timestamp(
        self, packets: List[RawPacket], test_start_time: float, time_window: float = 5.0
    ) -> List[RawPacket]:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–∞–∫–µ—Ç—ã –ø–æ timestamp –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –ø–∞–∫–µ—Ç–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞.

        –ö–æ–≥–¥–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤ –ø–∏—à—É—Ç –≤ –æ–¥–∏–Ω PCAP —Ñ–∞–π–ª, –Ω—É–∂–Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å
        –ø–∞–∫–µ—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏.

        –í–ê–ñ–ù–û: –û–∫–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–æ –Ω–∞–∑–∞–¥ –Ω–∞ 5 —Å–µ–∫—É–Ω–¥, —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å –ø–∞–∫–µ—Ç—ã,
        –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–µ –≤–æ –≤—Ä–µ–º—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PCAP –¥–æ –Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∞.

        Args:
            packets: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ PCAP
            test_start_time: Unix timestamp –Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∞ (–∏–∑ metadata)
            time_window: –í—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5 —Å–µ–∫—É–Ω–¥)

        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
        """
        filtered_packets = []

        try:
            # Define time range for this test
            # Expand window backwards to include packets captured during PCAP initialization
            time_window_before = 5.0  # 5 seconds before test start
            time_window_after = 10.0  # 10 seconds after test start

            test_window_start = test_start_time - time_window_before
            test_window_end = test_start_time + time_window_after

            self.logger.debug(
                f"üîç –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–∞–∫–µ—Ç–æ–≤: test_start={test_start_time}, window=[{test_window_start:.3f}, {test_window_end:.3f}]"
            )

            for pkt in packets:
                # Check if packet has timestamp
                if not hasattr(pkt, "timestamp") or pkt.timestamp is None:
                    # If no timestamp, include packet (fallback behavior)
                    filtered_packets.append(pkt)
                    continue

                # Filter by timestamp range (expanded window)
                if test_window_start <= pkt.timestamp <= test_window_end:
                    filtered_packets.append(pkt)

            self.logger.info(
                f"‚úÖ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_packets)}/{len(packets)} –ø–∞–∫–µ—Ç–æ–≤ –≤ –æ–∫–Ω–µ [{test_window_start:.3f}, {test_window_end:.3f}]"
            )

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ timestamp: {e}")
            # Fallback: return all packets if filtering fails
            return packets

        return filtered_packets

    def _detect_fake_packets(
        self,
        packets: List[RawPacket],
        checksums: Dict[str, bool],
    ) -> int:
        """
        Detects fake packets in PCAP.

        Task 3.2: Detect packets with is_fake flag or bad checksums

        Returns:
            Count of fake packets detected

        Requirements: 2.4
        """
        fake_count = 0

        try:
            from core.packet.raw_packet_engine import IPHeader

            for i, pkt in enumerate(packets):
                packet_id = f"packet_{i}"

                # Explicit is_fake flag
                if hasattr(pkt, "is_fake") and getattr(pkt, "is_fake"):
                    fake_count += 1
                    continue

                # Bad checksum
                if packet_id in checksums and not checksums[packet_id]:
                    fake_count += 1
                    continue

                # Heuristic: very low TTL in TCP packets
                if pkt.protocol == ProtocolType.TCP:
                    try:
                        ip_header = IPHeader.unpack(pkt.data[:20])
                        if ip_header.ttl <= 3:
                            fake_count += 1
                    except Exception:
                        pass

            self.logger.debug(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {fake_count} —Ñ–µ–π–∫–æ–≤—ã—Ö –ø–∞–∫–µ—Ç–æ–≤")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ñ–µ–π–∫–æ–≤—ã—Ö –ø–∞–∫–µ—Ç–æ–≤: {e}")

        return fake_count

    def _detect_attacks(
        self,
        packets: List[RawPacket],
        split_positions: List[int],
        fake_packets: int,
        checksums: Dict[str, bool],
    ) -> List[str]:
        """
        Detects all component attacks in PCAP.

        Task 3.1: Detect all component attacks in combo strategies

        Returns:
            List of detected base attack names (e.g., ['split', 'fake'])

        Requirements: 2.1, 7.4
        """
        detected: List[str] = []

        try:
            # Detect split vs multisplit
            if split_positions:
                if len(split_positions) > 1:
                    detected.append("multisplit")
                else:
                    detected.append("split")

            # Detect fake attack
            if fake_packets > 0:
                detected.append("fake")

            # Detect disorder (packets out of order)
            if self._detect_disorder(packets):
                detected.append("disorder")

            # Detect seqovl (sequence overlap)
            if self._detect_sequence_overlap(packets):
                detected.append("seqovl")

            # Detect TTL manipulation
            if self._detect_ttl_manipulation(packets):
                if "ttl_manipulation" not in detected:
                    detected.append("ttl_manipulation")

            # Detect fooling methods (badsum, badseq, etc.)
            fooling_methods = self._detect_fooling_methods(packets, checksums)
            for method in fooling_methods:
                if method not in detected:
                    detected.append(method)

            self.logger.debug(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –±–∞–∑–æ–≤—ã–µ –∞—Ç–∞–∫–∏: {detected}")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞—Ç–∞–∫: {e}")

        return detected

    def _detect_disorder(self, packets: List[RawPacket]) -> bool:
        """
        Detects if packets are sent out of order (disorder attack).

        Disorder attack patterns:
        1. Non-monotonic sequence numbers for REAL packets (not fake)
        2. Reverse order pattern: larger segment sent before smaller segment

        IMPORTANT: This method now filters out fake packets to avoid false positives.
        Fake packets (low TTL, bad checksum) are expected to have same seq as real packets,
        which would otherwise trigger false disorder detection.
        """
        try:
            from core.packet.raw_packet_engine import IPHeader, TCPHeader

            tcp_packets = [p for p in packets if p.protocol == ProtocolType.TCP and p.payload]
            if len(tcp_packets) < 2:
                return False

            # Filter out fake packets (low TTL or bad checksum) to avoid false positives
            real_packets_data: List[Tuple[int, int, int, int]] = (
                []
            )  # (seq_num, packet_idx, payload_size, ttl)
            for idx, pkt in enumerate(tcp_packets):
                try:
                    ip_header = IPHeader.unpack(pkt.data[:20])
                    ip_header_size = ip_header.ihl * 4
                    tcp_data = pkt.data[ip_header_size:]
                    if len(tcp_data) >= 20:
                        tcp_header = TCPHeader.unpack(tcp_data)
                        tcp_header_size = tcp_header.data_offset * 4
                        payload_size = len(tcp_data) - tcp_header_size

                        # Skip fake packets (TTL <= 5 is typically fake)
                        if ip_header.ttl <= 5:
                            continue

                        if payload_size > 0:
                            real_packets_data.append(
                                (tcp_header.seq_num, idx, payload_size, ip_header.ttl)
                            )
                except Exception:
                    continue

            if len(real_packets_data) < 2:
                return False

            # Group by unique (seq, size) to handle retransmissions
            # Retransmissions have same seq and size, disorder has different sizes
            unique_segments: Dict[int, List[Tuple[int, int, int]]] = {}  # seq -> [(idx, size, ttl)]
            for seq, idx, size, ttl in real_packets_data:
                unique_segments.setdefault(seq, []).append((idx, size, ttl))

            # Check for disorder pattern: same seq but different sizes sent in reverse order
            for seq, entries in unique_segments.items():
                if len(entries) > 1:
                    # Multiple packets with same seq - check if they have different sizes
                    sizes = set(e[1] for e in entries)
                    if len(sizes) > 1:
                        # Different sizes with same seq = disorder (split + reorder)
                        self.logger.debug(
                            f"üîç Disorder detected: seq={seq} has packets with different sizes: {sizes}"
                        )
                        return True

            # Check for reverse order pattern in sequence numbers
            # Only consider packets with different seq numbers
            seq_order = [(seq, idx) for seq, idx, size, ttl in real_packets_data]
            unique_seqs = []
            seen_seqs = set()
            for seq, idx in seq_order:
                if seq not in seen_seqs:
                    unique_seqs.append((seq, idx))
                    seen_seqs.add(seq)

            if len(unique_seqs) >= 2:
                # Check if sequence numbers are in reverse order
                seqs_only = [s[0] for s in unique_seqs]
                if seqs_only == sorted(seqs_only, reverse=True):
                    # All seqs in reverse order = disorder
                    self.logger.debug(
                        f"üîç Disorder detected: sequence numbers in reverse order: {seqs_only}"
                    )
                    return True

                # Check for partial reverse order (first seq > second seq)
                first_seq = unique_seqs[0][0]
                second_seq = unique_seqs[1][0]
                if first_seq > second_seq:
                    self.logger.debug(
                        f"üîç Disorder detected: first seq ({first_seq}) > second seq ({second_seq})"
                    )
                    return True

        except Exception as e:
            self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è disorder: {e}")

        return False

    def _detect_sequence_overlap(self, packets: List[RawPacket]) -> bool:
        """
        Detects sequence overlap attack.

        IMPORTANT: This method now filters out fake packets to avoid false positives.
        Fake packets have the same seq as real packets, which would otherwise
        trigger false seqovl detection.

        True seqovl is when REAL packets have overlapping byte ranges with
        different content (intentional overlap for DPI confusion).
        """
        try:
            from core.packet.raw_packet_engine import IPHeader, TCPHeader

            tcp_packets = [p for p in packets if p.protocol == ProtocolType.TCP]
            if len(tcp_packets) < 2:
                return False

            # Collect seq ranges only for REAL packets (TTL > 5)
            real_seq_ranges: List[Tuple[int, int, int]] = []  # (start, end, ttl)
            for pkt in tcp_packets:
                try:
                    ip_header = IPHeader.unpack(pkt.data[:20])
                    ip_header_size = ip_header.ihl * 4
                    tcp_data = pkt.data[ip_header_size:]
                    if len(tcp_data) >= 20:
                        tcp_header = TCPHeader.unpack(tcp_data)
                        tcp_header_size = tcp_header.data_offset * 4
                        payload_size = len(tcp_data) - tcp_header_size

                        # Skip fake packets (TTL <= 5)
                        if ip_header.ttl <= 5:
                            continue

                        if payload_size > 0:
                            seq_start = tcp_header.seq_num
                            seq_end = seq_start + payload_size
                            real_seq_ranges.append((seq_start, seq_end, ip_header.ttl))
                except Exception:
                    continue

            if len(real_seq_ranges) < 2:
                return False

            # Check for overlapping ranges between REAL packets only
            # Exclude exact duplicates (retransmissions)
            for i in range(len(real_seq_ranges) - 1):
                for j in range(i + 1, len(real_seq_ranges)):
                    start1, end1, ttl1 = real_seq_ranges[i]
                    start2, end2, ttl2 = real_seq_ranges[j]

                    # Skip exact duplicates (retransmissions)
                    if start1 == start2 and end1 == end2:
                        continue

                    # Check for partial overlap (true seqovl)
                    if start1 < end2 and start2 < end1:
                        # Ensure it's not just adjacent segments
                        overlap_size = min(end1, end2) - max(start1, start2)
                        if overlap_size > 0:
                            self.logger.debug(
                                f"üîç Seqovl detected: ranges [{start1}-{end1}] and [{start2}-{end2}] "
                                f"overlap by {overlap_size} bytes"
                            )
                            return True

        except Exception as e:
            self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è seqovl: {e}")

        return False

    def _detect_ttl_manipulation(self, packets: List[RawPacket]) -> bool:
        """Detects TTL manipulation (low TTL values)."""
        try:
            from core.packet.raw_packet_engine import IPHeader

            low_ttl_count = 0
            ttl_observed = 0
            for pkt in packets:
                try:
                    ip_header = IPHeader.unpack(pkt.data[:20])
                    ttl_observed += 1
                    if ip_header.ttl <= 5:
                        low_ttl_count += 1
                except Exception:
                    continue

            if ttl_observed == 0:
                return False

            # If >20% of packets have low TTL ‚Üí likely TTL manipulation
            return low_ttl_count > ttl_observed * 0.2

        except Exception as e:
            self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è TTL manipulation: {e}")

        return False

    def _detect_fooling_methods(
        self,
        packets: List[RawPacket],
        checksums: Dict[str, bool],
    ) -> List[str]:
        """
        Detects fooling methods (badsum, badseq, etc.).

        IMPORTANT: badseq detection now only considers REAL packets (TTL > 5).
        Fake packets intentionally have duplicate seq numbers, which is not badseq.
        True badseq is when real packets have intentionally bad sequence numbers.
        """
        methods: List[str] = []

        try:
            # badsum - detected from checksums validation
            invalid_checksums = sum(1 for v in checksums.values() if not v)
            if invalid_checksums > 0:
                methods.append("badsum")

            # badseq detection - only for REAL packets
            # Fake packets have same seq as real packets by design, that's not badseq
            from core.packet.raw_packet_engine import IPHeader, TCPHeader

            real_seq_numbers: List[int] = []
            for pkt in [p for p in packets if p.protocol == ProtocolType.TCP]:
                try:
                    ip_header = IPHeader.unpack(pkt.data[:20])

                    # Skip fake packets (TTL <= 5)
                    if ip_header.ttl <= 5:
                        continue

                    ip_header_size = ip_header.ihl * 4
                    tcp_data = pkt.data[ip_header_size:]
                    if len(tcp_data) >= 20:
                        tcp_header = TCPHeader.unpack(tcp_data)
                        real_seq_numbers.append(tcp_header.seq_num)
                except Exception:
                    continue

            # badseq is when REAL packets have duplicate seq numbers
            # (not counting retransmissions which are normal)
            # For now, we don't detect badseq as it's hard to distinguish from retransmissions
            # and fake packets already handle the DPI confusion

        except Exception as e:
            self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è fooling methods: {e}")

        return methods

    # ------------------------------------------------------------------ #
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ / TTL / –∫–æ–º–±–æ-–ª–æ–≥–∏–∫–∞
    # ------------------------------------------------------------------ #

    def _extract_all_parameters(
        self,
        packets: List[RawPacket],
        split_positions: List[int],
        sni_values: List[str],
        checksums: Dict[str, bool],
    ) -> Dict[str, Any]:
        """
        Extracts all non-null parameters from PCAP.

        COMBINED APPROACH:
        1. Groups packets by TCP flow (src_ip, src_port, dst_ip, dst_port)
        2. Analyzes each flow separately to find the "best" flow
        3. Extracts parameters from the best flow (most splits = successful strategy)

        This solves the problem of mixing packets from different flows/retries.

        Task 3.3: Extract split_pos, ttl, fooling_modes, etc.
        """
        parameters: Dict[str, Any] = {}

        try:
            # STEP 1: Group packets by TCP flow
            from collections import defaultdict

            flows = defaultdict(list)

            for pkt in packets:
                if pkt.protocol == ProtocolType.TCP:
                    # Create flow key (src -> dst direction)
                    flow_key = (pkt.src_ip, pkt.src_port, pkt.dst_ip, pkt.dst_port)
                    flows[flow_key].append(pkt)

            # STEP 2: Analyze each flow to find the "best" one
            best_flow_key = None
            max_splits = -1
            best_flow_splits = []

            self.logger.debug(f"üåä Found {len(flows)} TCP flows in PCAP")

            for flow_key, flow_packets in flows.items():
                # Calculate split positions for this specific flow
                flow_splits = self.find_split_positions(flow_packets)

                # Heuristic: flow with most splits is likely the successful strategy
                if len(flow_splits) > max_splits:
                    max_splits = len(flow_splits)
                    best_flow_key = flow_key
                    best_flow_splits = flow_splits

                    self.logger.debug(
                        f"üåä Flow {flow_key[0]}:{flow_key[1]} -> {flow_key[2]}:{flow_key[3]} "
                        f"has {len(flow_splits)} splits"
                    )

            # STEP 3: Use parameters from the best flow
            if best_flow_key:
                self.logger.info(
                    f"‚úÖ Selected best flow: {best_flow_key[0]}:{best_flow_key[1]} -> "
                    f"{best_flow_key[2]}:{best_flow_key[3]} with {max_splits} splits"
                )
                split_positions = best_flow_splits

            # split_pos / positions (from best flow)
            if split_positions:
                parameters["split_positions"] = split_positions
                parameters["split_count"] = len(split_positions)

                if len(split_positions) == 1:
                    parameters["split_pos"] = split_positions[0]
                elif len(split_positions) > 1:
                    parameters["split_pos"] = split_positions[0]
                    parameters["positions"] = split_positions

            # TTL values
            ttl_values = self._extract_ttl_values(packets)
            if ttl_values:
                from collections import Counter

                ttl_counter = Counter(ttl_values)
                most_common_ttl = ttl_counter.most_common(1)[0][0]
                parameters["ttl"] = most_common_ttl

                low_ttls = [ttl for ttl in ttl_values if ttl <= 5]
                if low_ttls:
                    parameters["fake_ttl"] = min(low_ttls)

            # fooling modes (badsum, badseq - NOT disorder, which is a separate attack)
            fooling_modes: List[str] = []
            invalid_checksums = sum(1 for v in checksums.values() if not v)
            if invalid_checksums > 0:
                fooling_modes.append("badsum")
            # Note: disorder is NOT a fooling mode, it's a separate attack type
            # Don't add it to fooling_modes
            if fooling_modes:
                parameters["fooling"] = fooling_modes
                parameters["fooling_modes"] = fooling_modes

            # SNI values
            if sni_values:
                parameters["sni_values"] = sni_values
                if len(sni_values) == 1:
                    parameters["sni"] = sni_values[0]

            # Packet count / bytes
            tcp_packets = [p for p in packets if p.protocol == ProtocolType.TCP]
            if tcp_packets:
                parameters["packet_count"] = len(tcp_packets)
                parameters["total_bytes"] = sum(len(p.data) for p in tcp_packets)

            non_null_params = {k: v for k, v in parameters.items() if v is not None}
            self.logger.debug(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(non_null_params)}")
            for key, value in non_null_params.items():
                self.logger.debug(f"  - {key}: {value}")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}")

        return parameters

    def _extract_ttl_values(self, packets: List[RawPacket]) -> List[int]:
        """Extracts TTL values from IP headers."""
        ttl_values: List[int] = []

        try:
            from core.packet.raw_packet_engine import IPHeader

            for pkt in packets:
                try:
                    ip_header = IPHeader.unpack(pkt.data[:20])
                    ttl_values.append(ip_header.ttl)
                except Exception:
                    continue

        except Exception as e:
            self.logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è TTL: {e}")

        return ttl_values

    def _determine_strategy_type_from_attacks(
        self,
        detected_attacks: List[str],
    ) -> Tuple[Optional[str], List[str]]:
        """
        Determines strategy type and combo attack list from detected attacks.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            (strategy_type, combo_attacks)

        strategy_type –º–æ–∂–µ—Ç –±—ã—Ç—å:
        - –æ–¥–∏–Ω–æ—á–Ω–æ–π –∞—Ç–∞–∫–æ–π: "fake", "multisplit", ...
        - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π: "fakeddisorder" (fake+disorder –±–µ–∑ split),
        - combo-—Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π: "smart_combo_fake_multisplit_disorder", –∏ —Ç.–ø.

        Edge case handling (Task 4.1, Requirements 7.1, 7.2):
        - Empty detected_attacks list ‚Üí return (None, [])
        - None detected_attacks ‚Üí return (None, [])
        - Only fooling attacks ‚Üí return (first_attack, [])
        """
        # Task 4.1: Handle None detected_attacks ‚Üí return (None, [])
        if detected_attacks is None:
            self.logger.warning("‚ö†Ô∏è Edge case: detected_attacks is None, returning (None, [])")
            return None, []

        # Task 4.1: Handle empty detected_attacks list ‚Üí return (None, [])
        if not detected_attacks:
            self.logger.debug("‚ö†Ô∏è Edge case: empty detected_attacks list, returning (None, [])")
            return None, []

        # –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º fooling/low-level —Ç–µ–≥–∏
        main_attacks = [a for a in detected_attacks if a not in FOOLING_LABELS]

        # Task 4.1: Handle only fooling attacks ‚Üí return (first_attack, [])
        if not main_attacks:
            # —Ç–æ–ª—å–∫–æ fooling-–º–µ—Ç–æ–¥—ã ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –∏–∑ –ø–æ–ª–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
            self.logger.warning(
                f"‚ö†Ô∏è Edge case: only fooling attacks detected {detected_attacks}, "
                f"returning ({detected_attacks[0]}, [])"
            )
            return detected_attacks[0], []

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
        unique_main: List[str] = []
        for a in main_attacks:
            if a not in unique_main:
                unique_main.append(a)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–º–µ–Ω–∏)
        ordered = sorted(
            unique_main,
            key=lambda x: CORE_ATTACKS_ORDER.get(x, 99),
        )

        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Å–ª—É—á–∞–π: fake + disorder ‚Üí fakeddisorder
        if set(ordered) == {"fake", "disorder"}:
            return "fakeddisorder", ordered

        # –û–±—â–∏–π —Å–ª—É—á–∞–π combo: –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∞—Ç–∞–∫
        if len(ordered) > 1:
            combo_name = "smart_combo_" + "_".join(ordered)
            return combo_name, ordered

        # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –æ—Å–Ω–æ–≤–Ω–∞—è –∞—Ç–∞–∫–∞
        return ordered[0], ordered

    # legacy helper (–º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    def _determine_strategy_type(
        self,
        packets: List[RawPacket],
        split_positions: List[int],
        sni_values: List[str],
    ) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ –ø–∞–∫–µ—Ç–∞–º (legacy, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)."""
        try:
            if split_positions:
                return "multisplit" if len(split_positions) > 1 else "split"
            if sni_values and len(set(sni_values)) > 1:
                return "sni_change"
            tcp_packets = [p for p in packets if p.protocol == ProtocolType.TCP]
            tcp_with_payload = [p for p in packets if p.protocol == ProtocolType.TCP and p.payload]
            if len(tcp_packets) > len(tcp_with_payload):
                return "fake"
            return None
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {e}")
            return None

    # ------------------------------------------------------------------ #
    # –ê–Ω–æ–º–∞–ª–∏–∏ –∏ similarity
    # ------------------------------------------------------------------ #

    def _find_anomalies(
        self,
        packets: List[RawPacket],
        checksums: Dict[str, bool],
    ) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –ø–∞–∫–µ—Ç–∞—Ö."""
        anomalies: List[str] = []

        try:
            from core.packet.raw_packet_engine import TCPHeader, IPHeader

            invalid_checksums = [k for k, v in checksums.items() if not v]
            if invalid_checksums:
                anomalies.append(f"Invalid checksums in {len(invalid_checksums)} packets")

            # –î—É–±–ª–∏–∫–∞—Ç—ã –ø–∞–∫–µ—Ç–æ–≤
            packet_hashes: Set[int] = set()
            duplicates = 0
            for pkt in packets:
                h = hash(pkt.data)
                if h in packet_hashes:
                    duplicates += 1
                packet_hashes.add(h)
            if duplicates > 0:
                anomalies.append(f"Found {duplicates} duplicate packets")

            # Out-of-order
            tcp_packets = [p for p in packets if p.protocol == ProtocolType.TCP]
            if len(tcp_packets) > 1:
                seq_numbers: List[int] = []
                for pkt in tcp_packets:
                    try:
                        ip_header = IPHeader.unpack(pkt.data[:20])
                        ip_header_size = ip_header.ihl * 4
                        tcp_data = pkt.data[ip_header_size:]
                        if len(tcp_data) >= 20:
                            tcp_header = TCPHeader.unpack(tcp_data)
                            seq_numbers.append(tcp_header.seq_num)
                    except Exception:
                        continue
                if seq_numbers and seq_numbers != sorted(seq_numbers):
                    anomalies.append("Out-of-order TCP packets detected")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π: {e}")

        return anomalies

    def _calculate_similarity(
        self,
        analysis: StrategyAnalysisResult,
        expected: Dict[str, Any],
    ) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç similarity score –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–æ–º –∏ –æ–∂–∏–¥–∞–µ–º–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π."""
        score = 0.0
        checks = 0

        # Strategy type
        expected_type = expected.get("attack", expected.get("type"))
        if expected_type:
            checks += 1
            if analysis.strategy_type == expected_type:
                score += 1.0

        # split_pos
        expected_split = expected.get("params", {}).get("split_pos")
        if expected_split:
            checks += 1
            if isinstance(expected_split, str) and expected_split.isdigit():
                expected_split = int(expected_split)
            if expected_split in analysis.split_positions:
                score += 1.0

        # SNI
        expected_sni = expected.get("params", {}).get("sni")
        if expected_sni:
            checks += 1
            if expected_sni in analysis.sni_values:
                score += 1.0

        # attacks combo
        expected_attacks = expected.get("attacks")
        if expected_attacks:
            checks += 1
            if set(expected_attacks) == set(analysis.combo_attacks or analysis.detected_attacks):
                score += 1.0

        return score / checks if checks > 0 else 0.0

    def _calculate_pcap_similarity(
        self,
        testing: StrategyAnalysisResult,
        service: StrategyAnalysisResult,
    ) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç similarity score –º–µ–∂–¥—É –¥–≤—É–º—è PCAP –∞–Ω–∞–ª–∏–∑–∞–º–∏."""
        score = 0.0
        checks = 0

        # strategy_type
        checks += 1
        if testing.strategy_type == service.strategy_type:
            score += 1.0

        # split_positions
        if testing.split_positions or service.split_positions:
            checks += 1
            if set(testing.split_positions) == set(service.split_positions):
                score += 1.0

        # sni_values
        if testing.sni_values or service.sni_values:
            checks += 1
            if set(testing.sni_values) == set(service.sni_values):
                score += 1.0

        # packet_count (10% tolerance)
        if testing.packet_count > 0 and service.packet_count > 0:
            checks += 1
            ratio = min(testing.packet_count, service.packet_count) / max(
                testing.packet_count, service.packet_count
            )
            if ratio >= 0.9:
                score += 1.0

        return score / checks if checks > 0 else 0.0

    def _get_cache_key(
        self,
        pcap_file: str,
        test_start_time: Optional[float] = None,
        strategy_name: Optional[str] = None,
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è PCAP —Ñ–∞–π–ª–∞.

        Args:
            pcap_file: –ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É
            test_start_time: Timestamp –Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∞ (–¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ –Ω–∞ —Ç–µ—Å—Ç)
            strategy_name: –ò–º—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é)

        Returns:
            MD5 —Ö—ç—à –∫–ª—é—á–∞ –∫—ç—à–∞
        """
        import hashlib

        file_path = Path(pcap_file)
        file_stat = file_path.stat() if file_path.exists() else None
        key_data = f"{pcap_file}:{file_stat.st_mtime if file_stat else 0}:{test_start_time}:{strategy_name}"
        return hashlib.md5(key_data.encode()).hexdigest()

    def clear_cache(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à –∞–Ω–∞–ª–∏–∑–∞."""
        self.analysis_cache.clear()
        self.logger.info("üßπ –ö—ç—à –∞–Ω–∞–ª–∏–∑–∞ –æ—á–∏—â–µ–Ω")

    def load_operation_log(self, strategy_id: str) -> Optional[List[Dict[str, Any]]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç operation log –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ strategy_id.

        Args:
            strategy_id: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–ø–µ—Ä–∞—Ü–∏–π (—Å–µ–≥–º–µ–Ω—Ç–æ–≤) –∏–ª–∏ None –µ—Å–ª–∏ –ª–æ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            from core.operation_logger import get_operation_logger

            operation_logger = get_operation_logger()

            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            log_dir = Path("data/operation_logs")
            log_file = log_dir / f"{strategy_id}.json"

            if not log_file.exists():
                self.logger.warning(f"‚ö†Ô∏è Operation log not found: {log_file}")
                return None

            # –ß–∏—Ç–∞–µ–º JSON —Ñ–∞–π–ª
            import json

            with open(log_file, "r", encoding="utf-8") as f:
                log_data = json.load(f)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ —Ç–∏–ø–∞ "segment"
            operations = log_data.get("operations", [])
            segments = [op for op in operations if op.get("operation_type") == "segment"]

            self.logger.info(f"‚úÖ Loaded {len(segments)} segment operations from {log_file}")
            return segments

        except ImportError:
            self.logger.warning("‚ö†Ô∏è operation_logger not available")
            return None
        except Exception as e:
            self.logger.error(f"‚ùå Failed to load operation log: {e}", exc_info=True)
            return None

    def compare_pcap_with_operation_log(
        self,
        pcap_file: str,
        strategy_id: str,
    ) -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç PCAP —Å operation log –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤.

        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (PCAP vs log)
        - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å FAKE/REAL
        - TTL –∑–Ω–∞—á–µ–Ω–∏—è
        - Flags –∑–Ω–∞—á–µ–Ω–∏—è
        - Seq/Ack –Ω–æ–º–µ—Ä–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)

        Args:
            pcap_file: –ü—É—Ç—å –∫ PCAP —Ñ–∞–π–ª—É
            strategy_id: ID —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ operation log

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
            {
                "match": bool,  # –ü–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                "pcap_segments": int,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ PCAP
                "log_segments": int,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –ª–æ–≥–µ
                "differences": List[str],  # –°–ø–∏—Å–æ–∫ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π
                "details": Dict[str, Any]  # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            }
        """
        result = {
            "match": False,
            "pcap_segments": 0,
            "log_segments": 0,
            "differences": [],
            "details": {},
        }

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º operation log
            log_segments = self.load_operation_log(strategy_id)
            if log_segments is None:
                result["differences"].append("Operation log not found or empty")
                return result

            result["log_segments"] = len(log_segments)

            # –ß–∏—Ç–∞–µ–º PCAP
            if not Path(pcap_file).exists():
                result["differences"].append(f"PCAP file not found: {pcap_file}")
                return result

            packets = self.pcap_reader.read_pcap(pcap_file)
            if not packets:
                result["differences"].append("PCAP file is empty")
                return result

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ TCP –ø–∞–∫–µ—Ç—ã —Å payload (–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã)
            tcp_segments = []
            for pkt_data, timestamp in packets:
                parsed = self.packet_engine.parse_packet(pkt_data)
                if parsed and parsed.protocol == ProtocolType.TCP and parsed.payload:
                    tcp_segments.append(parsed)

            result["pcap_segments"] = len(tcp_segments)

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            if len(tcp_segments) != len(log_segments):
                result["differences"].append(
                    f"Segment count mismatch: PCAP={len(tcp_segments)}, Log={len(log_segments)}"
                )

            # –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            mismatches = []
            for i in range(min(len(tcp_segments), len(log_segments))):
                pcap_seg = tcp_segments[i]
                log_seg = log_segments[i]

                seg_diff = []

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
                log_ttl = log_seg.get("parameters", {}).get("ttl")
                if log_ttl is not None and pcap_seg.ttl != log_ttl:
                    seg_diff.append(f"TTL: PCAP={pcap_seg.ttl}, Log={log_ttl}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º flags
                log_flags = log_seg.get("parameters", {}).get("flags")
                if log_flags is not None and pcap_seg.tcp_flags != log_flags:
                    seg_diff.append(
                        f"Flags: PCAP=0x{pcap_seg.tcp_flags:02X}, Log=0x{log_flags:02X}"
                    )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º is_fake (–ø–æ TTL < 64 –∏–ª–∏ bad checksum)
                log_is_fake = log_seg.get("parameters", {}).get("is_fake", False)
                pcap_is_fake = pcap_seg.ttl < 64  # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
                if log_is_fake != pcap_is_fake:
                    seg_diff.append(f"is_fake: PCAP={pcap_is_fake}, Log={log_is_fake}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º payload length
                log_payload_len = log_seg.get("parameters", {}).get("payload_len", 0)
                pcap_payload_len = len(pcap_seg.payload) if pcap_seg.payload else 0
                if log_payload_len != pcap_payload_len:
                    seg_diff.append(
                        f"Payload length: PCAP={pcap_payload_len}, Log={log_payload_len}"
                    )

                if seg_diff:
                    mismatches.append({"segment_index": i + 1, "differences": seg_diff})

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if mismatches:
                result["differences"].append(f"Found {len(mismatches)} segment mismatches")
                result["details"]["segment_mismatches"] = mismatches

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result["match"] = len(result["differences"]) == 0

            if result["match"]:
                self.logger.info(
                    f"‚úÖ PCAP matches operation log perfectly: {len(tcp_segments)} segments"
                )
            else:
                self.logger.warning(
                    f"‚ö†Ô∏è PCAP vs operation log differences: {len(result['differences'])} issues"
                )
                for diff in result["differences"]:
                    self.logger.warning(f"   - {diff}")

            return result

        except Exception as e:
            self.logger.error(f"‚ùå Failed to compare PCAP with operation log: {e}", exc_info=True)
            result["differences"].append(f"Comparison error: {str(e)}")
            return result
