"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è PCAP –∞–Ω–∞–ª–∏–∑–∞ –≤ AdaptiveEngine

–ó–∞–¥–∞—á–∞ 7.3: –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å PCAP-–∞–Ω–∞–ª–∏–∑ –≤ AdaptiveEngine
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ PCAP –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ PCAP –∞–Ω–∞–ª–∏–∑–∞
- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è PCAP –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ —É—Å–ø–µ—Ö–∞–º–∏
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º Strategy Failure Analyzer
- –ü–µ—Ä–µ–¥–∞—á–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ PCAP –∞–Ω–∞–ª–∏–∑–∞ –≤ Strategy Generator
"""

import asyncio
import logging
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import asdict
from datetime import datetime, timedelta

# –ò–º–ø–æ—Ä—Ç PCAP –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
try:
    from .intelligent_pcap_analyzer import IntelligentPCAPAnalyzer, PCAPAnalysisResult, BlockingType
    from .pcap_strategy_generator import PCAPStrategyGenerator, PCAPGeneratedStrategy

    PCAP_COMPONENTS_AVAILABLE = True
except ImportError:
    PCAP_COMPONENTS_AVAILABLE = False
    IntelligentPCAPAnalyzer = None
    PCAPStrategyGenerator = None

LOG = logging.getLogger("AdaptiveEnginePCAPIntegration")


class AdaptiveEnginePCAPIntegration:
    """
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è PCAP –∞–Ω–∞–ª–∏–∑–∞ –≤ AdaptiveEngine

    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ PCAP –ø–æ—Å–ª–µ –Ω–µ—É–¥–∞—á
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—é —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ PCAP
    - –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    """

    def __init__(self, adaptive_engine):
        self.adaptive_engine = adaptive_engine

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è PCAP –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        if PCAP_COMPONENTS_AVAILABLE:
            self.pcap_analyzer = IntelligentPCAPAnalyzer()
            self.strategy_generator = PCAPStrategyGenerator()
            self.pcap_enabled = True
        else:
            self.pcap_analyzer = None
            self.strategy_generator = None
            self.pcap_enabled = False
            LOG.warning("‚ö†Ô∏è PCAP –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")

        # –ö—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_cache_file = "pcap_analysis_cache.json"
        self.analysis_cache = self._load_analysis_cache()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        self.integration_stats = {
            "pcap_analyses_performed": 0,
            "strategies_generated_from_pcap": 0,
            "successful_pcap_correlations": 0,
            "cache_hits": 0,
            "cache_misses": 0,
        }

        LOG.info(f"‚úÖ PCAP –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ (enabled: {self.pcap_enabled})")

    async def analyze_failure_with_pcap(
        self, domain: str, strategy: Any, test_result: Dict[str, Any]
    ) -> Optional[PCAPAnalysisResult]:
        """
        –ê–Ω–∞–ª–∏–∑ –Ω–µ—É–¥–∞—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PCAP –¥–∞–Ω–Ω—ã—Ö

        Args:
            domain: –î–æ–º–µ–Ω–Ω–æ–µ –∏–º—è
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞
            test_result: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç PCAP –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ None
        """
        if not self.pcap_enabled:
            LOG.debug("PCAP –∞–Ω–∞–ª–∏–∑ –æ—Ç–∫–ª—é—á–µ–Ω")
            return None

        try:
            # –ü–æ–ª—É—á–∞–µ–º PCAP —Ñ–∞–π–ª –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            pcap_file = test_result.get("pcap_file")
            if not pcap_file or not Path(pcap_file).exists():
                LOG.debug(f"PCAP —Ñ–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {pcap_file}")
                return None

            LOG.info(
                f"üîç –ó–∞–ø—É—Å–∫ PCAP –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {domain} –ø–æ—Å–ª–µ –Ω–µ—É–¥–∞—á–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {getattr(strategy, 'name', 'unknown')}"
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cache_key = self._get_cache_key(pcap_file, domain)
            if cache_key in self.analysis_cache:
                LOG.debug("üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π PCAP –∞–Ω–∞–ª–∏–∑")
                self.integration_stats["cache_hits"] += 1
                return self._deserialize_analysis_result(self.analysis_cache[cache_key])

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
            start_time = time.time()
            analysis_result = await self.pcap_analyzer.analyze_pcap_file(
                pcap_file, domain, self._create_strategy_context(strategy)
            )
            analysis_time = time.time() - start_time

            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.analysis_cache[cache_key] = self._serialize_analysis_result(analysis_result)
            self._save_analysis_cache()
            self.integration_stats["cache_misses"] += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.integration_stats["pcap_analyses_performed"] += 1

            LOG.info(
                f"‚úÖ PCAP –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {analysis_time:.2f}s: "
                f"{analysis_result.blocking_type.value} (confidence: {analysis_result.confidence:.2f})"
            )

            return analysis_result

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ PCAP –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None

    async def generate_strategies_from_pcap(
        self, pcap_analysis: PCAPAnalysisResult, max_strategies: int = 5
    ) -> List[PCAPGeneratedStrategy]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ PCAP –∞–Ω–∞–ª–∏–∑–∞

        Args:
            pcap_analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç PCAP –∞–Ω–∞–ª–∏–∑–∞
            max_strategies: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        """
        if not self.pcap_enabled or not pcap_analysis:
            return []

        try:
            LOG.info(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ PCAP –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {pcap_analysis.domain}")

            strategies = await self.strategy_generator.generate_strategies_from_pcap(
                pcap_analysis, max_strategies
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.integration_stats["strategies_generated_from_pcap"] += len(strategies)

            LOG.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ PCAP")

            return strategies

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏–∑ PCAP: {e}")
            return []

    async def correlate_with_historical_data(
        self, pcap_analysis: PCAPAnalysisResult
    ) -> Dict[str, Any]:
        """
        –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è PCAP –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ —É—Å–ø–µ—Ö–∞–º–∏

        Args:
            pcap_analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç PCAP –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –î–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        """
        try:
            correlation_data = {
                "domain": pcap_analysis.domain,
                "blocking_type": pcap_analysis.blocking_type.value,
                "similar_cases": [],
                "successful_strategies": [],
                "recommendations": [],
            }

            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Å–ª—É—á–∞–∏ –≤ –∫—ç—à–µ
            similar_cases = self._find_similar_cases(pcap_analysis)
            correlation_data["similar_cases"] = similar_cases

            # –ò—â–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
            if hasattr(self.adaptive_engine, "best_strategies"):
                successful_strategies = self._find_successful_strategies_for_blocking_type(
                    pcap_analysis.blocking_type
                )
                correlation_data["successful_strategies"] = successful_strategies

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            if similar_cases or successful_strategies:
                correlation_data["recommendations"] = self._generate_correlation_recommendations(
                    pcap_analysis, similar_cases, successful_strategies
                )
                self.integration_stats["successful_pcap_correlations"] += 1

            LOG.info(
                f"üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(similar_cases)} –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤, "
                f"{len(successful_strategies)} —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"
            )

            return correlation_data

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {e}")
            return {}

    def _create_strategy_context(self, strategy: Any) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        context = {
            "strategy_name": getattr(strategy, "name", "unknown"),
            "timestamp": datetime.now().isoformat(),
        }

        if hasattr(strategy, "attack_combination"):
            context["attacks"] = strategy.attack_combination
        elif hasattr(strategy, "attack_name"):
            context["attacks"] = [strategy.attack_name]

        if hasattr(strategy, "parameters"):
            context["parameters"] = strategy.parameters

        return context

    def _find_similar_cases(self, pcap_analysis: PCAPAnalysisResult) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤ –≤ –∫—ç—à–µ –∞–Ω–∞–ª–∏–∑–∞"""
        similar_cases = []

        try:
            for cache_key, cached_data in self.analysis_cache.items():
                cached_analysis = self._deserialize_analysis_result(cached_data)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
                if (
                    cached_analysis.blocking_type == pcap_analysis.blocking_type
                    and cached_analysis.domain != pcap_analysis.domain
                    and abs(cached_analysis.confidence - pcap_analysis.confidence) < 0.3
                ):

                    similar_case = {
                        "domain": cached_analysis.domain,
                        "blocking_type": cached_analysis.blocking_type.value,
                        "confidence": cached_analysis.confidence,
                        "analyzed_at": cached_analysis.analyzed_at.isoformat(),
                        "similarity_score": self._calculate_similarity_score(
                            pcap_analysis, cached_analysis
                        ),
                    }
                    similar_cases.append(similar_case)

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏
            similar_cases.sort(key=lambda x: x["similarity_score"], reverse=True)

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤: {e}")

        return similar_cases[:5]  # –¢–æ–ø 5 –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤

    def _calculate_similarity_score(
        self, analysis1: PCAPAnalysisResult, analysis2: PCAPAnalysisResult
    ) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–∞–º–∏"""
        score = 0.0

        # –°—Ö–æ–∂–µ—Å—Ç—å —Ç–∏–ø–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        if analysis1.blocking_type == analysis2.blocking_type:
            score += 0.5

        # –°—Ö–æ–∂–µ—Å—Ç—å confidence
        confidence_diff = abs(analysis1.confidence - analysis2.confidence)
        score += max(0, 0.3 - confidence_diff)

        # –°—Ö–æ–∂–µ—Å—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ DPI —Å–∏–≥–Ω–∞—Ç—É—Ä
        sig_count_diff = abs(len(analysis1.dpi_signatures) - len(analysis2.dpi_signatures))
        score += max(0, 0.2 - sig_count_diff * 0.05)

        return min(score, 1.0)

    def _find_successful_strategies_for_blocking_type(
        self, blocking_type: BlockingType
    ) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è —Ç–∏–ø–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"""
        successful_strategies = []

        try:
            if hasattr(self.adaptive_engine, "best_strategies"):
                for domain, strategy in self.adaptive_engine.best_strategies.items():
                    # –ó–¥–µ—Å—å –Ω—É–∂–Ω–∞ –ª–æ–≥–∏–∫–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å —Ç–∏–ø–æ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                    # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É
                    strategy_info = {
                        "domain": domain,
                        "strategy_name": getattr(strategy, "name", "unknown"),
                        "success_rate": 1.0,  # –≠—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —É–∂–µ —É—Å–ø–µ—à–Ω—ã
                    }

                    if hasattr(strategy, "attack_combination"):
                        strategy_info["attacks"] = strategy.attack_combination
                    elif hasattr(strategy, "attack_name"):
                        strategy_info["attacks"] = [strategy.attack_name]

                    if hasattr(strategy, "parameters"):
                        strategy_info["parameters"] = strategy.parameters

                    successful_strategies.append(strategy_info)

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {e}")

        return successful_strategies[:10]  # –¢–æ–ø 10 —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π

    def _generate_correlation_recommendations(
        self,
        pcap_analysis: PCAPAnalysisResult,
        similar_cases: List[Dict],
        successful_strategies: List[Dict],
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"""
        recommendations = []

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤
        if similar_cases:
            recommendations.append(f"–ù–∞–π–¥–µ–Ω–æ {len(similar_cases)} –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            blocking_types = [case["blocking_type"] for case in similar_cases]
            most_common_type = max(set(blocking_types), key=blocking_types.count)
            recommendations.append(f"–ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π —Ç–∏–ø –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {most_common_type}")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        if successful_strategies:
            attack_counts = {}
            for strategy in successful_strategies:
                for attack in strategy.get("attacks", []):
                    attack_counts[attack] = attack_counts.get(attack, 0) + 1

            if attack_counts:
                most_effective_attack = max(attack_counts.keys(), key=lambda k: attack_counts[k])
                recommendations.append(f"–ù–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—Ç–∞–∫–∞: {most_effective_attack}")

        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ç–∏–ø–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        if pcap_analysis.blocking_type == BlockingType.RST_INJECTION:
            recommendations.append("–î–ª—è RST –∏–Ω—ä–µ–∫—Ü–∏–π —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∏–∑–∫–∏–π TTL")
        elif pcap_analysis.blocking_type == BlockingType.SNI_FILTERING:
            recommendations.append("–î–ª—è SNI —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è TLS")

        return recommendations

    def _load_analysis_cache(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if Path(self.analysis_cache_file).exists():
                with open(self.analysis_cache_file, "r", encoding="utf-8") as f:
                    cache_data = json.load(f)
                LOG.info(f"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à PCAP –∞–Ω–∞–ª–∏–∑–∞: {len(cache_data)} –∑–∞–ø–∏—Å–µ–π")
                return cache_data
        except Exception as e:
            LOG.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")

        return {}

    def _save_analysis_cache(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–∞–π–ª"""
        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
            if len(self.analysis_cache) > 1000:
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
                sorted_items = sorted(
                    self.analysis_cache.items(),
                    key=lambda x: x[1].get("analyzed_at", ""),
                    reverse=True,
                )
                self.analysis_cache = dict(sorted_items[:800])

            with open(self.analysis_cache_file, "w", encoding="utf-8") as f:
                json.dump(self.analysis_cache, f, indent=2, ensure_ascii=False, default=str)

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")

    def _get_cache_key(self, pcap_file: str, domain: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞ –¥–ª—è PCAP –∞–Ω–∞–ª–∏–∑–∞"""
        file_stat = Path(pcap_file).stat() if Path(pcap_file).exists() else None
        key_data = f"{pcap_file}:{domain}:{file_stat.st_mtime if file_stat else 0}"
        import hashlib

        return hashlib.md5(key_data.encode()).hexdigest()

    def _serialize_analysis_result(self, analysis_result: PCAPAnalysisResult) -> Dict[str, Any]:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            return {
                "pcap_file": analysis_result.pcap_file,
                "domain": analysis_result.domain,
                "blocking_detected": analysis_result.blocking_detected,
                "blocking_type": analysis_result.blocking_type.value,
                "confidence": analysis_result.confidence,
                "dpi_signatures": [asdict(sig) for sig in analysis_result.dpi_signatures],
                "analysis_details": analysis_result.analysis_details,
                "recommendations": analysis_result.recommendations,
                "analyzed_at": analysis_result.analyzed_at.isoformat(),
            }
        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {}

    def _deserialize_analysis_result(self, cached_data: Dict[str, Any]) -> PCAPAnalysisResult:
        """–î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –∫—ç—à–∞"""
        try:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º BlockingType
            blocking_type = BlockingType(cached_data["blocking_type"])

            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º DPI —Å–∏–≥–Ω–∞—Ç—É—Ä—ã
            dpi_signatures = []
            for sig_data in cached_data.get("dpi_signatures", []):
                # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å DPISignature –æ–±—ä–µ–∫—Ç—ã
                # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
                pass

            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º datetime
            analyzed_at = datetime.fromisoformat(cached_data["analyzed_at"])

            return PCAPAnalysisResult(
                pcap_file=cached_data["pcap_file"],
                domain=cached_data["domain"],
                blocking_detected=cached_data["blocking_detected"],
                blocking_type=blocking_type,
                confidence=cached_data["confidence"],
                dpi_signatures=dpi_signatures,
                analysis_details=cached_data.get("analysis_details", {}),
                recommendations=cached_data.get("recommendations", []),
                analyzed_at=analyzed_at,
            )

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return PCAPAnalysisResult(
                pcap_file="",
                domain="",
                blocking_detected=False,
                blocking_type=BlockingType.UNKNOWN,
                confidence=0.0,
            )

    async def integrate_with_strategy_failure_analyzer(
        self, failure_analyzer, pcap_analysis: PCAPAnalysisResult
    ) -> Dict[str, Any]:
        """
        –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º Strategy Failure Analyzer

        Args:
            failure_analyzer: –≠–∫–∑–µ–º–ø–ª—è—Ä StrategyFailureAnalyzer
            pcap_analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç PCAP –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            integration_result = {
                "pcap_analysis": {
                    "blocking_type": pcap_analysis.blocking_type.value,
                    "confidence": pcap_analysis.confidence,
                    "signatures_count": len(pcap_analysis.dpi_signatures),
                    "recommendations": pcap_analysis.recommendations,
                },
                "sfa_integration": {"enhanced_failure_report": True, "pcap_evidence_added": True},
            }

            # –î–æ–±–∞–≤–ª—è–µ–º PCAP –¥–∞–Ω–Ω—ã–µ –≤ failure report
            if hasattr(failure_analyzer, "_last_failure_report"):
                failure_report = failure_analyzer._last_failure_report
                if failure_report:
                    # –û–±–æ–≥–∞—â–∞–µ–º failure report –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ PCAP
                    if hasattr(failure_report, "failure_details"):
                        failure_report.failure_details.update(
                            {
                                "pcap_blocking_type": pcap_analysis.blocking_type.value,
                                "pcap_confidence": pcap_analysis.confidence,
                                "pcap_signatures": len(pcap_analysis.dpi_signatures),
                                "pcap_recommendations": pcap_analysis.recommendations[:3],
                            }
                        )

                    integration_result["sfa_integration"]["failure_report_enhanced"] = True

            LOG.info("üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å SFA –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return integration_result

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å SFA: {e}")
            return {}

    async def cleanup_old_pcap_files(self, max_age_hours: int = 24):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö PCAP —Ñ–∞–π–ª–æ–≤"""
        try:
            cleanup_count = 0
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)

            # –ò—â–µ–º PCAP —Ñ–∞–π–ª—ã –≤ –∫—ç—à–µ
            for cache_key, cached_data in list(self.analysis_cache.items()):
                try:
                    analyzed_at = datetime.fromisoformat(cached_data["analyzed_at"])
                    pcap_file = cached_data["pcap_file"]

                    if analyzed_at < cutoff_time and Path(pcap_file).exists():
                        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
                        Path(pcap_file).unlink()
                        # –£–¥–∞–ª—è–µ–º –∏–∑ –∫—ç—à–∞
                        del self.analysis_cache[cache_key]
                        cleanup_count += 1

                except Exception as e:
                    LOG.debug(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ {cache_key}: {e}")

            if cleanup_count > 0:
                self._save_analysis_cache()
                LOG.info(f"üßπ –û—á–∏—â–µ–Ω–æ {cleanup_count} —Å—Ç–∞—Ä—ã—Ö PCAP —Ñ–∞–π–ª–æ–≤")

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ PCAP —Ñ–∞–π–ª–æ–≤: {e}")

    def get_integration_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        stats = self.integration_stats.copy()

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        if self.pcap_analyzer:
            stats.update({"pcap_analyzer_stats": self.pcap_analyzer.get_analysis_statistics()})

        if self.strategy_generator:
            stats.update(
                {"strategy_generator_stats": self.strategy_generator.get_generation_statistics()}
            )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
        stats.update(
            {
                "cache_size": len(self.analysis_cache),
                "cache_hit_rate": (
                    stats["cache_hits"] / max(stats["cache_hits"] + stats["cache_misses"], 1)
                )
                * 100,
            }
        )

        return stats

    async def export_pcap_analysis_report(self, output_file: str = "pcap_analysis_report.json"):
        """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –ø–æ PCAP –∞–Ω–∞–ª–∏–∑—É"""
        try:
            report = {
                "generated_at": datetime.now().isoformat(),
                "integration_statistics": self.get_integration_statistics(),
                "analysis_cache_summary": {
                    "total_analyses": len(self.analysis_cache),
                    "blocking_types_distribution": {},
                    "domains_analyzed": set(),
                    "average_confidence": 0.0,
                },
            }

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—ç—à –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            confidences = []
            for cached_data in self.analysis_cache.values():
                blocking_type = cached_data.get("blocking_type", "unknown")
                confidence = cached_data.get("confidence", 0.0)
                domain = cached_data.get("domain", "")

                # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
                if (
                    blocking_type
                    not in report["analysis_cache_summary"]["blocking_types_distribution"]
                ):
                    report["analysis_cache_summary"]["blocking_types_distribution"][
                        blocking_type
                    ] = 0
                report["analysis_cache_summary"]["blocking_types_distribution"][blocking_type] += 1

                # –î–æ–º–µ–Ω—ã
                report["analysis_cache_summary"]["domains_analyzed"].add(domain)

                # Confidence
                confidences.append(confidence)

            # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            report["analysis_cache_summary"]["domains_analyzed"] = len(
                report["analysis_cache_summary"]["domains_analyzed"]
            )
            if confidences:
                report["analysis_cache_summary"]["average_confidence"] = sum(confidences) / len(
                    confidences
                )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            LOG.info(f"üìä –û—Ç—á–µ—Ç PCAP –∞–Ω–∞–ª–∏–∑–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {output_file}")

        except Exception as e:
            LOG.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–∞: {e}")


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ AdaptiveEngine
def integrate_pcap_analysis_into_adaptive_engine(adaptive_engine):
    """
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è PCAP –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π AdaptiveEngine

    Args:
        adaptive_engine: –≠–∫–∑–µ–º–ø–ª—è—Ä AdaptiveEngine

    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä AdaptiveEnginePCAPIntegration
    """
    try:
        pcap_integration = AdaptiveEnginePCAPIntegration(adaptive_engine)

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥—ã –≤ AdaptiveEngine
        adaptive_engine.pcap_integration = pcap_integration
        adaptive_engine.analyze_failure_with_pcap = pcap_integration.analyze_failure_with_pcap
        adaptive_engine.generate_strategies_from_pcap = (
            pcap_integration.generate_strategies_from_pcap
        )
        adaptive_engine.correlate_pcap_with_history = (
            pcap_integration.correlate_with_historical_data
        )

        LOG.info("‚úÖ PCAP –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ AdaptiveEngine")
        return pcap_integration

    except Exception as e:
        LOG.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ PCAP –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return None
